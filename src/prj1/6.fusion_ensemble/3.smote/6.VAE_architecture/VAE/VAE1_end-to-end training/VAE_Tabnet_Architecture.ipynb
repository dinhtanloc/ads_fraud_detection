{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, Union, Tuple\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrun_functions_eagerly(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Union, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "# import tensorflow_probability as tfp\n",
    "from keras import ops\n",
    "# import tensorflow_addons as tfa\n",
    "# from keras.activations import gelu as keras_gelu\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "@tf.function\n",
    "def identity(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SymbolAlreadyExposedError",
     "evalue": "Symbol Zeros is already exposed as ().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSymbolAlreadyExposedError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKERAS_BACKEND\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\__internal__\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\__internal__\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\__init__.py:21\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\applications\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtBase\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtLarge\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtSmall\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\applications\\convnext.py:26\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"ConvNeXt models for Keras.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mReferences:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m  (CVPR 2022)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\tensorflow\\__init__.py:478\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;66;03m# Do an eager load for Keras' code so that any function/method that needs to\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;66;03m# happen at load time will trigger, eg registration of optimizers in the\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# SavedModel registry.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# See b/196254385 for more details.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m   \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m    480\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\optimizers\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m legacy\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m schedules\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\optimizers\\experimental\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madadelta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adadelta\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madafactor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adafactor\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madagrad\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adagrad\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adadelta\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adafactor\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\backend.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_coordinator_utils \u001b[38;5;28;01mas\u001b[39;00m dc\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtensor_api \u001b[38;5;28;01mas\u001b[39;00m dtensor\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_flow_util\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_identity\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\engine\\keras_tensor.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Input Tensor used to track functional API Topology.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_identity\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\utils\\__init__.py:20\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Public Keras utilities.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Serialization related\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize_keras_object\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize_keras_object\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_registration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomObjectScope\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_registration\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization \u001b[38;5;28;01mas\u001b[39;00m legacy_serialization\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_tf_saved_model_scope\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\utils.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_contextlib\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallFunctionSpec\n\u001b[0;32m     32\u001b[0m training_lib \u001b[38;5;241m=\u001b[39m LazyLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_lib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mglobals\u001b[39m(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.src.engine.training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muse_wrapped_call\u001b[39m(\n\u001b[0;32m     36\u001b[0m     layer, call_fn, call_spec, default_training_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     37\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\utils\\layer_utils.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\initializers\\__init__.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers_v1\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization_lib\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization \u001b[38;5;28;01mas\u001b[39;00m legacy_serialization\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\initializers\\initializers_v1.py:32\u001b[0m\n\u001b[0;32m     29\u001b[0m _v1_glorot_uniform_initializer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mglorot_uniform_initializer\n\u001b[0;32m     30\u001b[0m _v1_glorot_normal_initializer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mglorot_normal_initializer\n\u001b[1;32m---> 32\u001b[0m \u001b[43mkeras_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.initializers.Zeros\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.initializers.zeros\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_v1_zeros_initializer\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m keras_export(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.initializers.Ones\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.initializers.ones\u001b[39m\u001b[38;5;124m\"\u001b[39m])(\n\u001b[0;32m     36\u001b[0m     _v1_ones_initializer\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m keras_export(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.initializers.Constant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.initializers.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m])(\n\u001b[0;32m     39\u001b[0m     _v1_constant_initializer\n\u001b[0;32m     40\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py:348\u001b[0m, in \u001b[0;36mapi_export.__call__\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    345\u001b[0m   \u001b[38;5;28mdelattr\u001b[39m(undecorated_f, api_names_attr_v1)\n\u001b[0;32m    347\u001b[0m _, undecorated_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(func)\n\u001b[1;32m--> 348\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mundecorated_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_names_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_attr(undecorated_func, api_names_attr_v1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_names_v1)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_names:\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py:364\u001b[0m, in \u001b[0;36mapi_export.set_attr\u001b[1;34m(self, func, api_names_attr, names)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_names_attr \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m    363\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_multiple_exports:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SymbolAlreadyExposedError(\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymbol \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is already exposed as \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    366\u001b[0m         (func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(func, api_names_attr)))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28msetattr\u001b[39m(func, api_names_attr, names)\n",
      "\u001b[1;31mSymbolAlreadyExposedError\u001b[0m: Symbol Zeros is already exposed as ()."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SymbolAlreadyExposedError",
     "evalue": "Symbol Zeros is already exposed as ().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSymbolAlreadyExposedError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\__internal__\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\__internal__\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\__init__.py:21\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\applications\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtBase\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtLarge\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtSmall\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\applications\\convnext.py:26\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"ConvNeXt models for Keras.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mReferences:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m  (CVPR 2022)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\tensorflow\\__init__.py:478\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;66;03m# Do an eager load for Keras' code so that any function/method that needs to\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;66;03m# happen at load time will trigger, eg registration of optimizers in the\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# SavedModel registry.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# See b/196254385 for more details.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m   \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m    480\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\optimizers\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m legacy\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m schedules\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\optimizers\\experimental\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madadelta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adadelta\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madafactor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adafactor\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madagrad\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adagrad\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adadelta\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adafactor\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\backend.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_coordinator_utils \u001b[38;5;28;01mas\u001b[39;00m dc\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtensor_api \u001b[38;5;28;01mas\u001b[39;00m dtensor\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_flow_util\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_identity\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\engine\\keras_tensor.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Input Tensor used to track functional API Topology.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_identity\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\utils\\__init__.py:20\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Public Keras utilities.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Serialization related\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize_keras_object\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize_keras_object\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_registration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomObjectScope\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_registration\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization \u001b[38;5;28;01mas\u001b[39;00m legacy_serialization\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_tf_saved_model_scope\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\utils.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_contextlib\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallFunctionSpec\n\u001b[0;32m     32\u001b[0m training_lib \u001b[38;5;241m=\u001b[39m LazyLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_lib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mglobals\u001b[39m(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.src.engine.training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muse_wrapped_call\u001b[39m(\n\u001b[0;32m     36\u001b[0m     layer, call_fn, call_spec, default_training_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     37\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\utils\\layer_utils.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\initializers\\__init__.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers_v1\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization_lib\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization \u001b[38;5;28;01mas\u001b[39;00m legacy_serialization\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\keras\\src\\initializers\\initializers_v1.py:32\u001b[0m\n\u001b[0;32m     29\u001b[0m _v1_glorot_uniform_initializer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mglorot_uniform_initializer\n\u001b[0;32m     30\u001b[0m _v1_glorot_normal_initializer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mglorot_normal_initializer\n\u001b[1;32m---> 32\u001b[0m \u001b[43mkeras_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.initializers.Zeros\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.initializers.zeros\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_v1_zeros_initializer\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m keras_export(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.initializers.Ones\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.initializers.ones\u001b[39m\u001b[38;5;124m\"\u001b[39m])(\n\u001b[0;32m     36\u001b[0m     _v1_ones_initializer\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m keras_export(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.initializers.Constant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.initializers.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m])(\n\u001b[0;32m     39\u001b[0m     _v1_constant_initializer\n\u001b[0;32m     40\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py:348\u001b[0m, in \u001b[0;36mapi_export.__call__\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    345\u001b[0m   \u001b[38;5;28mdelattr\u001b[39m(undecorated_f, api_names_attr_v1)\n\u001b[0;32m    347\u001b[0m _, undecorated_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(func)\n\u001b[1;32m--> 348\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mundecorated_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_names_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_attr(undecorated_func, api_names_attr_v1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_names_v1)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_names:\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_prj_nckh\\.conda\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py:364\u001b[0m, in \u001b[0;36mapi_export.set_attr\u001b[1;34m(self, func, api_names_attr, names)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_names_attr \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m    363\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_multiple_exports:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SymbolAlreadyExposedError(\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymbol \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is already exposed as \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    366\u001b[0m         (func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(func, api_names_attr)))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28msetattr\u001b[39m(func, api_names_attr, names)\n",
      "\u001b[1;31mSymbolAlreadyExposedError\u001b[0m: Symbol Zeros is already exposed as ()."
     ]
    }
   ],
   "source": [
    "from keras import ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
      "0   0.374540   0.185133   0.261706   0.672703   0.571996   0.393636   \n",
      "1   0.950714   0.541901   0.246979   0.796681   0.805432   0.473436   \n",
      "2   0.731994   0.872946   0.906255   0.250468   0.760161   0.854547   \n",
      "3   0.598658   0.732225   0.249546   0.624874   0.153900   0.340004   \n",
      "4   0.156019   0.806561   0.271950   0.571746   0.149249   0.869650   \n",
      "\n",
      "   Feature_7  Feature_8  Feature_9  Feature_10  Feature_11  Feature_12  Target  \n",
      "0   0.648257   0.038799   0.720268    0.913578    0.373641    0.533031       1  \n",
      "1   0.172386   0.186773   0.687283    0.525360    0.332912    0.137899       1  \n",
      "2   0.872395   0.831246   0.095754    0.724910    0.176154    0.591243       0  \n",
      "3   0.613116   0.766768   0.922572    0.436048    0.607267    0.314786       0  \n",
      "4   0.157204   0.350643   0.568472    0.630035    0.476624    0.052349       0  \n",
      "Số lượng mẫu: 1000, Số lượng cột: 13\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)  \n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "data = {}\n",
    "for i in range(1, 42):\n",
    "    col_name = f\"Feature_{i}\"\n",
    "    data[col_name] = np.random.rand(num_samples)  \n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['Target'] = np.random.randint(0, 2, size=num_samples) \n",
    "\n",
    "print(df.head())\n",
    "feature_columns = list(df.columns[:-1])  \n",
    "\n",
    "print(f\"Số lượng mẫu: {len(df)}, Số lượng cột: {len(df.columns)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLUBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, units: Optional[int] = None,\n",
    "                #  virtual_batch_size: Optional[int] = 128, \n",
    "                 momentum: Optional[float] = 0.02):\n",
    "        super(GLUBlock, self).__init__()\n",
    "        self.units = units\n",
    "        # self.virtual_batch_size = virtual_batch_size\n",
    "        self.momentum = momentum\n",
    "        \n",
    "    def build(self, input_shape: tf.TensorShape):\n",
    "        if self.units is None:\n",
    "            self.units = input_shape[-1]\n",
    "            \n",
    "        self.fc_outout = tf.keras.layers.Dense(self.units, \n",
    "                                               use_bias=False)\n",
    "        self.bn_outout = tf.keras.layers.BatchNormalization(\n",
    "                                                            momentum=self.momentum)\n",
    "        \n",
    "        self.fc_gate = tf.keras.layers.Dense(self.units, \n",
    "                                             use_bias=False)\n",
    "        self.bn_gate = tf.keras.layers.BatchNormalization( \n",
    "                                                          momentum=self.momentum)\n",
    "        \n",
    "    def call(self, inputs: Union[tf.Tensor, np.ndarray], training: Optional[bool] = None):\n",
    "        output = self.bn_outout(self.fc_outout(inputs), \n",
    "                                training=training)\n",
    "        gate = self.bn_gate(self.fc_gate(inputs), \n",
    "                            training=training)\n",
    "    \n",
    "        return output * tf.keras.activations.sigmoid(gate) # GLU\n",
    "    \n",
    "class FeatureTransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, units: Optional[int] = None,\n",
    "                 momentum: Optional[float] = 0.02, skip=False):\n",
    "        super(FeatureTransformerBlock, self).__init__()\n",
    "        self.units = units\n",
    "        # self.virtual_batch_size = virtual_batch_size\n",
    "        self.momentum = momentum\n",
    "        self.skip = skip\n",
    "        \n",
    "    def build(self, input_shape: tf.TensorShape):\n",
    "        if self.units is None:\n",
    "            self.units = input_shape[-1]\n",
    "        \n",
    "        self.initial = GLUBlock(units = self.units, \n",
    "                                # virtual_batch_size=self.virtual_batch_size, \n",
    "                                momentum=self.momentum)\n",
    "        self.residual =  GLUBlock(units = self.units, \n",
    "                                #   virtual_batch_size=self.virtual_batch_size, \n",
    "                                  momentum=self.momentum)\n",
    "        \n",
    "    def call(self, inputs: Union[tf.Tensor, np.ndarray], training: Optional[bool] = None):\n",
    "        initial = self.initial(inputs, training=training)\n",
    "        \n",
    "        if self.skip == True:\n",
    "            initial += inputs\n",
    "\n",
    "        residual = self.residual(initial, training=training) # skip\n",
    "        \n",
    "        return (initial + residual) * np.sqrt(0.5)\n",
    "\n",
    "class AttentiveTransformer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units: Optional[int] = None, \n",
    "                #  virtual_batch_size: Optional[int] = 128, \n",
    "                 momentum: Optional[float] = 0.02):\n",
    "        super(AttentiveTransformer, self).__init__()\n",
    "        self.units = units\n",
    "        # self.virtual_batch_size = virtual_batch_size\n",
    "        self.momentum = momentum\n",
    "        \n",
    "    def build(self, input_shape: tf.TensorShape):\n",
    "        if self.units is None:\n",
    "            self.units = input_shape[-1]\n",
    "            \n",
    "        self.fc = tf.keras.layers.Dense(self.units, \n",
    "                                        use_bias=False)\n",
    "        self.bn = tf.keras.layers.BatchNormalization(\n",
    "            # virtual_batch_size=self.virtual_batch_size, \n",
    "                                                     momentum=self.momentum)\n",
    "        \n",
    "    def call(self, inputs: Union[tf.Tensor, np.ndarray], priors: Optional[Union[tf.Tensor, np.ndarray]] = None, training: Optional[bool] = None) -> tf.Tensor:\n",
    "        feature = self.bn(self.fc(inputs), \n",
    "                          training=training)\n",
    "        if priors is None:\n",
    "            output = feature\n",
    "        else:\n",
    "            output = feature * priors\n",
    "        \n",
    "        return keras.layers.sparsemax(output)\n",
    "\n",
    "class TabNetStep(tf.keras.layers.Layer):\n",
    "    def __init__(self, units: Optional[int] = None,\n",
    "                 momentum: Optional[float] =0.02):\n",
    "        super(TabNetStep, self).__init__()\n",
    "        self.units = units\n",
    "        # self.virtual_batch_size = virtual_batch_size\n",
    "        self.momentum = momentum\n",
    "        \n",
    "    def build(self, input_shape: tf.TensorShape):\n",
    "        if self.units is None:\n",
    "            self.units = input_shape[-1]\n",
    "        \n",
    "        self.unique = FeatureTransformerBlock(units = self.units, \n",
    "                                            #   virtual_batch_size=self.virtual_batch_size, \n",
    "                                              momentum=self.momentum,\n",
    "                                              skip=True)\n",
    "        self.attention = AttentiveTransformer(units = input_shape[-1], \n",
    "                                            #   virtual_batch_size=self.virtual_batch_size, \n",
    "                                              momentum=self.momentum)\n",
    "        \n",
    "    def call(self, inputs, shared, priors, training=None) -> Tuple[tf.Tensor]:  \n",
    "        split = self.unique(shared, training=training)\n",
    "        keys = self.attention(split, priors, training=training)\n",
    "        masked = keys * inputs\n",
    "        \n",
    "        return split, masked, keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabNetEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, units: int =1, \n",
    "                 n_steps: int = 3, \n",
    "                 n_features: int = 8,\n",
    "                 outputs: int = 1, \n",
    "                 gamma: float = 1.3,\n",
    "                 epsilon: float = 1e-8, \n",
    "                 sparsity: float = 1e-5, \n",
    "                #  virtual_batch_size: Optional[int]=128, \n",
    "                 momentum: Optional[float] =0.02):\n",
    "        super(TabNetEncoder, self).__init__()\n",
    "        \n",
    "        self.units = units\n",
    "        self.n_steps = n_steps\n",
    "        self.n_features = n_features\n",
    "        # self.virtual_batch_size = virtual_batch_size\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.momentum = momentum\n",
    "        self.sparsity = sparsity\n",
    "        \n",
    "    def build(self, input_shape: tf.TensorShape):            \n",
    "        self.bn = tf.keras.layers.BatchNormalization(\n",
    "            # virtual_batch_size=self.virtual_batch_size, \n",
    "                                                     momentum=self.momentum)\n",
    "        self.shared_block = FeatureTransformerBlock(units = self.n_features, \n",
    "                                                    # virtual_batch_size=self.virtual_batch_size, \n",
    "                                                    momentum=self.momentum)        \n",
    "        self.initial_step = TabNetStep(units = self.n_features, \n",
    "                                    #    virtual_batch_size=self.virtual_batch_size, \n",
    "                                       momentum=self.momentum)\n",
    "        self.steps = [TabNetStep(units = self.n_features, \n",
    "                                #  virtual_batch_size=self.virtual_batch_size, \n",
    "                                 momentum=self.momentum) for _ in range(self.n_steps)]\n",
    "        self.final = tf.keras.layers.Dense(units = self.units, \n",
    "                                           use_bias=False)\n",
    "    \n",
    "\n",
    "    def call(self, X: Union[tf.Tensor, np.ndarray], training: Optional[bool] = None) -> Tuple[tf.Tensor]:        \n",
    "        entropy_loss = 0.\n",
    "        encoded = 0.\n",
    "        output = 0.\n",
    "        importance = 0.\n",
    "        prior = tf.reduce_mean(tf.ones_like(X), axis=0)\n",
    "        \n",
    "        B = prior * self.bn(X, training=training)\n",
    "        shared = self.shared_block(B, training=training)\n",
    "        _, masked, keys = self.initial_step(B, shared, prior, training=training)\n",
    "\n",
    "        for step in self.steps:\n",
    "            entropy_loss += tf.reduce_mean(tf.reduce_sum(-keys * tf.math.log(keys + self.epsilon), axis=-1)) / tf.cast(self.n_steps, tf.float32)\n",
    "            prior *= (self.gamma - tf.reduce_mean(keys, axis=0))\n",
    "            importance += keys\n",
    "            \n",
    "            shared = self.shared_block(masked, training=training)\n",
    "            split, masked, keys = step(B, shared, prior, training=training)\n",
    "            features = tf.keras.activations.relu(split)\n",
    "            \n",
    "            output += features\n",
    "            encoded += split\n",
    "            \n",
    "        self.add_loss(self.sparsity * entropy_loss)\n",
    "          \n",
    "        prediction = self.final(output)\n",
    "        return prediction, encoded, importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabNetDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=1, \n",
    "                 n_steps = 3, \n",
    "                 n_features = 8,\n",
    "                 outputs = 1, \n",
    "                 gamma = 1.3,\n",
    "                 epsilon = 1e-8, \n",
    "                 sparsity = 1e-5, \n",
    "                #  virtual_batch_size=128, \n",
    "                 momentum=0.02):\n",
    "        super(TabNetDecoder, self).__init__()\n",
    "        \n",
    "        self.units = units\n",
    "        self.n_steps = n_steps\n",
    "        self.n_features = n_features\n",
    "        # self.virtual_batch_size = virtual_batch_size\n",
    "        self.momentum = momentum\n",
    "        \n",
    "    def build(self, input_shape: tf.TensorShape):\n",
    "        self.shared_block = FeatureTransformerBlock(units = self.n_features, \n",
    "                                                    # virtual_batch_size=self.virtual_batch_size, \n",
    "                                                    momentum=self.momentum)\n",
    "        self.steps = [FeatureTransformerBlock(units = self.n_features,\n",
    "                                            #   virtual_batch_size=self.virtual_batch_size, \n",
    "                                              momentum=self.momentum) for _ in range(self.n_steps)]\n",
    "        self.fc = [tf.keras.layers.Dense(units = self.units) for _ in range(self.n_steps)]\n",
    "    \n",
    "\n",
    "    def call(self, X: Union[tf.Tensor, np.ndarray], training: Optional[bool] = None) -> tf.Tensor:\n",
    "        decoded = 0.\n",
    "        \n",
    "        for ftb, fc in zip(self.steps, self.fc):\n",
    "            shared = self.shared_block(X, training=training)\n",
    "            feature = ftb(shared, training=training)\n",
    "            output = fc(feature)\n",
    "            \n",
    "            decoded += output\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.seed_generator = keras.random.SeedGenerator(1337)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = ops.shape(z_mean)[0]\n",
    "        dim = ops.shape(z_mean)[1]\n",
    "        epsilon = keras.random.normal(shape=(batch, dim), seed=self.seed_generator)\n",
    "        return z_mean + ops.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 outputs: int = 1, \n",
    "                 inputs: int = 12,\n",
    "                 n_steps: int = 3, \n",
    "                 n_features: int = 12,\n",
    "                 gamma: float = 1.3, \n",
    "                 epsilon: float = 1e-8, \n",
    "                 sparsity: float = 1e-5, \n",
    "                #  virtual_batch_size: Optional[int] = None, \n",
    "                 momentum: Optional[float] = 0.02, \n",
    "                 mlp_units=None, \n",
    "                 latent_dim=64, \n",
    "                 name='vae_encoder', \n",
    "                 **kwargs):\n",
    "        \n",
    "        super(VAE_Encoder, self).__init__(name=name, **kwargs)\n",
    "        self.feature = tf.keras.layers.Lambda(lambda x: x)\n",
    "        # if feature_column is None:\n",
    "        # else:\n",
    "        #     self.feature = feature_column\n",
    "        self.tabnet_encoder = TabNetEncoder(units=outputs, \n",
    "                                    n_steps=n_steps, \n",
    "                                    n_features=n_features,\n",
    "                                    gamma=gamma, \n",
    "                                    epsilon=epsilon, \n",
    "                                    sparsity=sparsity,\n",
    "                                    # virtual_batch_size=virtual_batch_size, \n",
    "                                    momentum=momentum)\n",
    "        if mlp_units:\n",
    "            self.mlp = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(units, activation='relu') for units in mlp_units\n",
    "            ])\n",
    "        self.mean_layer = tf.keras.layers.Dense(latent_dim)\n",
    "        self.logvar_layer = tf.keras.layers.Dense(latent_dim)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        _, encoded, _ = self.tabnet_encoder(inputs)\n",
    "        print('ok')\n",
    "        encoded = self.mlp(encoded, training=training)\n",
    "        z_mean = self.mean_layer(encoded)\n",
    "        z_log_var = self.logvar_layer(encoded)\n",
    "        z = Sampling()([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var,z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 outputs: int = 1, \n",
    "                 inputs: int = 12,\n",
    "                 n_steps: int = 3, \n",
    "                 n_features: int = 12,\n",
    "                 gamma: float = 1.3, \n",
    "                 epsilon: float = 1e-8, \n",
    "                 sparsity: float = 1e-5, \n",
    "                #  virtual_batch_size: Optional[int] = None, \n",
    "                 momentum: Optional[float] = 0.02,\n",
    "                 mlp_units=None, \n",
    "                 name='vae_decoder', \n",
    "                 **kwargs):\n",
    "        super(VAE_Decoder, self).__init__(name=name, **kwargs)\n",
    "        if mlp_units:\n",
    "            self.mlp = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(units, activation='relu') for units in reversed(mlp_units)\n",
    "            ])\n",
    "        self.tabnet_decoder = TabNetDecoder(units=inputs, \n",
    "                                     n_steps=n_steps, \n",
    "                                     n_features=n_features,\n",
    "                                    #  virtual_batch_size=virtual_batch_size, \n",
    "                                     momentum=momentum)\n",
    "\n",
    "    def call(self, inputs=64, training=False):\n",
    "        decoded = self.mlp(inputs, training=training)\n",
    "        reconstructed = self.tabnet_decoder(decoded, training=training)\n",
    "        return reconstructed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.drop(columns=['Target'])  \n",
    "y_train = df['Target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>Feature_10</th>\n",
       "      <th>Feature_11</th>\n",
       "      <th>Feature_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.185133</td>\n",
       "      <td>0.261706</td>\n",
       "      <td>0.672703</td>\n",
       "      <td>0.571996</td>\n",
       "      <td>0.393636</td>\n",
       "      <td>0.648257</td>\n",
       "      <td>0.038799</td>\n",
       "      <td>0.720268</td>\n",
       "      <td>0.913578</td>\n",
       "      <td>0.373641</td>\n",
       "      <td>0.533031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.541901</td>\n",
       "      <td>0.246979</td>\n",
       "      <td>0.796681</td>\n",
       "      <td>0.805432</td>\n",
       "      <td>0.473436</td>\n",
       "      <td>0.172386</td>\n",
       "      <td>0.186773</td>\n",
       "      <td>0.687283</td>\n",
       "      <td>0.525360</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>0.137899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.872946</td>\n",
       "      <td>0.906255</td>\n",
       "      <td>0.250468</td>\n",
       "      <td>0.760161</td>\n",
       "      <td>0.854547</td>\n",
       "      <td>0.872395</td>\n",
       "      <td>0.831246</td>\n",
       "      <td>0.095754</td>\n",
       "      <td>0.724910</td>\n",
       "      <td>0.176154</td>\n",
       "      <td>0.591243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.732225</td>\n",
       "      <td>0.249546</td>\n",
       "      <td>0.624874</td>\n",
       "      <td>0.153900</td>\n",
       "      <td>0.340004</td>\n",
       "      <td>0.613116</td>\n",
       "      <td>0.766768</td>\n",
       "      <td>0.922572</td>\n",
       "      <td>0.436048</td>\n",
       "      <td>0.607267</td>\n",
       "      <td>0.314786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.156019</td>\n",
       "      <td>0.806561</td>\n",
       "      <td>0.271950</td>\n",
       "      <td>0.571746</td>\n",
       "      <td>0.149249</td>\n",
       "      <td>0.869650</td>\n",
       "      <td>0.157204</td>\n",
       "      <td>0.350643</td>\n",
       "      <td>0.568472</td>\n",
       "      <td>0.630035</td>\n",
       "      <td>0.476624</td>\n",
       "      <td>0.052349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.091582</td>\n",
       "      <td>0.656955</td>\n",
       "      <td>0.865296</td>\n",
       "      <td>0.442107</td>\n",
       "      <td>0.897397</td>\n",
       "      <td>0.684435</td>\n",
       "      <td>0.579737</td>\n",
       "      <td>0.273160</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>0.857656</td>\n",
       "      <td>0.359445</td>\n",
       "      <td>0.004644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.917314</td>\n",
       "      <td>0.956615</td>\n",
       "      <td>0.157273</td>\n",
       "      <td>0.334401</td>\n",
       "      <td>0.119381</td>\n",
       "      <td>0.503220</td>\n",
       "      <td>0.667037</td>\n",
       "      <td>0.209519</td>\n",
       "      <td>0.165370</td>\n",
       "      <td>0.897509</td>\n",
       "      <td>0.926708</td>\n",
       "      <td>0.873669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.136819</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.309788</td>\n",
       "      <td>0.394572</td>\n",
       "      <td>0.327843</td>\n",
       "      <td>0.765149</td>\n",
       "      <td>0.911577</td>\n",
       "      <td>0.455329</td>\n",
       "      <td>0.977713</td>\n",
       "      <td>0.946708</td>\n",
       "      <td>0.698657</td>\n",
       "      <td>0.307325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.950237</td>\n",
       "      <td>0.057055</td>\n",
       "      <td>0.290046</td>\n",
       "      <td>0.529941</td>\n",
       "      <td>0.815745</td>\n",
       "      <td>0.485291</td>\n",
       "      <td>0.345620</td>\n",
       "      <td>0.908438</td>\n",
       "      <td>0.107925</td>\n",
       "      <td>0.397488</td>\n",
       "      <td>0.257177</td>\n",
       "      <td>0.938589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.446006</td>\n",
       "      <td>0.282187</td>\n",
       "      <td>0.871414</td>\n",
       "      <td>0.161367</td>\n",
       "      <td>0.597312</td>\n",
       "      <td>0.149382</td>\n",
       "      <td>0.621507</td>\n",
       "      <td>0.104480</td>\n",
       "      <td>0.931944</td>\n",
       "      <td>0.217140</td>\n",
       "      <td>0.564085</td>\n",
       "      <td>0.316945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0     0.374540   0.185133   0.261706   0.672703   0.571996   0.393636   \n",
       "1     0.950714   0.541901   0.246979   0.796681   0.805432   0.473436   \n",
       "2     0.731994   0.872946   0.906255   0.250468   0.760161   0.854547   \n",
       "3     0.598658   0.732225   0.249546   0.624874   0.153900   0.340004   \n",
       "4     0.156019   0.806561   0.271950   0.571746   0.149249   0.869650   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "995   0.091582   0.656955   0.865296   0.442107   0.897397   0.684435   \n",
       "996   0.917314   0.956615   0.157273   0.334401   0.119381   0.503220   \n",
       "997   0.136819   0.068958   0.309788   0.394572   0.327843   0.765149   \n",
       "998   0.950237   0.057055   0.290046   0.529941   0.815745   0.485291   \n",
       "999   0.446006   0.282187   0.871414   0.161367   0.597312   0.149382   \n",
       "\n",
       "     Feature_7  Feature_8  Feature_9  Feature_10  Feature_11  Feature_12  \n",
       "0     0.648257   0.038799   0.720268    0.913578    0.373641    0.533031  \n",
       "1     0.172386   0.186773   0.687283    0.525360    0.332912    0.137899  \n",
       "2     0.872395   0.831246   0.095754    0.724910    0.176154    0.591243  \n",
       "3     0.613116   0.766768   0.922572    0.436048    0.607267    0.314786  \n",
       "4     0.157204   0.350643   0.568472    0.630035    0.476624    0.052349  \n",
       "..         ...        ...        ...         ...         ...         ...  \n",
       "995   0.579737   0.273160   0.514929    0.857656    0.359445    0.004644  \n",
       "996   0.667037   0.209519   0.165370    0.897509    0.926708    0.873669  \n",
       "997   0.911577   0.455329   0.977713    0.946708    0.698657    0.307325  \n",
       "998   0.345620   0.908438   0.107925    0.397488    0.257177    0.938589  \n",
       "999   0.621507   0.104480   0.931944    0.217140    0.564085    0.316945  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Tabnet_MLPS(tf.keras.Model):\n",
    "    def __init__(self, encoder, decoder, classifier, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.feature = tf.keras.layers.Lambda(lambda x: x)\n",
    "        self.classifier = classifier\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.classification_loss_tracker = tf.keras.metrics.Mean(name=\"classification_loss\")\n",
    "        self.accuracy_tracker = tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")\n",
    "        self.bn = tf.keras.layers.BatchNormalization(momentum=0.02)\n",
    "        self.do = tf.keras.layers.Dropout(0.25)\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.classification_loss_tracker,\n",
    "            self.accuracy_tracker,\n",
    "        ]\n",
    "    \n",
    "        \n",
    "\n",
    "    # def call(self, X: Union[tf.Tensor, np.ndarray], training: Optional[bool] = None) -> tf.Tensor:\n",
    "    #     X = self.feature(X)\n",
    "    #     print(X)\n",
    "    #     X = self.bn(X, training=training)\n",
    "        \n",
    "    #     M = self.do(tf.ones_like(X), training=training)\n",
    "    #     D = X * M\n",
    "    #     print(X.shape)\n",
    "        \n",
    "    #     output, encoded, importance = self.encoder(D)\n",
    "    #     prediction = tf.keras.activations.sigmoid(output)        \n",
    "        \n",
    "    #     T = X * (1 - M)\n",
    "    #     reconstruction = self.decoder(encoded)\n",
    "        \n",
    "    #     loss = tf.reduce_mean(tf.where(M != 0., tf.square(T - reconstruction), tf.zeros_like(reconstruction)))\n",
    "    #     self.add_loss(loss)\n",
    "        \n",
    "    #     return prediction\n",
    "\n",
    "    def train_step(self, inputs): \n",
    "        # print(inputs.shape)\n",
    "        x_train,y_train=inputs\n",
    "        print(x_train.shape,y_train.shape)\n",
    "\n",
    "        # # x_train, y_train = data \n",
    "        # # print(f\"x_train shape: {x_train.shape}\")\n",
    "        # X = self.feature(X)[0]\n",
    "        # print(X.shape)\n",
    "        # X = self.bn(X, training=training)\n",
    "        # print(X.shape)\n",
    "        \n",
    "        # M = self.do(tf.ones_like(X), training=training)\n",
    "        # # D = X * M\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z, z_mean, z_log_var = self.encoder(x_train)\n",
    "            reconstruction = self.decoder(z)\n",
    "            classification_output = self.classifier(z)\n",
    "            \n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.keras.losses.binary_crossentropy(x_train, reconstruction)\n",
    "            )\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "            )\n",
    "            \n",
    "            classification_loss = tf.reduce_mean(\n",
    "                tf.keras.losses.binary_crossentropy(y_train, classification_output)\n",
    "            )\n",
    "\n",
    "            total_loss = reconstruction_loss + kl_loss + classification_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        self.classification_loss_tracker.update_state(classification_loss)\n",
    "        self.accuracy_tracker.update_state(y_train, classification_output)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            \"classification_loss\": self.classification_loss_tracker.result(),\n",
    "            \"accuracy\": self.accuracy_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64)\n"
     ]
    }
   ],
   "source": [
    "def build_classifier(input_dim, num_classes):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    print(inputs.shape)\n",
    "    x = Dense(32, activation='relu')(inputs)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    outputs = Dense(num_classes, activation='sigmoid')(x)  # Sử dụng softmax cho phân loại đa lớp\n",
    "    classifier = Model(inputs=inputs, outputs=outputs)\n",
    "    classifier.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),loss='binary_crossentropy')\n",
    "    return classifier\n",
    "classifier= build_classifier(64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 12)\n",
      "Epoch 1/50\n",
      "(32, 12) (32, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\miniconda3\\envs\\vae\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\miniconda3\\envs\\vae\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling AttentiveTransformer.call().\n\n\u001b[1mmodule 'keras.api.layers' has no attribute 'sparsemax'\u001b[0m\n\nArguments received by AttentiveTransformer.call():\n  • inputs=tf.Tensor(shape=(32, 12), dtype=float32)\n  • priors=tf.Tensor(shape=(12,), dtype=float32)\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m vae\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\miniconda3\\envs\\vae\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[60], line 64\u001b[0m, in \u001b[0;36mVAE_Tabnet_MLPS.train_step\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# # x_train, y_train = data \u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# # print(f\"x_train shape: {x_train.shape}\")\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# X = self.feature(X)[0]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# M = self.do(tf.ones_like(X), training=training)\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# # D = X * M\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 64\u001b[0m     z, z_mean, z_log_var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x_train)\n\u001b[0;32m     65\u001b[0m     reconstruction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(z)\n\u001b[0;32m     66\u001b[0m     classification_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(z)\n",
      "Cell \u001b[1;32mIn[42], line 38\u001b[0m, in \u001b[0;36mVAE_Encoder.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 38\u001b[0m     _, encoded, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtabnet_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m     encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(encoded, training\u001b[38;5;241m=\u001b[39mtraining)\n",
      "Cell \u001b[1;32mIn[4], line 48\u001b[0m, in \u001b[0;36mTabNetEncoder.call\u001b[1;34m(self, X, training)\u001b[0m\n\u001b[0;32m     46\u001b[0m B \u001b[38;5;241m=\u001b[39m prior \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(X, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[0;32m     47\u001b[0m shared \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_block(B, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m---> 48\u001b[0m _, masked, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps:\n\u001b[0;32m     51\u001b[0m     entropy_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(tf\u001b[38;5;241m.\u001b[39mreduce_sum(\u001b[38;5;241m-\u001b[39mkeys \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(keys \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m/\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps, tf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "Cell \u001b[1;32mIn[3], line 113\u001b[0m, in \u001b[0;36mTabNetStep.call\u001b[1;34m(self, inputs, shared, priors, training)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, shared, priors, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[tf\u001b[38;5;241m.\u001b[39mTensor]:  \n\u001b[0;32m    112\u001b[0m     split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique(shared, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m--> 113\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpriors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     masked \u001b[38;5;241m=\u001b[39m keys \u001b[38;5;241m*\u001b[39m inputs\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m split, masked, keys\n",
      "Cell \u001b[1;32mIn[3], line 89\u001b[0m, in \u001b[0;36mAttentiveTransformer.call\u001b[1;34m(self, inputs, priors, training)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     output \u001b[38;5;241m=\u001b[39m feature \u001b[38;5;241m*\u001b[39m priors\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparsemax\u001b[49m(output)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Exception encountered when calling AttentiveTransformer.call().\n\n\u001b[1mmodule 'keras.api.layers' has no attribute 'sparsemax'\u001b[0m\n\nArguments received by AttentiveTransformer.call():\n  • inputs=tf.Tensor(shape=(32, 12), dtype=float32)\n  • priors=tf.Tensor(shape=(12,), dtype=float32)\n  • training=False"
     ]
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "# tabnet_encoder = TabNetEncoder(units=latent_dim, n_steps=3, n_features=12)\n",
    "# tabnet_decoder = TabNetDecoder(units=12, n_steps=3, n_features=12)\n",
    "\n",
    "vae_encoder = VAE_Encoder(mlp_units=[64, 32], latent_dim=64, outputs=64, inputs=12)\n",
    "vae_decoder = VAE_Decoder(mlp_units=[32, 64], outputs=12, inputs=latent_dim)\n",
    "vae = VAE_Tabnet_MLPS(encoder=vae_encoder, decoder=vae_decoder, classifier=classifier)\n",
    "\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy')\n",
    "print(x_train.shape)\n",
    "vae.fit(x_train, y_train, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
