{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3fedb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dd1c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Data\\ads_fraud_detection\n",
      "c:/Users/Admin/Data/ads_fraud_detection\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "__script_path=os.path.abspath(globals().get('__file__','.'))\n",
    "__script_dir = os.path.dirname(__script_path)\n",
    "root_dir = os.path.abspath(f'{__script_dir}/../../../..')\n",
    "#print(root_dir)\n",
    "for lib in [root_dir][::-1]:\n",
    "    if lib in sys.path:\n",
    "        sys.path.remove(lib)\n",
    "    sys.path.insert(0,lib)\n",
    "from config.config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69041950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#print(torch.version.cuda)  # Hiển thị phiên bản CUDA mà PyTorch đang sử dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Training on gpu.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Training on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on gpu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "622aee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=f\"{exps_dir}/exp1/exp_smote\"\n",
    "if os.path.exists(save_dir) == False: \n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee0c5839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_selection=dict(np.load(f'{save_dir}/feature_model_selection.npz',allow_pickle=True))['feature_model_selection']\n",
    "# feature_selection = {key: value for key, value in feature_selection.item().items()}\n",
    "# feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d162d6",
   "metadata": {},
   "source": [
    "* kiểm tra và tạo các thư mục (nếu chưa có)\n",
    "* tập test 33%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7e092",
   "metadata": {},
   "source": [
    "# 5. Xây dựng và đánh giá mô hình học sâu Neutual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d84bdb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bg_model=joblib.load(f'{save_dir}/bg_model.joblib')\n",
    "# rf_model=joblib.load(f'{save_dir}/rf_model.joblib')\n",
    "# svm_model=joblib.load(f'{save_dir}/svm_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e81211d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6555772994129159, 1: 2.106918238993711}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "class_weights_dict=dict(np.load(f'{save_dir}/class_weights_dict.npz',allow_pickle=True))['class_weights_dict']\n",
    "class_weights_dict = {key: value for key, value in class_weights_dict.item().items()}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0369d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91c27093",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values.squeeze(), dtype=torch.long)\n",
    "X_test = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values.squeeze(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = len(np.unique(y_train))\n",
    "# #print(f\"Số lớp: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd43638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_train_onehot = torch.nn.functional.one_hot(y_train, num_classes=2)\n",
    "# # y_test_onehot = torch.nn.functional.one_hot(y_test, num_classes=2)\n",
    "\n",
    "# #print(\"Mã hóa one-hot của y_train:\\n\", y_train_onehot)\n",
    "# #print(\"Mã hóa one-hot của y_test:\\n\", y_test_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52323c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.tensor(x_data.values, dtype=torch.float32)  # Chuyển features thành tensor\n",
    "        self.y_data = y_data  # Nhãn đã được mã hóa one-hot\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfa909c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "test_dataset = CustomDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5731513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cf5d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor([class_weights_dict[key] for key in sorted(class_weights_dict.keys())], dtype=torch.float32)\n",
    "class_weights = class_weights\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dda6290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 39)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1c3ac7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 39)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e415e738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 8.80416 | val_0_unsup_loss_numpy: 59.052978515625|  0:00:00s\n",
      "epoch 1  | loss: 6.14867 | val_0_unsup_loss_numpy: 36.15195846557617|  0:00:00s\n",
      "epoch 2  | loss: 4.86443 | val_0_unsup_loss_numpy: 10.468839645385742|  0:00:00s\n",
      "epoch 3  | loss: 4.13779 | val_0_unsup_loss_numpy: 9.760029792785645|  0:00:00s\n",
      "epoch 4  | loss: 3.50821 | val_0_unsup_loss_numpy: 5.360750198364258|  0:00:00s\n",
      "epoch 5  | loss: 3.075   | val_0_unsup_loss_numpy: 3.9730899333953857|  0:00:00s\n",
      "epoch 6  | loss: 2.70275 | val_0_unsup_loss_numpy: 3.4019598960876465|  0:00:00s\n",
      "epoch 7  | loss: 2.4362  | val_0_unsup_loss_numpy: 2.7136099338531494|  0:00:00s\n",
      "epoch 8  | loss: 2.19751 | val_0_unsup_loss_numpy: 2.245879888534546|  0:00:00s\n",
      "epoch 9  | loss: 2.04662 | val_0_unsup_loss_numpy: 3.8299500942230225|  0:00:00s\n",
      "epoch 10 | loss: 1.87432 | val_0_unsup_loss_numpy: 2.237529993057251|  0:00:00s\n",
      "epoch 11 | loss: 1.72491 | val_0_unsup_loss_numpy: 1.796429991722107|  0:00:00s\n",
      "epoch 12 | loss: 1.63449 | val_0_unsup_loss_numpy: 1.7627500295639038|  0:00:01s\n",
      "epoch 13 | loss: 1.51899 | val_0_unsup_loss_numpy: 1.9949500560760498|  0:00:01s\n",
      "epoch 14 | loss: 1.44518 | val_0_unsup_loss_numpy: 1.5119400024414062|  0:00:01s\n",
      "epoch 15 | loss: 1.39122 | val_0_unsup_loss_numpy: 1.4872599840164185|  0:00:01s\n",
      "epoch 16 | loss: 1.34404 | val_0_unsup_loss_numpy: 1.4131900072097778|  0:00:01s\n",
      "epoch 17 | loss: 1.30441 | val_0_unsup_loss_numpy: 1.5671700239181519|  0:00:01s\n",
      "epoch 18 | loss: 1.27796 | val_0_unsup_loss_numpy: 1.302340030670166|  0:00:01s\n",
      "epoch 19 | loss: 1.25    | val_0_unsup_loss_numpy: 1.3090300559997559|  0:00:01s\n",
      "epoch 20 | loss: 1.21098 | val_0_unsup_loss_numpy: 1.2858999967575073|  0:00:01s\n",
      "epoch 21 | loss: 1.18391 | val_0_unsup_loss_numpy: 1.2177200317382812|  0:00:01s\n",
      "epoch 22 | loss: 1.15883 | val_0_unsup_loss_numpy: 1.211210012435913|  0:00:01s\n",
      "epoch 23 | loss: 1.14546 | val_0_unsup_loss_numpy: 1.2125500440597534|  0:00:01s\n",
      "epoch 24 | loss: 1.1215  | val_0_unsup_loss_numpy: 1.1505299806594849|  0:00:01s\n",
      "epoch 25 | loss: 1.11265 | val_0_unsup_loss_numpy: 1.1218899488449097|  0:00:02s\n",
      "epoch 26 | loss: 1.10624 | val_0_unsup_loss_numpy: 1.123420000076294|  0:00:02s\n",
      "epoch 27 | loss: 1.09593 | val_0_unsup_loss_numpy: 1.1259000301361084|  0:00:02s\n",
      "epoch 28 | loss: 1.08821 | val_0_unsup_loss_numpy: 1.1205099821090698|  0:00:02s\n",
      "epoch 29 | loss: 1.0727  | val_0_unsup_loss_numpy: 1.1028900146484375|  0:00:02s\n",
      "epoch 30 | loss: 1.0707  | val_0_unsup_loss_numpy: 1.0907000303268433|  0:00:02s\n",
      "epoch 31 | loss: 1.06635 | val_0_unsup_loss_numpy: 1.111109972000122|  0:00:02s\n",
      "epoch 32 | loss: 1.05221 | val_0_unsup_loss_numpy: 1.0656499862670898|  0:00:02s\n",
      "epoch 33 | loss: 1.05739 | val_0_unsup_loss_numpy: 1.0675100088119507|  0:00:02s\n",
      "epoch 34 | loss: 1.04365 | val_0_unsup_loss_numpy: 1.069350004196167|  0:00:02s\n",
      "epoch 35 | loss: 1.03473 | val_0_unsup_loss_numpy: 1.0588300228118896|  0:00:02s\n",
      "epoch 36 | loss: 1.03651 | val_0_unsup_loss_numpy: 1.0447100400924683|  0:00:02s\n",
      "epoch 37 | loss: 1.02268 | val_0_unsup_loss_numpy: 1.0514800548553467|  0:00:02s\n",
      "epoch 38 | loss: 1.02735 | val_0_unsup_loss_numpy: 1.045009970664978|  0:00:03s\n",
      "epoch 39 | loss: 1.01474 | val_0_unsup_loss_numpy: 1.0263299942016602|  0:00:03s\n",
      "epoch 40 | loss: 1.01171 | val_0_unsup_loss_numpy: 1.0257400274276733|  0:00:03s\n",
      "epoch 41 | loss: 1.00894 | val_0_unsup_loss_numpy: 1.0260000228881836|  0:00:03s\n",
      "epoch 42 | loss: 0.99731 | val_0_unsup_loss_numpy: 1.0157099962234497|  0:00:03s\n",
      "epoch 43 | loss: 1.00084 | val_0_unsup_loss_numpy: 1.0124499797821045|  0:00:03s\n",
      "epoch 44 | loss: 1.005   | val_0_unsup_loss_numpy: 1.01364004611969|  0:00:03s\n",
      "epoch 45 | loss: 0.99988 | val_0_unsup_loss_numpy: 0.9991899728775024|  0:00:03s\n",
      "epoch 46 | loss: 0.99512 | val_0_unsup_loss_numpy: 1.0118199586868286|  0:00:03s\n",
      "epoch 47 | loss: 0.99099 | val_0_unsup_loss_numpy: 1.0016100406646729|  0:00:03s\n",
      "epoch 48 | loss: 0.99909 | val_0_unsup_loss_numpy: 1.0049500465393066|  0:00:03s\n",
      "epoch 49 | loss: 0.98963 | val_0_unsup_loss_numpy: 1.0043699741363525|  0:00:03s\n",
      "epoch 50 | loss: 0.99888 | val_0_unsup_loss_numpy: 1.0029000043869019|  0:00:04s\n",
      "epoch 51 | loss: 0.98739 | val_0_unsup_loss_numpy: 0.9940400123596191|  0:00:04s\n",
      "epoch 52 | loss: 0.98404 | val_0_unsup_loss_numpy: 0.9850599765777588|  0:00:04s\n",
      "epoch 53 | loss: 0.984   | val_0_unsup_loss_numpy: 0.9848700165748596|  0:00:04s\n",
      "epoch 54 | loss: 0.98192 | val_0_unsup_loss_numpy: 0.9857199788093567|  0:00:04s\n",
      "epoch 55 | loss: 0.98089 | val_0_unsup_loss_numpy: 0.9850599765777588|  0:00:04s\n",
      "epoch 56 | loss: 0.97912 | val_0_unsup_loss_numpy: 0.9882500171661377|  0:00:04s\n",
      "epoch 57 | loss: 0.98011 | val_0_unsup_loss_numpy: 0.9759299755096436|  0:00:04s\n",
      "epoch 58 | loss: 0.9789  | val_0_unsup_loss_numpy: 0.9830600023269653|  0:00:04s\n",
      "epoch 59 | loss: 0.97355 | val_0_unsup_loss_numpy: 0.9761899709701538|  0:00:04s\n",
      "epoch 60 | loss: 0.97428 | val_0_unsup_loss_numpy: 0.9904999732971191|  0:00:04s\n",
      "epoch 61 | loss: 0.98383 | val_0_unsup_loss_numpy: 0.9823700189590454|  0:00:04s\n",
      "epoch 62 | loss: 0.97817 | val_0_unsup_loss_numpy: 0.9650899767875671|  0:00:04s\n",
      "epoch 63 | loss: 0.97309 | val_0_unsup_loss_numpy: 0.9642800092697144|  0:00:05s\n",
      "epoch 64 | loss: 0.97141 | val_0_unsup_loss_numpy: 0.986810028553009|  0:00:05s\n",
      "epoch 65 | loss: 0.97071 | val_0_unsup_loss_numpy: 0.96697998046875|  0:00:05s\n",
      "epoch 66 | loss: 0.97301 | val_0_unsup_loss_numpy: 0.9680699706077576|  0:00:05s\n",
      "epoch 67 | loss: 0.97055 | val_0_unsup_loss_numpy: 0.972350001335144|  0:00:05s\n",
      "epoch 68 | loss: 0.96473 | val_0_unsup_loss_numpy: 0.9650099873542786|  0:00:05s\n",
      "epoch 69 | loss: 0.96914 | val_0_unsup_loss_numpy: 0.9552800059318542|  0:00:05s\n",
      "epoch 70 | loss: 0.96525 | val_0_unsup_loss_numpy: 0.9734399914741516|  0:00:05s\n",
      "epoch 71 | loss: 0.96533 | val_0_unsup_loss_numpy: 0.9809100031852722|  0:00:05s\n",
      "epoch 72 | loss: 0.97048 | val_0_unsup_loss_numpy: 0.9634400010108948|  0:00:05s\n",
      "epoch 73 | loss: 0.96617 | val_0_unsup_loss_numpy: 0.9730799794197083|  0:00:05s\n",
      "epoch 74 | loss: 0.96272 | val_0_unsup_loss_numpy: 0.9685199856758118|  0:00:05s\n",
      "epoch 75 | loss: 0.96039 | val_0_unsup_loss_numpy: 0.9593600034713745|  0:00:05s\n",
      "epoch 76 | loss: 0.96143 | val_0_unsup_loss_numpy: 0.9463300108909607|  0:00:06s\n",
      "epoch 77 | loss: 0.96383 | val_0_unsup_loss_numpy: 0.9765400290489197|  0:00:06s\n",
      "epoch 78 | loss: 0.97606 | val_0_unsup_loss_numpy: 0.9568600058555603|  0:00:06s\n",
      "epoch 79 | loss: 0.96915 | val_0_unsup_loss_numpy: 0.9647700190544128|  0:00:06s\n",
      "epoch 80 | loss: 0.96555 | val_0_unsup_loss_numpy: 0.9445400238037109|  0:00:06s\n",
      "epoch 81 | loss: 0.95857 | val_0_unsup_loss_numpy: 0.9456700086593628|  0:00:06s\n",
      "epoch 82 | loss: 0.96427 | val_0_unsup_loss_numpy: 0.9650200009346008|  0:00:06s\n",
      "epoch 83 | loss: 0.9583  | val_0_unsup_loss_numpy: 0.9456499814987183|  0:00:06s\n",
      "epoch 84 | loss: 0.96808 | val_0_unsup_loss_numpy: 0.9491999745368958|  0:00:06s\n",
      "epoch 85 | loss: 0.96153 | val_0_unsup_loss_numpy: 0.9511299729347229|  0:00:06s\n",
      "epoch 86 | loss: 0.96021 | val_0_unsup_loss_numpy: 0.9539499878883362|  0:00:06s\n",
      "epoch 87 | loss: 0.96171 | val_0_unsup_loss_numpy: 0.9549999833106995|  0:00:06s\n",
      "epoch 88 | loss: 0.95641 | val_0_unsup_loss_numpy: 0.9601699709892273|  0:00:07s\n",
      "epoch 89 | loss: 0.96032 | val_0_unsup_loss_numpy: 0.9428099989891052|  0:00:07s\n",
      "epoch 90 | loss: 0.96001 | val_0_unsup_loss_numpy: 0.9647700190544128|  0:00:07s\n",
      "epoch 91 | loss: 0.95858 | val_0_unsup_loss_numpy: 0.9589099884033203|  0:00:07s\n",
      "epoch 92 | loss: 0.95883 | val_0_unsup_loss_numpy: 0.955020010471344|  0:00:07s\n",
      "epoch 93 | loss: 0.9564  | val_0_unsup_loss_numpy: 0.9629700183868408|  0:00:07s\n",
      "epoch 94 | loss: 0.95025 | val_0_unsup_loss_numpy: 0.9639300107955933|  0:00:07s\n",
      "epoch 95 | loss: 0.96131 | val_0_unsup_loss_numpy: 0.9481800198554993|  0:00:07s\n",
      "epoch 96 | loss: 0.95911 | val_0_unsup_loss_numpy: 0.9464499950408936|  0:00:07s\n",
      "epoch 97 | loss: 0.94941 | val_0_unsup_loss_numpy: 0.9595000147819519|  0:00:07s\n",
      "epoch 98 | loss: 0.95879 | val_0_unsup_loss_numpy: 0.9399999976158142|  0:00:07s\n",
      "epoch 99 | loss: 0.9589  | val_0_unsup_loss_numpy: 0.9376000165939331|  0:00:07s\n",
      "epoch 100| loss: 0.95281 | val_0_unsup_loss_numpy: 0.9349799752235413|  0:00:07s\n",
      "Stop training because you reached max_epochs = 101 with best_epoch = 100 and best_val_0_unsup_loss_numpy = 0.9349799752235413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "tabnet_params = {\n",
    "    \"n_d\": 16,\n",
    "    \"n_a\": 16,\n",
    "    \"n_steps\": 3,\n",
    "    \"n_shared\": 2,\n",
    "    \"n_independent\": 2,\n",
    "    \"gamma\": 1.3,\n",
    "    \"epsilon\": 1e-15,\n",
    "    \"momentum\": 0.98,\n",
    "    \"mask_type\": \"sparsemax\",\n",
    "    \"lambda_sparse\": 1e-3\n",
    "}\n",
    "\n",
    "\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    **tabnet_params\n",
    ")\n",
    " \n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train,\n",
    "    eval_set=[X_test],  \n",
    "    pretraining_ratio=0.8,\n",
    "    max_epochs=101,\n",
    "    patience=10,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b90ccf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "TabNetPretraining                                            [1022, 39]                --\n",
       "├─EmbeddingGenerator: 1-1                                    [1022, 39]                --\n",
       "├─TabNetEncoder: 1-2                                         [1022, 16]                --\n",
       "│    └─BatchNorm1d: 2-1                                      [1022, 39]                78\n",
       "│    └─FeatTransformer: 2-2                                  [1022, 32]                4,352\n",
       "│    │    └─GLU_Block: 3-1                                   [1022, 32]                4,800\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-6                                   [1022, 32]                4,352\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-7                        [1022, 39]                702\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-8                             [1022, 32]                9,152\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-13                       [1022, 39]                702\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-14                            [1022, 32]                9,152\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-19                       [1022, 39]                702\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-20                            [1022, 32]                9,152\n",
       "├─TabNetDecoder: 1-3                                         [1022, 39]                --\n",
       "│    └─ModuleList: 2-13                                      --                        --\n",
       "│    │    └─FeatTransformer: 3-21                            [1022, 16]                1,152\n",
       "│    │    └─FeatTransformer: 3-25                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-23                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-24                            [1022, 16]                1,152\n",
       "│    │    └─FeatTransformer: 3-25                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-26                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-27                            [1022, 16]                1,152\n",
       "│    └─Linear: 2-14                                          [1022, 39]                624\n",
       "==============================================================================================================\n",
       "Total params: 69,560\n",
       "Trainable params: 69,560\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 43.82\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.16\n",
       "Forward/backward pass size (MB): 22.43\n",
       "Params size (MB): 0.11\n",
       "Estimated Total Size (MB): 22.71\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truy cập vào mô hình TabNet bên trong\n",
    "from torchinfo import summary\n",
    "\n",
    "tabnet_model = unsupervised_model.network\n",
    "\n",
    "summary(tabnet_model, input_size=X_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d41dbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tabnet_model.encoder\n",
    "decoder = tabnet_model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0baf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(nn.Module):\n",
    "    def __init__(self, seed=1337):\n",
    "        super(Sampling, self).__init__()\n",
    "        self.seed = seed\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = z_mean.size(0)\n",
    "        dim = z_mean.size(1)\n",
    "        # #print(batch, dim)\n",
    "        epsilon = torch.randn(batch, dim, generator=torch.Generator().manual_seed(self.seed))\n",
    "        return z_mean + torch.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ffbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE_Encoder, self).__init__()\n",
    "        self.tabnet_encoder = tabnet_model.encoder\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(16, 128),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, latent_dim)\n",
    "        )\n",
    "        self.fc_mean = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(latent_dim, latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "\n",
    "    def forward(self, x):\n",
    "        steps_output, _ = self.tabnet_encoder(x)\n",
    "        encoded = steps_output[-1]\n",
    "        # #print(\"Shape of encoded tensor:\", encoded.shape)\n",
    "        encoded = self.mlp(encoded)\n",
    "        z_mean = self.fc_mean(encoded)\n",
    "        z_log_var = self.fc_log_var(encoded)\n",
    "        try:\n",
    "            z = self.sampling((z_mean, z_log_var))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in sampling function: {e}\")\n",
    "            #print(f\"z_mean shape: {z_mean.shape}\")\n",
    "            #print(f\"z_log_var shape: {z_log_var.shape}\")\n",
    "        return z_mean, z_log_var, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56016559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim,encoded_dim, output_dim):\n",
    "        super(VAE_Decoder, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),   \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, encoded_dim),  \n",
    "        )\n",
    "        self.tabnet_decoder = tabnet_model.decoder\n",
    "        self.reshape = nn.Unflatten(1, (encoded_dim,))\n",
    "        self.output_dim=output_dim\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = F.relu(self.mlp(z))\n",
    "\n",
    "        # #print(\"Shape before reshape:\", x.shape)\n",
    "        # x = self.reshape(x)\n",
    "        x = x[None, ...]\n",
    "\n",
    "        # #print(\"Shape after reshape:\", x.shape)\n",
    "        # x = x.view(x.size(0), output_dim)\n",
    "        \n",
    "        output = self.tabnet_decoder(x)\n",
    "        # #print(output.shape)\n",
    "        # #print(\"Shape of output from tabnet_decoder:\", output.shape)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output.view(-1, self.output_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "492bd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from lightning.pytorch import LightningModule, Trainer\n",
    "from torchmetrics import Accuracy, AUROC, F1Score, Precision, Recall\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(LightningModule):\n",
    "    def __init__(self, encoder, decoder, classifier, loss, learning_rate=1e-3):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.classifier = classifier\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss = loss\n",
    "\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        self.val_auroc = AUROC(task=\"multiclass\", num_classes=2)\n",
    "        self.val_f1 = F1Score(task=\"multiclass\", num_classes=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_mean, z_log_var, z = self.encoder(x)\n",
    "        # #print(\"Shape after encoder:\", z.shape)\n",
    "\n",
    "        reconstruction = self.decoder(z)\n",
    "        # #print(\"Shape after decoder:\", reconstruction.shape)\n",
    "\n",
    "        return reconstruction, z_mean, z_log_var, z\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        # z_mean, z_log_var, z = self.encoder(data)\n",
    "        # reconstruction = self.decoder(z)\n",
    "        #print(\"Shape of data in training_step:\", batch[0].shape)\n",
    "        data, labels = batch\n",
    "        reconstruction, z_mean, z_log_var, z = self.forward(data)\n",
    "        #print(\"Shape of reconstruction in training_step:\", reconstruction.shape)\n",
    "        reconstruction_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                F.binary_cross_entropy_with_logits(reconstruction, data, reduction='none'),\n",
    "                dim=1\n",
    "                # dim=(1, 2)\n",
    "                )  # Tính tổng trên chiều (1, 2)\n",
    "        )\n",
    "        #print(\"Shape of reconstruction_loss:\", reconstruction_loss.shape)\n",
    "        preds_logit = self.classifier(z)\n",
    "        #print(\"Shape of preds_logit in validation_step:\", preds_logit.shape)\n",
    "        #print(\"Shape of reconstruction in validation_step:\", reconstruction.shape)\n",
    "        #print(\"Shape of data in validation_step:\", data.shape)\n",
    "        #print(\"Shape of labels in validation_step:\", labels.shape)\n",
    "        classification_loss = self.loss(preds_logit, labels.long())\n",
    "        probs = F.softmax(preds_logit, dim=1)\n",
    "        #print(\"Shape of probs:\", probs.shape)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        #print(\"Shape of preds after argmax:\", preds.shape)\n",
    "        #print(data.dtype, preds.dtype, probs.dtype)  # Chọn lớp có xác suất cao nhất\n",
    "\n",
    "\n",
    "        kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=1)\n",
    "        kl_loss = torch.mean(torch.sum(kl_loss))\n",
    "        vae_loss = reconstruction_loss + kl_loss\n",
    "        total_loss = vae_loss + classification_loss\n",
    "\n",
    "        self.log('train_loss', total_loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return total_loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, labels = batch\n",
    "        reconstruction, z_mean, z_log_var, z = self.forward(data)\n",
    "        preds_logit = self.classifier(z)\n",
    "        #print(\"Shape of preds_logit in validation_step:\", preds_logit.shape)\n",
    "        #print(\"Shape of reconstruction in validation_step:\", reconstruction.shape)\n",
    "        #print(\"Shape of data in validation_step:\", data.shape)\n",
    "        #print(\"Shape of labels in validation_step:\", labels.shape)\n",
    "        classification_loss = self.loss(preds_logit, labels.long())\n",
    "        probs = F.softmax(preds_logit, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "        \n",
    "        reconstruction, z_mean, z_log_var, z = self.forward(data)\n",
    "        reconstruction_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                F.binary_cross_entropy_with_logits(reconstruction, data, reduction='none'),\n",
    "                dim=1\n",
    "                # dim=(1, 2)\n",
    "                )  # Tính tổng trên chiều (1, 2)\n",
    "        )\n",
    "\n",
    "        kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=1)\n",
    "        kl_loss = torch.mean(torch.sum(kl_loss))\n",
    "        vae_loss = reconstruction_loss + kl_loss\n",
    "        total_loss = vae_loss + classification_loss\n",
    "        acc = self.val_accuracy(preds, labels)\n",
    "        auroc = self.val_auroc(probs, labels)\n",
    "        f1 = self.val_f1(preds, labels)\n",
    "\n",
    "        # Logging\n",
    "        self.log('val_loss', total_loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        self.log('val_auroc', auroc, prog_bar=True)\n",
    "        self.log('val_f1', f1, prog_bar=True)\n",
    "\n",
    "        return total_loss\n",
    "     \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = {\n",
    "            'scheduler': ReduceLROnPlateau(optimizer, mode='max', factor=0.95, patience=10, min_lr=1e-6, verbose=True),\n",
    "            'monitor': 'val_acc',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1,\n",
    "        }\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "384702b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, latent_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, 64)  # Layer đầu tiên\n",
    "        self.fc2 = nn.Linear(64, num_classes)  # Output layer: num_classes nodes\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = F.relu(self.fc1(z))  # Activation ReLU\n",
    "        x = self.fc2(x)          # Logits (chưa áp dụng softmax)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89162f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "encoded_dim = 16\n",
    "output_dim = X_train.shape[1]\n",
    "input_dim = X_train.shape[1]\n",
    "#print(input_dim)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc',\n",
    "    # min_delta=0.00005,\n",
    "    patience=60,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    filename='best_model',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "VAE_Encoder                                                  [1022, 64]                --\n",
       "├─TabNetEncoder: 1-1                                         [1022, 16]                --\n",
       "│    └─BatchNorm1d: 2-1                                      [1022, 39]                78\n",
       "│    └─FeatTransformer: 2-2                                  [1022, 32]                4,352\n",
       "│    │    └─GLU_Block: 3-1                                   [1022, 32]                4,800\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-6                                   [1022, 32]                4,352\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-7                        [1022, 39]                702\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-8                             [1022, 32]                9,152\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-13                       [1022, 39]                702\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-14                            [1022, 32]                9,152\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-19                       [1022, 39]                702\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-20                            [1022, 32]                9,152\n",
       "├─Sequential: 1-2                                            [1022, 64]                --\n",
       "│    └─Linear: 2-13                                          [1022, 128]               2,176\n",
       "│    └─ReLU: 2-14                                            [1022, 128]               --\n",
       "│    └─Linear: 2-15                                          [1022, 128]               16,512\n",
       "│    └─ReLU: 2-16                                            [1022, 128]               --\n",
       "│    └─Linear: 2-17                                          [1022, 96]                12,384\n",
       "│    └─ReLU: 2-18                                            [1022, 96]                --\n",
       "│    └─Linear: 2-19                                          [1022, 64]                6,208\n",
       "├─Linear: 1-3                                                [1022, 64]                4,160\n",
       "├─Linear: 1-4                                                [1022, 64]                4,160\n",
       "├─Sampling: 1-5                                              [1022, 64]                --\n",
       "==============================================================================================================\n",
       "Total params: 109,288\n",
       "Trainable params: 109,288\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 86.25\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.16\n",
       "Forward/backward pass size (MB): 23.42\n",
       "Params size (MB): 0.28\n",
       "Estimated Total Size (MB): 23.87\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_encoder = VAE_Encoder(latent_dim=latent_dim)\n",
    "#print(\"Encoder Summary:\")\n",
    "summary(vae_encoder, input_size=(1022, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dc46dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shape: torch.Size([800, 16])\n",
      "Shape of encoder output: [torch.Size([800, 16]), torch.Size([800, 16]), torch.Size([800, 16])]\n",
      "Decoder shape: torch.Size([800, 39])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(800, 39) \n",
    "steps_output, _ = tabnet_model.encoder(x)\n",
    "encoded = steps_output[-1]\n",
    "#print(f\"Encoded shape: {encoded.shape}\")\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.randn(800, 39)  \n",
    "\n",
    "steps_output, _ = tabnet_model.encoder(x)\n",
    "#print(\"Shape of encoder output:\", [output.shape for output in steps_output])\n",
    "\n",
    "decoder_input = steps_output[-1] \n",
    "decoder_input = decoder_input[None, ...]\n",
    "try:\n",
    "    decoder_output = tabnet_model.decoder(decoder_input)\n",
    "    #print(f\"Decoder shape: {decoder_output.shape}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06afebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "VAE_Decoder                                                  [700, 39]                 --\n",
       "├─Sequential: 1-1                                            [700, 16]                 --\n",
       "│    └─Linear: 2-1                                           [700, 32]                 2,080\n",
       "│    └─ReLU: 2-2                                             [700, 32]                 --\n",
       "│    └─Linear: 2-3                                           [700, 96]                 3,168\n",
       "│    └─ReLU: 2-4                                             [700, 96]                 --\n",
       "│    └─Linear: 2-5                                           [700, 96]                 9,312\n",
       "│    └─ReLU: 2-6                                             [700, 96]                 --\n",
       "│    └─Linear: 2-7                                           [700, 16]                 1,552\n",
       "├─TabNetDecoder: 1-2                                         [700, 39]                 --\n",
       "│    └─ModuleList: 2-8                                       --                        --\n",
       "│    │    └─FeatTransformer: 3-1                             [700, 16]                 1,152\n",
       "│    │    └─FeatTransformer: 3-2                             --                        1,152\n",
       "│    │    └─FeatTransformer: 3-3                             --                        (recursive)\n",
       "│    └─Linear: 2-9                                           [700, 39]                 624\n",
       "==============================================================================================================\n",
       "Total params: 19,680\n",
       "Trainable params: 19,680\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 12.52\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.18\n",
       "Forward/backward pass size (MB): 2.28\n",
       "Params size (MB): 0.07\n",
       "Estimated Total Size (MB): 2.53\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_decoder = VAE_Decoder(latent_dim=latent_dim, encoded_dim=encoded_dim, output_dim=output_dim)\n",
    "#print(\"Decoder Summary:\")\n",
    "summary(vae_decoder, input_size=(700, latent_dim), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345d90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                                            Output Shape              Param #\n",
       "===================================================================================================================\n",
       "VAE                                                               [700, 39]                 4,290\n",
       "├─VAE_Encoder: 1-1                                                [700, 64]                 --\n",
       "│    └─TabNetEncoder: 2-1                                         [700, 16]                 --\n",
       "│    │    └─BatchNorm1d: 3-1                                      [700, 39]                 78\n",
       "│    │    └─FeatTransformer: 3-2                                  [700, 32]                 9,152\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-6                                  --                        (recursive)\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-6                                  --                        (recursive)\n",
       "│    │    └─ModuleList: 3-11                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-11                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-11                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    └─Sequential: 2-2                                            [700, 64]                 --\n",
       "│    │    └─Linear: 3-13                                          [700, 128]                2,176\n",
       "│    │    └─ReLU: 3-14                                            [700, 128]                --\n",
       "│    │    └─Linear: 3-15                                          [700, 128]                16,512\n",
       "│    │    └─ReLU: 3-16                                            [700, 128]                --\n",
       "│    │    └─Linear: 3-17                                          [700, 96]                 12,384\n",
       "│    │    └─ReLU: 3-18                                            [700, 96]                 --\n",
       "│    │    └─Linear: 3-19                                          [700, 64]                 6,208\n",
       "│    └─Linear: 2-3                                                [700, 64]                 4,160\n",
       "│    └─Linear: 2-4                                                [700, 64]                 4,160\n",
       "│    └─Sampling: 2-5                                              [700, 64]                 --\n",
       "├─VAE_Decoder: 1-2                                                [700, 39]                 --\n",
       "│    └─Sequential: 2-6                                            [700, 16]                 --\n",
       "│    │    └─Linear: 3-20                                          [700, 32]                 2,080\n",
       "│    │    └─ReLU: 3-21                                            [700, 32]                 --\n",
       "│    │    └─Linear: 3-22                                          [700, 96]                 3,168\n",
       "│    │    └─ReLU: 3-23                                            [700, 96]                 --\n",
       "│    │    └─Linear: 3-24                                          [700, 96]                 9,312\n",
       "│    │    └─ReLU: 3-25                                            [700, 96]                 --\n",
       "│    │    └─Linear: 3-26                                          [700, 16]                 1,552\n",
       "│    └─TabNetDecoder: 2-7                                         [700, 39]                 --\n",
       "│    │    └─ModuleList: 3-27                                      --                        2,432\n",
       "│    │    └─Linear: 3-28                                          [700, 39]                 624\n",
       "===================================================================================================================\n",
       "Total params: 133,258\n",
       "Trainable params: 133,258\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 71.60\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 18.32\n",
       "Params size (MB): 0.35\n",
       "Estimated Total Size (MB): 18.79\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "learning_rate=0.0001\n",
    "classifier = SimpleClassifier(latent_dim, num_classes=2)\n",
    "vae = VAE(encoder=vae_encoder, decoder=vae_decoder, classifier=classifier, loss=criterion, learning_rate=learning_rate)\n",
    "summary(vae, input_size=(700, input_dim), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467dd58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "\n",
      "  | Name         | Type               | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | encoder      | VAE_Encoder        | 70.8 K | train\n",
      "1 | decoder      | VAE_Decoder        | 19.2 K | train\n",
      "2 | classifier   | SimpleClassifier   | 4.3 K  | train\n",
      "3 | loss         | CrossEntropyLoss   | 0      | train\n",
      "4 | val_accuracy | MulticlassAccuracy | 0      | train\n",
      "5 | val_auroc    | MulticlassAUROC    | 0      | train\n",
      "6 | val_f1       | MulticlassF1Score  | 0      | train\n",
      "------------------------------------------------------------\n",
      "94.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "94.2 K    Total params\n",
      "0.377     Total estimated model params size (MB)\n",
      "168       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00, 34.47it/s]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/16 [00:00<?, ?it/s] Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:   6%|▋         | 1/16 [00:00<00:00, 35.70it/s, v_num=16, train_loss_step=6.670]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  12%|█▎        | 2/16 [00:00<00:00, 36.02it/s, v_num=16, train_loss_step=2.700]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  19%|█▉        | 3/16 [00:00<00:00, 37.73it/s, v_num=16, train_loss_step=3.210]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  25%|██▌       | 4/16 [00:00<00:00, 36.52it/s, v_num=16, train_loss_step=4.600]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  31%|███▏      | 5/16 [00:00<00:00, 36.36it/s, v_num=16, train_loss_step=3.640]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  38%|███▊      | 6/16 [00:00<00:00, 36.80it/s, v_num=16, train_loss_step=3.110]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  44%|████▍     | 7/16 [00:00<00:00, 37.43it/s, v_num=16, train_loss_step=6.420]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  50%|█████     | 8/16 [00:00<00:00, 37.55it/s, v_num=16, train_loss_step=4.250]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  56%|█████▋    | 9/16 [00:00<00:00, 37.57it/s, v_num=16, train_loss_step=0.812]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  62%|██████▎   | 10/16 [00:00<00:00, 37.24it/s, v_num=16, train_loss_step=5.790]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  69%|██████▉   | 11/16 [00:00<00:00, 36.97it/s, v_num=16, train_loss_step=3.220]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  75%|███████▌  | 12/16 [00:00<00:00, 37.32it/s, v_num=16, train_loss_step=-0.13]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  81%|████████▏ | 13/16 [00:00<00:00, 37.46it/s, v_num=16, train_loss_step=1.790]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  88%|████████▊ | 14/16 [00:00<00:00, 37.43it/s, v_num=16, train_loss_step=2.020]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0:  94%|█████████▍| 15/16 [00:00<00:00, 37.40it/s, v_num=16, train_loss_step=0.580]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 0: 100%|██████████| 16/16 [00:00<00:00, 37.82it/s, v_num=16, train_loss_step=0.623]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 0: 100%|██████████| 16/16 [00:00<00:00, 28.28it/s, v_num=16, train_loss_step=0.623, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved. New best score: 0.406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=0.623, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:   6%|▋         | 1/16 [00:00<00:00, 29.84it/s, v_num=16, train_loss_step=2.150, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  12%|█▎        | 2/16 [00:00<00:00, 30.07it/s, v_num=16, train_loss_step=1.730, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  19%|█▉        | 3/16 [00:00<00:00, 32.43it/s, v_num=16, train_loss_step=-2.34, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  25%|██▌       | 4/16 [00:00<00:00, 34.04it/s, v_num=16, train_loss_step=0.221, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  31%|███▏      | 5/16 [00:00<00:00, 34.24it/s, v_num=16, train_loss_step=2.740, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  38%|███▊      | 6/16 [00:00<00:00, 35.08it/s, v_num=16, train_loss_step=-1.74, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  44%|████▍     | 7/16 [00:00<00:00, 35.71it/s, v_num=16, train_loss_step=-0.213, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  50%|█████     | 8/16 [00:00<00:00, 35.87it/s, v_num=16, train_loss_step=-3.09, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090] Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  56%|█████▋    | 9/16 [00:00<00:00, 35.92it/s, v_num=16, train_loss_step=-1.62, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  62%|██████▎   | 10/16 [00:00<00:00, 35.65it/s, v_num=16, train_loss_step=-2.82, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  69%|██████▉   | 11/16 [00:00<00:00, 35.77it/s, v_num=16, train_loss_step=-3.00, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  75%|███████▌  | 12/16 [00:00<00:00, 35.44it/s, v_num=16, train_loss_step=-2.37, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  81%|████████▏ | 13/16 [00:00<00:00, 35.74it/s, v_num=16, train_loss_step=-3.31, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  88%|████████▊ | 14/16 [00:00<00:00, 35.47it/s, v_num=16, train_loss_step=-3.15, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1:  94%|█████████▍| 15/16 [00:00<00:00, 35.48it/s, v_num=16, train_loss_step=1.330, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 1: 100%|██████████| 16/16 [00:00<00:00, 35.38it/s, v_num=16, train_loss_step=-4.09, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 1: 100%|██████████| 16/16 [00:00<00:00, 26.66it/s, v_num=16, train_loss_step=-4.09, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.027 >= min_delta = 0.0. New best score: 0.379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-4.09, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:   6%|▋         | 1/16 [00:00<00:00, 33.88it/s, v_num=16, train_loss_step=-7.86, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  12%|█▎        | 2/16 [00:00<00:00, 34.18it/s, v_num=16, train_loss_step=-4.36, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  19%|█▉        | 3/16 [00:00<00:00, 33.15it/s, v_num=16, train_loss_step=-0.417, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  25%|██▌       | 4/16 [00:00<00:00, 33.67it/s, v_num=16, train_loss_step=-3.95, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22] Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  31%|███▏      | 5/16 [00:00<00:00, 34.51it/s, v_num=16, train_loss_step=-4.43, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  38%|███▊      | 6/16 [00:00<00:00, 35.32it/s, v_num=16, train_loss_step=-1.95, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  44%|████▍     | 7/16 [00:00<00:00, 35.74it/s, v_num=16, train_loss_step=-3.89, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  50%|█████     | 8/16 [00:00<00:00, 35.81it/s, v_num=16, train_loss_step=-3.42, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  56%|█████▋    | 9/16 [00:00<00:00, 36.23it/s, v_num=16, train_loss_step=-4.50, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  62%|██████▎   | 10/16 [00:00<00:00, 35.89it/s, v_num=16, train_loss_step=-3.74, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  69%|██████▉   | 11/16 [00:00<00:00, 35.88it/s, v_num=16, train_loss_step=-7.94, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  75%|███████▌  | 12/16 [00:00<00:00, 35.49it/s, v_num=16, train_loss_step=-4.79, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  81%|████████▏ | 13/16 [00:00<00:00, 35.90it/s, v_num=16, train_loss_step=-3.62, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  88%|████████▊ | 14/16 [00:00<00:00, 35.89it/s, v_num=16, train_loss_step=-6.53, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2:  94%|█████████▍| 15/16 [00:00<00:00, 35.87it/s, v_num=16, train_loss_step=-4.06, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 2: 100%|██████████| 16/16 [00:00<00:00, 36.31it/s, v_num=16, train_loss_step=-7.46, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 2: 100%|██████████| 16/16 [00:00<00:00, 27.58it/s, v_num=16, train_loss_step=-7.46, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.070 >= min_delta = 0.0. New best score: 0.309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-7.46, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:   6%|▋         | 1/16 [00:00<00:00, 29.41it/s, v_num=16, train_loss_step=-5.67, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  12%|█▎        | 2/16 [00:00<00:00, 31.23it/s, v_num=16, train_loss_step=-4.92, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  19%|█▉        | 3/16 [00:00<00:00, 27.02it/s, v_num=16, train_loss_step=-8.24, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  25%|██▌       | 4/16 [00:00<00:00, 28.26it/s, v_num=16, train_loss_step=-7.95, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  31%|███▏      | 5/16 [00:00<00:00, 30.02it/s, v_num=16, train_loss_step=-8.77, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  38%|███▊      | 6/16 [00:00<00:00, 30.75it/s, v_num=16, train_loss_step=-3.57, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  44%|████▍     | 7/16 [00:00<00:00, 31.68it/s, v_num=16, train_loss_step=-7.51, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  50%|█████     | 8/16 [00:00<00:00, 31.73it/s, v_num=16, train_loss_step=-5.61, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  56%|█████▋    | 9/16 [00:00<00:00, 32.29it/s, v_num=16, train_loss_step=-7.81, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  62%|██████▎   | 10/16 [00:00<00:00, 32.82it/s, v_num=16, train_loss_step=-9.42, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  69%|██████▉   | 11/16 [00:00<00:00, 33.11it/s, v_num=16, train_loss_step=-9.45, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  75%|███████▌  | 12/16 [00:00<00:00, 33.26it/s, v_num=16, train_loss_step=-7.48, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  81%|████████▏ | 13/16 [00:00<00:00, 33.53it/s, v_num=16, train_loss_step=-9.58, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  88%|████████▊ | 14/16 [00:00<00:00, 33.35it/s, v_num=16, train_loss_step=-8.22, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3:  94%|█████████▍| 15/16 [00:00<00:00, 33.29it/s, v_num=16, train_loss_step=-6.73, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 3: 100%|██████████| 16/16 [00:00<00:00, 33.64it/s, v_num=16, train_loss_step=-8.39, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 3: 100%|██████████| 16/16 [00:00<00:00, 25.74it/s, v_num=16, train_loss_step=-8.39, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.012 >= min_delta = 0.0. New best score: 0.297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-8.39, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:   6%|▋         | 1/16 [00:00<00:00, 35.50it/s, v_num=16, train_loss_step=-10.2, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  12%|█▎        | 2/16 [00:00<00:00, 35.94it/s, v_num=16, train_loss_step=-9.52, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  19%|█▉        | 3/16 [00:00<00:00, 34.63it/s, v_num=16, train_loss_step=-7.60, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  25%|██▌       | 4/16 [00:00<00:00, 34.44it/s, v_num=16, train_loss_step=-5.60, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  31%|███▏      | 5/16 [00:00<00:00, 35.17it/s, v_num=16, train_loss_step=-8.81, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  38%|███▊      | 6/16 [00:00<00:00, 34.85it/s, v_num=16, train_loss_step=-11.5, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  44%|████▍     | 7/16 [00:00<00:00, 35.15it/s, v_num=16, train_loss_step=-12.3, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  50%|█████     | 8/16 [00:00<00:00, 34.76it/s, v_num=16, train_loss_step=-10.9, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  56%|█████▋    | 9/16 [00:00<00:00, 34.46it/s, v_num=16, train_loss_step=-10.0, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  62%|██████▎   | 10/16 [00:00<00:00, 34.58it/s, v_num=16, train_loss_step=-9.86, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  69%|██████▉   | 11/16 [00:00<00:00, 35.12it/s, v_num=16, train_loss_step=-8.64, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  75%|███████▌  | 12/16 [00:00<00:00, 35.44it/s, v_num=16, train_loss_step=-10.4, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  81%|████████▏ | 13/16 [00:00<00:00, 35.95it/s, v_num=16, train_loss_step=-11.1, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  88%|████████▊ | 14/16 [00:00<00:00, 36.03it/s, v_num=16, train_loss_step=-9.42, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4:  94%|█████████▍| 15/16 [00:00<00:00, 36.18it/s, v_num=16, train_loss_step=-11.7, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 4: 100%|██████████| 16/16 [00:00<00:00, 36.68it/s, v_num=16, train_loss_step=-13.6, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 4: 100%|██████████| 16/16 [00:00<00:00, 27.67it/s, v_num=16, train_loss_step=-13.6, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.006 >= min_delta = 0.0. New best score: 0.291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-13.6, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:   6%|▋         | 1/16 [00:00<00:00, 35.71it/s, v_num=16, train_loss_step=-10.5, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  12%|█▎        | 2/16 [00:00<00:00, 33.61it/s, v_num=16, train_loss_step=-13.8, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  19%|█▉        | 3/16 [00:00<00:00, 34.68it/s, v_num=16, train_loss_step=-12.2, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  25%|██▌       | 4/16 [00:00<00:00, 35.87it/s, v_num=16, train_loss_step=-14.5, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  31%|███▏      | 5/16 [00:00<00:00, 36.76it/s, v_num=16, train_loss_step=-8.48, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  38%|███▊      | 6/16 [00:00<00:00, 37.50it/s, v_num=16, train_loss_step=-11.4, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  44%|████▍     | 7/16 [00:00<00:00, 36.84it/s, v_num=16, train_loss_step=-10.9, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  50%|█████     | 8/16 [00:00<00:00, 36.36it/s, v_num=16, train_loss_step=-14.0, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  56%|█████▋    | 9/16 [00:00<00:00, 36.69it/s, v_num=16, train_loss_step=-13.8, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  62%|██████▎   | 10/16 [00:00<00:00, 37.00it/s, v_num=16, train_loss_step=-10.8, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  69%|██████▉   | 11/16 [00:00<00:00, 37.00it/s, v_num=16, train_loss_step=-12.5, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  75%|███████▌  | 12/16 [00:00<00:00, 37.35it/s, v_num=16, train_loss_step=-10.2, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  81%|████████▏ | 13/16 [00:00<00:00, 36.95it/s, v_num=16, train_loss_step=-13.9, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  88%|████████▊ | 14/16 [00:00<00:00, 36.57it/s, v_num=16, train_loss_step=-14.9, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5:  94%|█████████▍| 15/16 [00:00<00:00, 36.25it/s, v_num=16, train_loss_step=-15.2, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 5: 100%|██████████| 16/16 [00:00<00:00, 36.26it/s, v_num=16, train_loss_step=-11.1, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 5: 100%|██████████| 16/16 [00:00<00:00, 27.22it/s, v_num=16, train_loss_step=-11.1, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.003 >= min_delta = 0.0. New best score: 0.288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-11.1, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:   6%|▋         | 1/16 [00:00<00:00, 37.04it/s, v_num=16, train_loss_step=-12.0, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  12%|█▎        | 2/16 [00:00<00:00, 36.03it/s, v_num=16, train_loss_step=-13.0, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  19%|█▉        | 3/16 [00:00<00:00, 36.36it/s, v_num=16, train_loss_step=-11.6, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  25%|██▌       | 4/16 [00:00<00:00, 36.53it/s, v_num=16, train_loss_step=-16.0, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  31%|███▏      | 5/16 [00:00<00:00, 35.84it/s, v_num=16, train_loss_step=-11.7, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  38%|███▊      | 6/16 [00:00<00:00, 35.29it/s, v_num=16, train_loss_step=-15.6, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  44%|████▍     | 7/16 [00:00<00:00, 35.17it/s, v_num=16, train_loss_step=-12.9, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  50%|█████     | 8/16 [00:00<00:00, 34.93it/s, v_num=16, train_loss_step=-15.4, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  56%|█████▋    | 9/16 [00:00<00:00, 34.68it/s, v_num=16, train_loss_step=-14.7, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  62%|██████▎   | 10/16 [00:00<00:00, 35.27it/s, v_num=16, train_loss_step=-12.0, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  69%|██████▉   | 11/16 [00:00<00:00, 35.65it/s, v_num=16, train_loss_step=-12.2, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  75%|███████▌  | 12/16 [00:00<00:00, 35.66it/s, v_num=16, train_loss_step=-17.5, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  81%|████████▏ | 13/16 [00:00<00:00, 35.81it/s, v_num=16, train_loss_step=-13.9, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  88%|████████▊ | 14/16 [00:00<00:00, 35.71it/s, v_num=16, train_loss_step=-16.8, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6:  94%|█████████▍| 15/16 [00:00<00:00, 35.71it/s, v_num=16, train_loss_step=-15.4, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 6: 100%|██████████| 16/16 [00:00<00:00, 36.20it/s, v_num=16, train_loss_step=-15.0, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 6: 100%|██████████| 16/16 [00:00<00:00, 27.43it/s, v_num=16, train_loss_step=-15.0, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.006 >= min_delta = 0.0. New best score: 0.282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-15.0, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:   6%|▋         | 1/16 [00:00<00:00, 30.67it/s, v_num=16, train_loss_step=-15.2, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  12%|█▎        | 2/16 [00:00<00:00, 33.27it/s, v_num=16, train_loss_step=-17.5, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  19%|█▉        | 3/16 [00:00<00:00, 33.10it/s, v_num=16, train_loss_step=-14.8, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  25%|██▌       | 4/16 [00:00<00:00, 33.72it/s, v_num=16, train_loss_step=-18.6, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  31%|███▏      | 5/16 [00:00<00:00, 33.29it/s, v_num=16, train_loss_step=-14.3, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  38%|███▊      | 6/16 [00:00<00:00, 33.96it/s, v_num=16, train_loss_step=-14.5, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  44%|████▍     | 7/16 [00:00<00:00, 33.70it/s, v_num=16, train_loss_step=-14.6, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  50%|█████     | 8/16 [00:00<00:00, 34.23it/s, v_num=16, train_loss_step=-15.7, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  56%|█████▋    | 9/16 [00:00<00:00, 34.32it/s, v_num=16, train_loss_step=-14.1, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  62%|██████▎   | 10/16 [00:00<00:00, 34.34it/s, v_num=16, train_loss_step=-15.4, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  69%|██████▉   | 11/16 [00:00<00:00, 34.46it/s, v_num=16, train_loss_step=-17.6, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  75%|███████▌  | 12/16 [00:00<00:00, 33.69it/s, v_num=16, train_loss_step=-13.5, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  81%|████████▏ | 13/16 [00:00<00:00, 34.06it/s, v_num=16, train_loss_step=-13.9, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  88%|████████▊ | 14/16 [00:00<00:00, 33.92it/s, v_num=16, train_loss_step=-16.3, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7:  94%|█████████▍| 15/16 [00:00<00:00, 33.88it/s, v_num=16, train_loss_step=-14.5, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 7: 100%|██████████| 16/16 [00:00<00:00, 34.10it/s, v_num=16, train_loss_step=-15.0, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 7: 100%|██████████| 16/16 [00:00<00:00, 26.33it/s, v_num=16, train_loss_step=-15.0, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.015 >= min_delta = 0.0. New best score: 0.267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-15.0, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:   6%|▋         | 1/16 [00:00<00:00, 32.26it/s, v_num=16, train_loss_step=-18.1, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  12%|█▎        | 2/16 [00:00<00:00, 33.30it/s, v_num=16, train_loss_step=-16.4, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  19%|█▉        | 3/16 [00:00<00:00, 32.96it/s, v_num=16, train_loss_step=-17.2, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  25%|██▌       | 4/16 [00:00<00:00, 34.48it/s, v_num=16, train_loss_step=-12.9, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  31%|███▏      | 5/16 [00:00<00:00, 35.45it/s, v_num=16, train_loss_step=-18.4, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  38%|███▊      | 6/16 [00:00<00:00, 35.20it/s, v_num=16, train_loss_step=-18.0, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  44%|████▍     | 7/16 [00:00<00:00, 34.92it/s, v_num=16, train_loss_step=-13.6, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  50%|█████     | 8/16 [00:00<00:00, 35.32it/s, v_num=16, train_loss_step=-17.0, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  56%|█████▋    | 9/16 [00:00<00:00, 35.86it/s, v_num=16, train_loss_step=-18.1, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  62%|██████▎   | 10/16 [00:00<00:00, 36.23it/s, v_num=16, train_loss_step=-16.4, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  69%|██████▉   | 11/16 [00:00<00:00, 35.72it/s, v_num=16, train_loss_step=-15.8, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  75%|███████▌  | 12/16 [00:00<00:00, 36.04it/s, v_num=16, train_loss_step=-15.9, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  81%|████████▏ | 13/16 [00:00<00:00, 36.21it/s, v_num=16, train_loss_step=-15.0, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  88%|████████▊ | 14/16 [00:00<00:00, 36.55it/s, v_num=16, train_loss_step=-16.6, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8:  94%|█████████▍| 15/16 [00:00<00:00, 36.32it/s, v_num=16, train_loss_step=-14.2, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 8: 100%|██████████| 16/16 [00:00<00:00, 36.69it/s, v_num=16, train_loss_step=-16.3, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 9:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-16.3, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:   6%|▋         | 1/16 [00:00<00:00, 34.48it/s, v_num=16, train_loss_step=-15.4, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  12%|█▎        | 2/16 [00:00<00:00, 37.74it/s, v_num=16, train_loss_step=-18.4, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  19%|█▉        | 3/16 [00:00<00:00, 36.54it/s, v_num=16, train_loss_step=-19.2, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  25%|██▌       | 4/16 [00:00<00:00, 35.68it/s, v_num=16, train_loss_step=-16.6, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  31%|███▏      | 5/16 [00:00<00:00, 35.94it/s, v_num=16, train_loss_step=-17.6, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  38%|███▊      | 6/16 [00:00<00:00, 34.96it/s, v_num=16, train_loss_step=-15.5, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  44%|████▍     | 7/16 [00:00<00:00, 34.55it/s, v_num=16, train_loss_step=-16.0, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  50%|█████     | 8/16 [00:00<00:00, 34.84it/s, v_num=16, train_loss_step=-15.5, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  56%|█████▋    | 9/16 [00:00<00:00, 34.94it/s, v_num=16, train_loss_step=-18.1, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  62%|██████▎   | 10/16 [00:00<00:00, 34.55it/s, v_num=16, train_loss_step=-19.3, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  69%|██████▉   | 11/16 [00:00<00:00, 34.76it/s, v_num=16, train_loss_step=-16.7, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  75%|███████▌  | 12/16 [00:00<00:00, 34.44it/s, v_num=16, train_loss_step=-16.4, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  81%|████████▏ | 13/16 [00:00<00:00, 34.25it/s, v_num=16, train_loss_step=-16.2, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  88%|████████▊ | 14/16 [00:00<00:00, 34.52it/s, v_num=16, train_loss_step=-18.8, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9:  94%|█████████▍| 15/16 [00:00<00:00, 34.43it/s, v_num=16, train_loss_step=-16.0, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 9: 100%|██████████| 16/16 [00:00<00:00, 34.89it/s, v_num=16, train_loss_step=-12.8, val_loss=-20.2, val_acc=0.267, val_auroc=0.461, val_f1=0.267, train_loss_epoch=-16.2]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 10:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-12.8, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]        Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:   6%|▋         | 1/16 [00:00<00:00, 30.64it/s, v_num=16, train_loss_step=-17.3, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  12%|█▎        | 2/16 [00:00<00:00, 31.93it/s, v_num=16, train_loss_step=-16.6, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  19%|█▉        | 3/16 [00:00<00:00, 30.88it/s, v_num=16, train_loss_step=-20.4, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  25%|██▌       | 4/16 [00:00<00:00, 29.15it/s, v_num=16, train_loss_step=-19.6, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  31%|███▏      | 5/16 [00:00<00:00, 30.82it/s, v_num=16, train_loss_step=-12.6, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  38%|███▊      | 6/16 [00:00<00:00, 31.68it/s, v_num=16, train_loss_step=-15.5, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  44%|████▍     | 7/16 [00:00<00:00, 32.50it/s, v_num=16, train_loss_step=-17.4, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  50%|█████     | 8/16 [00:00<00:00, 33.42it/s, v_num=16, train_loss_step=-18.2, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  56%|█████▋    | 9/16 [00:00<00:00, 33.53it/s, v_num=16, train_loss_step=-17.4, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  62%|██████▎   | 10/16 [00:00<00:00, 33.80it/s, v_num=16, train_loss_step=-16.5, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  69%|██████▉   | 11/16 [00:00<00:00, 34.06it/s, v_num=16, train_loss_step=-13.4, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  75%|███████▌  | 12/16 [00:00<00:00, 34.39it/s, v_num=16, train_loss_step=-17.7, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  81%|████████▏ | 13/16 [00:00<00:00, 34.17it/s, v_num=16, train_loss_step=-18.9, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  88%|████████▊ | 14/16 [00:00<00:00, 34.26it/s, v_num=16, train_loss_step=-18.3, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10:  94%|█████████▍| 15/16 [00:00<00:00, 34.57it/s, v_num=16, train_loss_step=-19.9, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 10: 100%|██████████| 16/16 [00:00<00:00, 35.10it/s, v_num=16, train_loss_step=-14.9, val_loss=-20.6, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-16.8]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 11:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-14.9, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:   6%|▋         | 1/16 [00:00<00:00, 31.25it/s, v_num=16, train_loss_step=-16.0, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  12%|█▎        | 2/16 [00:00<00:00, 31.25it/s, v_num=16, train_loss_step=-16.6, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  19%|█▉        | 3/16 [00:00<00:00, 31.74it/s, v_num=16, train_loss_step=-17.4, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  25%|██▌       | 4/16 [00:00<00:00, 30.89it/s, v_num=16, train_loss_step=-17.3, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  31%|███▏      | 5/16 [00:00<00:00, 31.35it/s, v_num=16, train_loss_step=-17.3, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  38%|███▊      | 6/16 [00:00<00:00, 31.91it/s, v_num=16, train_loss_step=-18.0, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  44%|████▍     | 7/16 [00:00<00:00, 31.65it/s, v_num=16, train_loss_step=-17.2, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  50%|█████     | 8/16 [00:00<00:00, 32.10it/s, v_num=16, train_loss_step=-15.1, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  56%|█████▋    | 9/16 [00:00<00:00, 32.18it/s, v_num=16, train_loss_step=-16.8, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  62%|██████▎   | 10/16 [00:00<00:00, 31.57it/s, v_num=16, train_loss_step=-16.7, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  69%|██████▉   | 11/16 [00:00<00:00, 31.28it/s, v_num=16, train_loss_step=-20.4, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  75%|███████▌  | 12/16 [00:00<00:00, 31.48it/s, v_num=16, train_loss_step=-16.0, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  81%|████████▏ | 13/16 [00:00<00:00, 31.69it/s, v_num=16, train_loss_step=-18.2, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  88%|████████▊ | 14/16 [00:00<00:00, 31.73it/s, v_num=16, train_loss_step=-22.1, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11:  94%|█████████▍| 15/16 [00:00<00:00, 31.90it/s, v_num=16, train_loss_step=-17.2, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 11: 100%|██████████| 16/16 [00:00<00:00, 32.34it/s, v_num=16, train_loss_step=-16.3, val_loss=-20.9, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.2]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 12:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-16.3, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:   6%|▋         | 1/16 [00:00<00:00, 37.03it/s, v_num=16, train_loss_step=-16.5, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  12%|█▎        | 2/16 [00:00<00:00, 37.37it/s, v_num=16, train_loss_step=-15.9, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  19%|█▉        | 3/16 [00:00<00:00, 36.80it/s, v_num=16, train_loss_step=-18.7, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  25%|██▌       | 4/16 [00:00<00:00, 37.91it/s, v_num=16, train_loss_step=-19.3, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  31%|███▏      | 5/16 [00:00<00:00, 38.02it/s, v_num=16, train_loss_step=-16.9, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  38%|███▊      | 6/16 [00:00<00:00, 38.21it/s, v_num=16, train_loss_step=-19.7, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  44%|████▍     | 7/16 [00:00<00:00, 38.67it/s, v_num=16, train_loss_step=-19.1, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  50%|█████     | 8/16 [00:00<00:00, 38.83it/s, v_num=16, train_loss_step=-18.0, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  56%|█████▋    | 9/16 [00:00<00:00, 38.96it/s, v_num=16, train_loss_step=-18.1, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  62%|██████▎   | 10/16 [00:00<00:00, 38.45it/s, v_num=16, train_loss_step=-18.8, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  69%|██████▉   | 11/16 [00:00<00:00, 37.15it/s, v_num=16, train_loss_step=-14.3, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  75%|███████▌  | 12/16 [00:00<00:00, 36.46it/s, v_num=16, train_loss_step=-18.5, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  81%|████████▏ | 13/16 [00:00<00:00, 36.35it/s, v_num=16, train_loss_step=-17.9, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  88%|████████▊ | 14/16 [00:00<00:00, 36.30it/s, v_num=16, train_loss_step=-16.0, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12:  94%|█████████▍| 15/16 [00:00<00:00, 36.09it/s, v_num=16, train_loss_step=-18.4, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 12: 100%|██████████| 16/16 [00:00<00:00, 36.35it/s, v_num=16, train_loss_step=-15.5, val_loss=-21.1, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.4]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 13:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-15.5, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:   6%|▋         | 1/16 [00:00<00:00, 35.71it/s, v_num=16, train_loss_step=-16.3, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  12%|█▎        | 2/16 [00:00<00:00, 38.46it/s, v_num=16, train_loss_step=-16.9, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  19%|█▉        | 3/16 [00:00<00:00, 37.26it/s, v_num=16, train_loss_step=-18.2, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  25%|██▌       | 4/16 [00:00<00:00, 35.55it/s, v_num=16, train_loss_step=-21.5, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  31%|███▏      | 5/16 [00:00<00:00, 35.09it/s, v_num=16, train_loss_step=-18.5, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  38%|███▊      | 6/16 [00:00<00:00, 35.08it/s, v_num=16, train_loss_step=-18.3, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  44%|████▍     | 7/16 [00:00<00:00, 35.53it/s, v_num=16, train_loss_step=-17.2, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  50%|█████     | 8/16 [00:00<00:00, 36.03it/s, v_num=16, train_loss_step=-13.5, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  56%|█████▋    | 9/16 [00:00<00:00, 33.61it/s, v_num=16, train_loss_step=-16.6, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  62%|██████▎   | 10/16 [00:00<00:00, 34.16it/s, v_num=16, train_loss_step=-21.7, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  69%|██████▉   | 11/16 [00:00<00:00, 34.19it/s, v_num=16, train_loss_step=-17.4, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  75%|███████▌  | 12/16 [00:00<00:00, 34.31it/s, v_num=16, train_loss_step=-19.1, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  81%|████████▏ | 13/16 [00:00<00:00, 34.39it/s, v_num=16, train_loss_step=-18.5, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  88%|████████▊ | 14/16 [00:00<00:00, 34.48it/s, v_num=16, train_loss_step=-16.1, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13:  94%|█████████▍| 15/16 [00:00<00:00, 34.80it/s, v_num=16, train_loss_step=-15.9, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 13: 100%|██████████| 16/16 [00:00<00:00, 35.24it/s, v_num=16, train_loss_step=-18.0, val_loss=-21.3, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-17.6]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 14:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-18.0, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:   6%|▋         | 1/16 [00:00<00:00, 36.18it/s, v_num=16, train_loss_step=-18.3, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  12%|█▎        | 2/16 [00:00<00:00, 35.83it/s, v_num=16, train_loss_step=-19.1, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  19%|█▉        | 3/16 [00:00<00:00, 35.37it/s, v_num=16, train_loss_step=-17.0, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  25%|██▌       | 4/16 [00:00<00:00, 33.95it/s, v_num=16, train_loss_step=-18.0, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  31%|███▏      | 5/16 [00:00<00:00, 32.78it/s, v_num=16, train_loss_step=-14.6, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  38%|███▊      | 6/16 [00:00<00:00, 32.25it/s, v_num=16, train_loss_step=-18.0, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  44%|████▍     | 7/16 [00:00<00:00, 33.01it/s, v_num=16, train_loss_step=-17.6, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  50%|█████     | 8/16 [00:00<00:00, 33.25it/s, v_num=16, train_loss_step=-19.5, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  56%|█████▋    | 9/16 [00:00<00:00, 33.20it/s, v_num=16, train_loss_step=-20.1, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  62%|██████▎   | 10/16 [00:00<00:00, 33.48it/s, v_num=16, train_loss_step=-19.2, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  69%|██████▉   | 11/16 [00:00<00:00, 33.78it/s, v_num=16, train_loss_step=-17.1, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  75%|███████▌  | 12/16 [00:00<00:00, 33.98it/s, v_num=16, train_loss_step=-17.0, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  81%|████████▏ | 13/16 [00:00<00:00, 34.10it/s, v_num=16, train_loss_step=-17.6, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  88%|████████▊ | 14/16 [00:00<00:00, 34.47it/s, v_num=16, train_loss_step=-18.0, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14:  94%|█████████▍| 15/16 [00:00<00:00, 34.54it/s, v_num=16, train_loss_step=-16.1, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 14: 100%|██████████| 16/16 [00:00<00:00, 34.95it/s, v_num=16, train_loss_step=-17.8, val_loss=-21.4, val_acc=0.267, val_auroc=0.455, val_f1=0.267, train_loss_epoch=-17.7]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 15:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-17.8, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:   6%|▋         | 1/16 [00:00<00:00, 28.95it/s, v_num=16, train_loss_step=-17.3, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  12%|█▎        | 2/16 [00:00<00:00, 31.23it/s, v_num=16, train_loss_step=-18.2, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  19%|█▉        | 3/16 [00:00<00:00, 32.59it/s, v_num=16, train_loss_step=-19.5, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  25%|██▌       | 4/16 [00:00<00:00, 33.32it/s, v_num=16, train_loss_step=-15.6, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  31%|███▏      | 5/16 [00:00<00:00, 33.50it/s, v_num=16, train_loss_step=-16.5, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  38%|███▊      | 6/16 [00:00<00:00, 34.44it/s, v_num=16, train_loss_step=-18.8, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  44%|████▍     | 7/16 [00:00<00:00, 34.61it/s, v_num=16, train_loss_step=-18.4, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  50%|█████     | 8/16 [00:00<00:00, 34.75it/s, v_num=16, train_loss_step=-18.0, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  56%|█████▋    | 9/16 [00:00<00:00, 35.33it/s, v_num=16, train_loss_step=-15.4, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  62%|██████▎   | 10/16 [00:00<00:00, 35.00it/s, v_num=16, train_loss_step=-19.2, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  69%|██████▉   | 11/16 [00:00<00:00, 34.84it/s, v_num=16, train_loss_step=-17.6, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  75%|███████▌  | 12/16 [00:00<00:00, 34.56it/s, v_num=16, train_loss_step=-17.8, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  81%|████████▏ | 13/16 [00:00<00:00, 34.55it/s, v_num=16, train_loss_step=-19.0, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  88%|████████▊ | 14/16 [00:00<00:00, 33.80it/s, v_num=16, train_loss_step=-18.6, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15:  94%|█████████▍| 15/16 [00:00<00:00, 33.84it/s, v_num=16, train_loss_step=-19.1, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 15: 100%|██████████| 16/16 [00:00<00:00, 34.31it/s, v_num=16, train_loss_step=-17.9, val_loss=-21.5, val_acc=0.267, val_auroc=0.454, val_f1=0.267, train_loss_epoch=-17.8]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 16:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-17.9, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:   6%|▋         | 1/16 [00:00<00:00, 24.09it/s, v_num=16, train_loss_step=-16.5, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  12%|█▎        | 2/16 [00:00<00:00, 28.36it/s, v_num=16, train_loss_step=-17.2, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  19%|█▉        | 3/16 [00:00<00:00, 31.74it/s, v_num=16, train_loss_step=-17.9, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  25%|██▌       | 4/16 [00:00<00:00, 33.16it/s, v_num=16, train_loss_step=-18.9, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  31%|███▏      | 5/16 [00:00<00:00, 34.21it/s, v_num=16, train_loss_step=-16.7, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  38%|███▊      | 6/16 [00:00<00:00, 34.65it/s, v_num=16, train_loss_step=-18.4, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  44%|████▍     | 7/16 [00:00<00:00, 34.80it/s, v_num=16, train_loss_step=-18.0, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  50%|█████     | 8/16 [00:00<00:00, 35.07it/s, v_num=16, train_loss_step=-17.8, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  56%|█████▋    | 9/16 [00:00<00:00, 35.34it/s, v_num=16, train_loss_step=-17.2, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  62%|██████▎   | 10/16 [00:00<00:00, 35.63it/s, v_num=16, train_loss_step=-18.6, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  69%|██████▉   | 11/16 [00:00<00:00, 34.63it/s, v_num=16, train_loss_step=-18.2, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  75%|███████▌  | 12/16 [00:00<00:00, 34.77it/s, v_num=16, train_loss_step=-16.8, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  81%|████████▏ | 13/16 [00:00<00:00, 35.03it/s, v_num=16, train_loss_step=-19.9, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  88%|████████▊ | 14/16 [00:00<00:00, 35.43it/s, v_num=16, train_loss_step=-16.0, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16:  94%|█████████▍| 15/16 [00:00<00:00, 35.52it/s, v_num=16, train_loss_step=-20.2, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 16: 100%|██████████| 16/16 [00:00<00:00, 36.05it/s, v_num=16, train_loss_step=-20.3, val_loss=-21.6, val_acc=0.267, val_auroc=0.456, val_f1=0.267, train_loss_epoch=-17.9]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 17:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-20.3, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:   6%|▋         | 1/16 [00:00<00:00, 25.00it/s, v_num=16, train_loss_step=-20.0, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  12%|█▎        | 2/16 [00:00<00:00, 28.77it/s, v_num=16, train_loss_step=-19.9, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  19%|█▉        | 3/16 [00:00<00:00, 31.41it/s, v_num=16, train_loss_step=-18.2, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  25%|██▌       | 4/16 [00:00<00:00, 32.13it/s, v_num=16, train_loss_step=-17.3, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  31%|███▏      | 5/16 [00:00<00:00, 32.67it/s, v_num=16, train_loss_step=-19.9, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  38%|███▊      | 6/16 [00:00<00:00, 33.15it/s, v_num=16, train_loss_step=-17.8, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  44%|████▍     | 7/16 [00:00<00:00, 33.65it/s, v_num=16, train_loss_step=-18.3, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  50%|█████     | 8/16 [00:00<00:00, 33.75it/s, v_num=16, train_loss_step=-18.4, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  56%|█████▋    | 9/16 [00:00<00:00, 34.28it/s, v_num=16, train_loss_step=-18.5, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  62%|██████▎   | 10/16 [00:00<00:00, 34.30it/s, v_num=16, train_loss_step=-18.2, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  69%|██████▉   | 11/16 [00:00<00:00, 34.43it/s, v_num=16, train_loss_step=-14.0, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  75%|███████▌  | 12/16 [00:00<00:00, 34.83it/s, v_num=16, train_loss_step=-18.2, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  81%|████████▏ | 13/16 [00:00<00:00, 35.04it/s, v_num=16, train_loss_step=-16.8, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  88%|████████▊ | 14/16 [00:00<00:00, 35.17it/s, v_num=16, train_loss_step=-18.3, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17:  94%|█████████▍| 15/16 [00:00<00:00, 35.21it/s, v_num=16, train_loss_step=-17.5, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 17: 100%|██████████| 16/16 [00:00<00:00, 35.28it/s, v_num=16, train_loss_step=-18.2, val_loss=-21.7, val_acc=0.267, val_auroc=0.457, val_f1=0.267, train_loss_epoch=-18.0]Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of preds_logit in validation_step: torch.Size([10, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([10, 39])\n",
      "Shape of data in validation_step: torch.Size([10, 39])\n",
      "Shape of labels in validation_step: torch.Size([10])\n",
      "Epoch 18:   0%|          | 0/16 [00:00<?, ?it/s, v_num=16, train_loss_step=-18.2, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]         Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:   6%|▋         | 1/16 [00:00<00:00, 31.12it/s, v_num=16, train_loss_step=-15.4, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  12%|█▎        | 2/16 [00:00<00:00, 32.98it/s, v_num=16, train_loss_step=-16.4, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  19%|█▉        | 3/16 [00:00<00:00, 34.01it/s, v_num=16, train_loss_step=-18.3, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  25%|██▌       | 4/16 [00:00<00:00, 34.72it/s, v_num=16, train_loss_step=-20.1, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  31%|███▏      | 5/16 [00:00<00:00, 34.89it/s, v_num=16, train_loss_step=-16.7, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  38%|███▊      | 6/16 [00:00<00:00, 35.03it/s, v_num=16, train_loss_step=-20.1, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  44%|████▍     | 7/16 [00:00<00:00, 35.12it/s, v_num=16, train_loss_step=-17.2, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  50%|█████     | 8/16 [00:00<00:00, 35.04it/s, v_num=16, train_loss_step=-18.7, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  56%|█████▋    | 9/16 [00:00<00:00, 35.19it/s, v_num=16, train_loss_step=-19.6, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  62%|██████▎   | 10/16 [00:00<00:00, 34.87it/s, v_num=16, train_loss_step=-21.2, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  69%|██████▉   | 11/16 [00:00<00:00, 34.17it/s, v_num=16, train_loss_step=-18.2, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  75%|███████▌  | 12/16 [00:00<00:00, 33.47it/s, v_num=16, train_loss_step=-16.5, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  81%|████████▏ | 13/16 [00:00<00:00, 32.78it/s, v_num=16, train_loss_step=-19.3, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  88%|████████▊ | 14/16 [00:00<00:00, 32.80it/s, v_num=16, train_loss_step=-17.7, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([64, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([64, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([64, 39])\n",
      "Shape of data in validation_step: torch.Size([64, 39])\n",
      "Shape of labels in validation_step: torch.Size([64])\n",
      "Shape of probs: torch.Size([64, 2])\n",
      "Shape of preds after argmax: torch.Size([64])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18:  94%|█████████▍| 15/16 [00:00<00:00, 33.27it/s, v_num=16, train_loss_step=-17.4, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]Shape of data in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction in training_step: torch.Size([62, 39])\n",
      "Shape of reconstruction_loss: torch.Size([])\n",
      "Shape of preds_logit in validation_step: torch.Size([62, 2])\n",
      "Shape of reconstruction in validation_step: torch.Size([62, 39])\n",
      "Shape of data in validation_step: torch.Size([62, 39])\n",
      "Shape of labels in validation_step: torch.Size([62])\n",
      "Shape of probs: torch.Size([62, 2])\n",
      "Shape of preds after argmax: torch.Size([62])\n",
      "torch.float32 torch.int64 torch.float32\n",
      "Epoch 18: 100%|██████████| 16/16 [00:00<00:00, 33.70it/s, v_num=16, train_loss_step=-18.0, val_loss=-21.8, val_acc=0.267, val_auroc=0.458, val_f1=0.267, train_loss_epoch=-18.1]"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=100, callbacks=[early_stopping, checkpoint_callback], accelerator=\"cpu\", devices=1, enable_progress_bar=True, enable_model_summary=True, profiler=\"simple\")\n",
    "trainer.fit(vae, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate=0.0001\n",
    "# optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "# num_epochs = 10\n",
    "# for epoch in range(num_epochs):\n",
    "#     vae.train()\n",
    "#     train_loss = 0\n",
    "#     for batch_data, _ in train_loader:\n",
    "#         # #print(batch_data)\n",
    "#         loss, rec_loss, kl_loss = vae.train_step(batch_data, optimizer)\n",
    "#         train_loss += loss\n",
    "\n",
    "#     train_loss /= len(train_loader)\n",
    "#     #print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
