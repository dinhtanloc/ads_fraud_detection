{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3fedb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1dd1c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/Admin/Data/ads_fraud_detection\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "__script_path=os.path.abspath(globals().get('__file__','.'))\n",
    "__script_dir = os.path.dirname(__script_path)\n",
    "root_dir = os.path.abspath(f'{__script_dir}/../../../..')\n",
    "#print(root_dir)\n",
    "for lib in [root_dir][::-1]:\n",
    "    if lib in sys.path:\n",
    "        sys.path.remove(lib)\n",
    "    sys.path.insert(0,lib)\n",
    "from config.config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69041950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#print(torch.version.cuda)  # Hiển thị phiên bản CUDA mà PyTorch đang sử dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a272514f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Training on gpu.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Training on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on gpu.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "622aee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=f\"{exps_dir}/exp1/exp_smote\"\n",
    "if os.path.exists(save_dir) == False: \n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee0c5839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_selection=dict(np.load(f'{save_dir}/feature_model_selection.npz',allow_pickle=True))['feature_model_selection']\n",
    "# feature_selection = {key: value for key, value in feature_selection.item().items()}\n",
    "# feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d162d6",
   "metadata": {},
   "source": [
    "* kiểm tra và tạo các thư mục (nếu chưa có)\n",
    "* tập test 33%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7e092",
   "metadata": {},
   "source": [
    "# 5. Xây dựng và đánh giá mô hình học sâu Neutual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d84bdb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bg_model=joblib.load(f'{save_dir}/bg_model.joblib')\n",
    "# rf_model=joblib.load(f'{save_dir}/rf_model.joblib')\n",
    "# svm_model=joblib.load(f'{save_dir}/svm_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e81211d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6555772994129159, 1: 2.106918238993711}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "class_weights_dict=dict(np.load(f'{save_dir}/class_weights_dict.npz',allow_pickle=True))['class_weights_dict']\n",
    "class_weights_dict = {key: value for key, value in class_weights_dict.item().items()}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0369d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91c27093",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values.squeeze(), dtype=torch.long)\n",
    "X_test = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values.squeeze(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e7d3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = len(np.unique(y_train))\n",
    "# #print(f\"Số lớp: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dd43638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_train_onehot = torch.nn.functional.one_hot(y_train, num_classes=2)\n",
    "# # y_test_onehot = torch.nn.functional.one_hot(y_test, num_classes=2)\n",
    "\n",
    "# #print(\"Mã hóa one-hot của y_train:\\n\", y_train_onehot)\n",
    "# #print(\"Mã hóa one-hot của y_test:\\n\", y_test_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52323c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.tensor(x_data.values, dtype=torch.float32)  # Chuyển features thành tensor\n",
    "        self.y_data = y_data  # Nhãn đã được mã hóa one-hot\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfa909c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "test_dataset = CustomDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5731513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cf5d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor([class_weights_dict[key] for key in sorted(class_weights_dict.keys())], dtype=torch.float32)\n",
    "class_weights = class_weights\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dda6290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 39)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1c3ac7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 39)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e415e738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 8.80416 | val_0_unsup_loss_numpy: 59.052978515625|  0:00:00s\n",
      "epoch 1  | loss: 6.14867 | val_0_unsup_loss_numpy: 36.15195846557617|  0:00:00s\n",
      "epoch 2  | loss: 4.86443 | val_0_unsup_loss_numpy: 10.468839645385742|  0:00:00s\n",
      "epoch 3  | loss: 4.13779 | val_0_unsup_loss_numpy: 9.760029792785645|  0:00:00s\n",
      "epoch 4  | loss: 3.50821 | val_0_unsup_loss_numpy: 5.360750198364258|  0:00:00s\n",
      "epoch 5  | loss: 3.075   | val_0_unsup_loss_numpy: 3.9730899333953857|  0:00:00s\n",
      "epoch 6  | loss: 2.70275 | val_0_unsup_loss_numpy: 3.4019598960876465|  0:00:00s\n",
      "epoch 7  | loss: 2.4362  | val_0_unsup_loss_numpy: 2.7136099338531494|  0:00:00s\n",
      "epoch 8  | loss: 2.19751 | val_0_unsup_loss_numpy: 2.245879888534546|  0:00:00s\n",
      "epoch 9  | loss: 2.04662 | val_0_unsup_loss_numpy: 3.8299500942230225|  0:00:00s\n",
      "epoch 10 | loss: 1.87432 | val_0_unsup_loss_numpy: 2.237529993057251|  0:00:00s\n",
      "epoch 11 | loss: 1.72491 | val_0_unsup_loss_numpy: 1.796429991722107|  0:00:00s\n",
      "epoch 12 | loss: 1.63449 | val_0_unsup_loss_numpy: 1.7627500295639038|  0:00:01s\n",
      "epoch 13 | loss: 1.51899 | val_0_unsup_loss_numpy: 1.9949500560760498|  0:00:01s\n",
      "epoch 14 | loss: 1.44518 | val_0_unsup_loss_numpy: 1.5119400024414062|  0:00:01s\n",
      "epoch 15 | loss: 1.39122 | val_0_unsup_loss_numpy: 1.4872599840164185|  0:00:01s\n",
      "epoch 16 | loss: 1.34404 | val_0_unsup_loss_numpy: 1.4131900072097778|  0:00:01s\n",
      "epoch 17 | loss: 1.30441 | val_0_unsup_loss_numpy: 1.5671700239181519|  0:00:01s\n",
      "epoch 18 | loss: 1.27796 | val_0_unsup_loss_numpy: 1.302340030670166|  0:00:01s\n",
      "epoch 19 | loss: 1.25    | val_0_unsup_loss_numpy: 1.3090300559997559|  0:00:01s\n",
      "epoch 20 | loss: 1.21098 | val_0_unsup_loss_numpy: 1.2858999967575073|  0:00:01s\n",
      "epoch 21 | loss: 1.18391 | val_0_unsup_loss_numpy: 1.2177200317382812|  0:00:01s\n",
      "epoch 22 | loss: 1.15883 | val_0_unsup_loss_numpy: 1.211210012435913|  0:00:01s\n",
      "epoch 23 | loss: 1.14546 | val_0_unsup_loss_numpy: 1.2125500440597534|  0:00:01s\n",
      "epoch 24 | loss: 1.1215  | val_0_unsup_loss_numpy: 1.1505299806594849|  0:00:01s\n",
      "epoch 25 | loss: 1.11265 | val_0_unsup_loss_numpy: 1.1218899488449097|  0:00:02s\n",
      "epoch 26 | loss: 1.10624 | val_0_unsup_loss_numpy: 1.123420000076294|  0:00:02s\n",
      "epoch 27 | loss: 1.09593 | val_0_unsup_loss_numpy: 1.1259000301361084|  0:00:02s\n",
      "epoch 28 | loss: 1.08821 | val_0_unsup_loss_numpy: 1.1205099821090698|  0:00:02s\n",
      "epoch 29 | loss: 1.0727  | val_0_unsup_loss_numpy: 1.1028900146484375|  0:00:02s\n",
      "epoch 30 | loss: 1.0707  | val_0_unsup_loss_numpy: 1.0907000303268433|  0:00:02s\n",
      "epoch 31 | loss: 1.06635 | val_0_unsup_loss_numpy: 1.111109972000122|  0:00:02s\n",
      "epoch 32 | loss: 1.05221 | val_0_unsup_loss_numpy: 1.0656499862670898|  0:00:02s\n",
      "epoch 33 | loss: 1.05739 | val_0_unsup_loss_numpy: 1.0675100088119507|  0:00:02s\n",
      "epoch 34 | loss: 1.04365 | val_0_unsup_loss_numpy: 1.069350004196167|  0:00:02s\n",
      "epoch 35 | loss: 1.03473 | val_0_unsup_loss_numpy: 1.0588300228118896|  0:00:02s\n",
      "epoch 36 | loss: 1.03651 | val_0_unsup_loss_numpy: 1.0447100400924683|  0:00:02s\n",
      "epoch 37 | loss: 1.02268 | val_0_unsup_loss_numpy: 1.0514800548553467|  0:00:03s\n",
      "epoch 38 | loss: 1.02735 | val_0_unsup_loss_numpy: 1.045009970664978|  0:00:03s\n",
      "epoch 39 | loss: 1.01474 | val_0_unsup_loss_numpy: 1.0263299942016602|  0:00:03s\n",
      "epoch 40 | loss: 1.01171 | val_0_unsup_loss_numpy: 1.0257400274276733|  0:00:03s\n",
      "epoch 41 | loss: 1.00894 | val_0_unsup_loss_numpy: 1.0260000228881836|  0:00:03s\n",
      "epoch 42 | loss: 0.99731 | val_0_unsup_loss_numpy: 1.0157099962234497|  0:00:03s\n",
      "epoch 43 | loss: 1.00084 | val_0_unsup_loss_numpy: 1.0124499797821045|  0:00:03s\n",
      "epoch 44 | loss: 1.005   | val_0_unsup_loss_numpy: 1.01364004611969|  0:00:03s\n",
      "epoch 45 | loss: 0.99988 | val_0_unsup_loss_numpy: 0.9991899728775024|  0:00:03s\n",
      "epoch 46 | loss: 0.99512 | val_0_unsup_loss_numpy: 1.0118199586868286|  0:00:03s\n",
      "epoch 47 | loss: 0.99099 | val_0_unsup_loss_numpy: 1.0016100406646729|  0:00:03s\n",
      "epoch 48 | loss: 0.99909 | val_0_unsup_loss_numpy: 1.0049500465393066|  0:00:03s\n",
      "epoch 49 | loss: 0.98963 | val_0_unsup_loss_numpy: 1.0043699741363525|  0:00:03s\n",
      "epoch 50 | loss: 0.99888 | val_0_unsup_loss_numpy: 1.0029000043869019|  0:00:04s\n",
      "epoch 51 | loss: 0.98739 | val_0_unsup_loss_numpy: 0.9940400123596191|  0:00:04s\n",
      "epoch 52 | loss: 0.98404 | val_0_unsup_loss_numpy: 0.9850599765777588|  0:00:04s\n",
      "epoch 53 | loss: 0.984   | val_0_unsup_loss_numpy: 0.9848700165748596|  0:00:04s\n",
      "epoch 54 | loss: 0.98192 | val_0_unsup_loss_numpy: 0.9857199788093567|  0:00:04s\n",
      "epoch 55 | loss: 0.98089 | val_0_unsup_loss_numpy: 0.9850599765777588|  0:00:04s\n",
      "epoch 56 | loss: 0.97912 | val_0_unsup_loss_numpy: 0.9882500171661377|  0:00:04s\n",
      "epoch 57 | loss: 0.98011 | val_0_unsup_loss_numpy: 0.9759299755096436|  0:00:04s\n",
      "epoch 58 | loss: 0.9789  | val_0_unsup_loss_numpy: 0.9830600023269653|  0:00:04s\n",
      "epoch 59 | loss: 0.97355 | val_0_unsup_loss_numpy: 0.9761899709701538|  0:00:04s\n",
      "epoch 60 | loss: 0.97428 | val_0_unsup_loss_numpy: 0.9904999732971191|  0:00:04s\n",
      "epoch 61 | loss: 0.98383 | val_0_unsup_loss_numpy: 0.9823700189590454|  0:00:04s\n",
      "epoch 62 | loss: 0.97817 | val_0_unsup_loss_numpy: 0.9650899767875671|  0:00:05s\n",
      "epoch 63 | loss: 0.97309 | val_0_unsup_loss_numpy: 0.9642800092697144|  0:00:05s\n",
      "epoch 64 | loss: 0.97141 | val_0_unsup_loss_numpy: 0.986810028553009|  0:00:05s\n",
      "epoch 65 | loss: 0.97071 | val_0_unsup_loss_numpy: 0.96697998046875|  0:00:05s\n",
      "epoch 66 | loss: 0.97301 | val_0_unsup_loss_numpy: 0.9680699706077576|  0:00:05s\n",
      "epoch 67 | loss: 0.97055 | val_0_unsup_loss_numpy: 0.972350001335144|  0:00:05s\n",
      "epoch 68 | loss: 0.96473 | val_0_unsup_loss_numpy: 0.9650099873542786|  0:00:05s\n",
      "epoch 69 | loss: 0.96914 | val_0_unsup_loss_numpy: 0.9552800059318542|  0:00:05s\n",
      "epoch 70 | loss: 0.96525 | val_0_unsup_loss_numpy: 0.9734399914741516|  0:00:05s\n",
      "epoch 71 | loss: 0.96533 | val_0_unsup_loss_numpy: 0.9809100031852722|  0:00:05s\n",
      "epoch 72 | loss: 0.97048 | val_0_unsup_loss_numpy: 0.9634400010108948|  0:00:05s\n",
      "epoch 73 | loss: 0.96617 | val_0_unsup_loss_numpy: 0.9730799794197083|  0:00:05s\n",
      "epoch 74 | loss: 0.96272 | val_0_unsup_loss_numpy: 0.9685199856758118|  0:00:05s\n",
      "epoch 75 | loss: 0.96039 | val_0_unsup_loss_numpy: 0.9593600034713745|  0:00:06s\n",
      "epoch 76 | loss: 0.96143 | val_0_unsup_loss_numpy: 0.9463300108909607|  0:00:06s\n",
      "epoch 77 | loss: 0.96383 | val_0_unsup_loss_numpy: 0.9765400290489197|  0:00:06s\n",
      "epoch 78 | loss: 0.97606 | val_0_unsup_loss_numpy: 0.9568600058555603|  0:00:06s\n",
      "epoch 79 | loss: 0.96915 | val_0_unsup_loss_numpy: 0.9647700190544128|  0:00:06s\n",
      "epoch 80 | loss: 0.96555 | val_0_unsup_loss_numpy: 0.9445400238037109|  0:00:06s\n",
      "epoch 81 | loss: 0.95857 | val_0_unsup_loss_numpy: 0.9456700086593628|  0:00:06s\n",
      "epoch 82 | loss: 0.96427 | val_0_unsup_loss_numpy: 0.9650200009346008|  0:00:06s\n",
      "epoch 83 | loss: 0.9583  | val_0_unsup_loss_numpy: 0.9456499814987183|  0:00:06s\n",
      "epoch 84 | loss: 0.96808 | val_0_unsup_loss_numpy: 0.9491999745368958|  0:00:06s\n",
      "epoch 85 | loss: 0.96153 | val_0_unsup_loss_numpy: 0.9511299729347229|  0:00:06s\n",
      "epoch 86 | loss: 0.96021 | val_0_unsup_loss_numpy: 0.9539499878883362|  0:00:06s\n",
      "epoch 87 | loss: 0.96171 | val_0_unsup_loss_numpy: 0.9549999833106995|  0:00:06s\n",
      "epoch 88 | loss: 0.95641 | val_0_unsup_loss_numpy: 0.9601699709892273|  0:00:07s\n",
      "epoch 89 | loss: 0.96032 | val_0_unsup_loss_numpy: 0.9428099989891052|  0:00:07s\n",
      "epoch 90 | loss: 0.96001 | val_0_unsup_loss_numpy: 0.9647700190544128|  0:00:07s\n",
      "epoch 91 | loss: 0.95858 | val_0_unsup_loss_numpy: 0.9589099884033203|  0:00:07s\n",
      "epoch 92 | loss: 0.95883 | val_0_unsup_loss_numpy: 0.955020010471344|  0:00:07s\n",
      "epoch 93 | loss: 0.9564  | val_0_unsup_loss_numpy: 0.9629700183868408|  0:00:07s\n",
      "epoch 94 | loss: 0.95025 | val_0_unsup_loss_numpy: 0.9639300107955933|  0:00:07s\n",
      "epoch 95 | loss: 0.96131 | val_0_unsup_loss_numpy: 0.9481800198554993|  0:00:07s\n",
      "epoch 96 | loss: 0.95911 | val_0_unsup_loss_numpy: 0.9464499950408936|  0:00:07s\n",
      "epoch 97 | loss: 0.94941 | val_0_unsup_loss_numpy: 0.9595000147819519|  0:00:07s\n",
      "epoch 98 | loss: 0.95879 | val_0_unsup_loss_numpy: 0.9399999976158142|  0:00:07s\n",
      "epoch 99 | loss: 0.9589  | val_0_unsup_loss_numpy: 0.9376000165939331|  0:00:07s\n",
      "epoch 100| loss: 0.95281 | val_0_unsup_loss_numpy: 0.9349799752235413|  0:00:08s\n",
      "Stop training because you reached max_epochs = 101 with best_epoch = 100 and best_val_0_unsup_loss_numpy = 0.9349799752235413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "tabnet_params = {\n",
    "    \"n_d\": 16,\n",
    "    \"n_a\": 16,\n",
    "    \"n_steps\": 3,\n",
    "    \"n_shared\": 2,\n",
    "    \"n_independent\": 2,\n",
    "    \"gamma\": 1.3,\n",
    "    \"epsilon\": 1e-15,\n",
    "    \"momentum\": 0.98,\n",
    "    \"mask_type\": \"sparsemax\",\n",
    "    \"lambda_sparse\": 1e-3\n",
    "}\n",
    "\n",
    "\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    **tabnet_params\n",
    ")\n",
    " \n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train,\n",
    "    eval_set=[X_test],  \n",
    "    pretraining_ratio=0.8,\n",
    "    max_epochs=101,\n",
    "    patience=10,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b90ccf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "TabNetPretraining                                            [1022, 39]                --\n",
       "├─EmbeddingGenerator: 1-1                                    [1022, 39]                --\n",
       "├─TabNetEncoder: 1-2                                         [1022, 16]                --\n",
       "│    └─BatchNorm1d: 2-1                                      [1022, 39]                78\n",
       "│    └─FeatTransformer: 2-2                                  [1022, 32]                4,352\n",
       "│    │    └─GLU_Block: 3-1                                   [1022, 32]                4,800\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-6                                   [1022, 32]                4,352\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-7                        [1022, 39]                702\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-8                             [1022, 32]                9,152\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-13                       [1022, 39]                702\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-14                            [1022, 32]                9,152\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-19                       [1022, 39]                702\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-20                            [1022, 32]                9,152\n",
       "├─TabNetDecoder: 1-3                                         [1022, 39]                --\n",
       "│    └─ModuleList: 2-13                                      --                        --\n",
       "│    │    └─FeatTransformer: 3-21                            [1022, 16]                1,152\n",
       "│    │    └─FeatTransformer: 3-25                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-23                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-24                            [1022, 16]                1,152\n",
       "│    │    └─FeatTransformer: 3-25                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-26                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-27                            [1022, 16]                1,152\n",
       "│    └─Linear: 2-14                                          [1022, 39]                624\n",
       "==============================================================================================================\n",
       "Total params: 69,560\n",
       "Trainable params: 69,560\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 43.82\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.16\n",
       "Forward/backward pass size (MB): 22.43\n",
       "Params size (MB): 0.11\n",
       "Estimated Total Size (MB): 22.71\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truy cập vào mô hình TabNet bên trong\n",
    "from torchinfo import summary\n",
    "\n",
    "tabnet_model = unsupervised_model.network\n",
    "\n",
    "summary(tabnet_model, input_size=X_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d41dbc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tabnet_model.encoder\n",
    "decoder = tabnet_model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec0baf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(nn.Module):\n",
    "    def __init__(self, seed=1337):\n",
    "        super(Sampling, self).__init__()\n",
    "        self.seed = seed\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = z_mean.size(0)\n",
    "        dim = z_mean.size(1)\n",
    "        # #print(batch, dim)\n",
    "        epsilon = torch.randn(batch, dim, generator=torch.Generator().manual_seed(self.seed))\n",
    "        return z_mean + torch.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06ffbd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE_Encoder, self).__init__()\n",
    "        self.tabnet_encoder = tabnet_model.encoder\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(16, 128),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, latent_dim)\n",
    "        )\n",
    "        self.fc_mean = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(latent_dim, latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "\n",
    "    def forward(self, x):\n",
    "        steps_output, _ = self.tabnet_encoder(x)\n",
    "        encoded = steps_output[-1]\n",
    "        # #print(\"Shape of encoded tensor:\", encoded.shape)\n",
    "        encoded = self.mlp(encoded)\n",
    "        z_mean = self.fc_mean(encoded)\n",
    "        z_log_var = self.fc_log_var(encoded)\n",
    "        try:\n",
    "            z = self.sampling((z_mean, z_log_var))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in sampling function: {e}\")\n",
    "            #print(f\"z_mean shape: {z_mean.shape}\")\n",
    "            #print(f\"z_log_var shape: {z_log_var.shape}\")\n",
    "        return z_mean, z_log_var, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56016559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim,encoded_dim, output_dim):\n",
    "        super(VAE_Decoder, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),   \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, encoded_dim),  \n",
    "        )\n",
    "        self.tabnet_decoder = tabnet_model.decoder\n",
    "        self.reshape = nn.Unflatten(1, (encoded_dim,))\n",
    "        self.output_dim=output_dim\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = F.relu(self.mlp(z))\n",
    "\n",
    "        # #print(\"Shape before reshape:\", x.shape)\n",
    "        # x = self.reshape(x)\n",
    "        x = x[None, ...]\n",
    "\n",
    "        # #print(\"Shape after reshape:\", x.shape)\n",
    "        # x = x.view(x.size(0), output_dim)\n",
    "        \n",
    "        output = self.tabnet_decoder(x)\n",
    "        # #print(output.shape)\n",
    "        # #print(\"Shape of output from tabnet_decoder:\", output.shape)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output.view(-1, self.output_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "492bd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from lightning.pytorch import LightningModule, Trainer\n",
    "from torchmetrics import Accuracy, AUROC, F1Score, Precision, Recall\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e2e486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(LightningModule):\n",
    "    def __init__(self, encoder, decoder, classifier, loss, learning_rate=1e-3):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.classifier = classifier\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss = loss\n",
    "\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        self.val_auroc = AUROC(task=\"multiclass\", num_classes=2)\n",
    "        self.val_f1 = F1Score(task=\"multiclass\", num_classes=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_mean, z_log_var, z = self.encoder(x)\n",
    "        # #print(\"Shape after encoder:\", z.shape)\n",
    "\n",
    "        reconstruction = self.decoder(z)\n",
    "        # #print(\"Shape after decoder:\", reconstruction.shape)\n",
    "\n",
    "        return reconstruction, z_mean, z_log_var, z\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        # z_mean, z_log_var, z = self.encoder(data)\n",
    "        # reconstruction = self.decoder(z)\n",
    "        #print(\"Shape of data in training_step:\", batch[0].shape)\n",
    "        data, labels = batch\n",
    "        reconstruction, z_mean, z_log_var, z = self.forward(data)\n",
    "        #print(\"Shape of reconstruction in training_step:\", reconstruction.shape)\n",
    "        reconstruction_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                F.binary_cross_entropy_with_logits(reconstruction, data, reduction='none'),\n",
    "                dim=1\n",
    "                # dim=(1, 2)\n",
    "                )  # Tính tổng trên chiều (1, 2)\n",
    "        )\n",
    "        #print(\"Shape of reconstruction_loss:\", reconstruction_loss.shape)\n",
    "        preds_logit = self.classifier(z)\n",
    "        #print(\"Shape of preds_logit in validation_step:\", preds_logit.shape)\n",
    "        #print(\"Shape of reconstruction in validation_step:\", reconstruction.shape)\n",
    "        #print(\"Shape of data in validation_step:\", data.shape)\n",
    "        #print(\"Shape of labels in validation_step:\", labels.shape)\n",
    "        classification_loss = self.loss(preds_logit, labels.long())\n",
    "        probs = F.softmax(preds_logit, dim=1)\n",
    "        #print(\"Shape of probs:\", probs.shape)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        #print(\"Shape of preds after argmax:\", preds.shape)\n",
    "        #print(data.dtype, preds.dtype, probs.dtype)  # Chọn lớp có xác suất cao nhất\n",
    "\n",
    "\n",
    "        kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=1)\n",
    "        kl_loss = torch.mean(torch.sum(kl_loss))\n",
    "        vae_loss = reconstruction_loss + kl_loss\n",
    "        total_loss = vae_loss + classification_loss\n",
    "\n",
    "        self.log('train_loss', total_loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return total_loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        data, labels = batch\n",
    "        reconstruction, z_mean, z_log_var, z = self.forward(data)\n",
    "        preds_logit = self.classifier(z)\n",
    "        #print(\"Shape of preds_logit in validation_step:\", preds_logit.shape)\n",
    "        #print(\"Shape of reconstruction in validation_step:\", reconstruction.shape)\n",
    "        #print(\"Shape of data in validation_step:\", data.shape)\n",
    "        #print(\"Shape of labels in validation_step:\", labels.shape)\n",
    "        classification_loss = self.loss(preds_logit, labels.long())\n",
    "        probs = F.softmax(preds_logit, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "        \n",
    "        reconstruction, z_mean, z_log_var, z = self.forward(data)\n",
    "        reconstruction_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                F.binary_cross_entropy_with_logits(reconstruction, data, reduction='none'),\n",
    "                dim=1\n",
    "                # dim=(1, 2)\n",
    "                )  # Tính tổng trên chiều (1, 2)\n",
    "        )\n",
    "\n",
    "        kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=1)\n",
    "        kl_loss = torch.mean(torch.sum(kl_loss))\n",
    "        vae_loss = reconstruction_loss + kl_loss\n",
    "        total_loss = vae_loss + classification_loss\n",
    "        acc = self.val_accuracy(preds, labels)\n",
    "        auroc = self.val_auroc(probs, labels)\n",
    "        f1 = self.val_f1(preds, labels)\n",
    "\n",
    "        # Logging\n",
    "        self.log('val_loss', total_loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        self.log('val_auroc', auroc, prog_bar=True)\n",
    "        self.log('val_f1', f1, prog_bar=True)\n",
    "\n",
    "        return total_loss\n",
    "     \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = {\n",
    "            'scheduler': ReduceLROnPlateau(optimizer, mode='max', factor=0.95, patience=10, min_lr=1e-6, verbose=True),\n",
    "            'monitor': 'val_acc',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1,\n",
    "        }\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "384702b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, latent_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, 64)  # Layer đầu tiên\n",
    "        self.fc2 = nn.Linear(64, num_classes)  # Output layer: num_classes nodes\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = F.relu(self.fc1(z))  # Activation ReLU\n",
    "        x = self.fc2(x)          # Logits (chưa áp dụng softmax)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f89162f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "encoded_dim = 16\n",
    "output_dim = X_train.shape[1]\n",
    "input_dim = X_train.shape[1]\n",
    "#print(input_dim)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc',\n",
    "    # min_delta=0.00005,\n",
    "    patience=60,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_acc',\n",
    "    filename='best_model',\n",
    "    save_top_k=1,\n",
    "    mode='max',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f99c9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "VAE_Encoder                                                  [1022, 64]                --\n",
       "├─TabNetEncoder: 1-1                                         [1022, 16]                --\n",
       "│    └─BatchNorm1d: 2-1                                      [1022, 39]                78\n",
       "│    └─FeatTransformer: 2-2                                  [1022, 32]                4,352\n",
       "│    │    └─GLU_Block: 3-1                                   [1022, 32]                4,800\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-6                                   [1022, 32]                4,352\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-7                        [1022, 39]                702\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-8                             [1022, 32]                9,152\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-13                       [1022, 39]                702\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-14                            [1022, 32]                9,152\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-19                       [1022, 39]                702\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-20                            [1022, 32]                9,152\n",
       "├─Sequential: 1-2                                            [1022, 64]                --\n",
       "│    └─Linear: 2-13                                          [1022, 128]               2,176\n",
       "│    └─ReLU: 2-14                                            [1022, 128]               --\n",
       "│    └─Linear: 2-15                                          [1022, 128]               16,512\n",
       "│    └─ReLU: 2-16                                            [1022, 128]               --\n",
       "│    └─Linear: 2-17                                          [1022, 96]                12,384\n",
       "│    └─ReLU: 2-18                                            [1022, 96]                --\n",
       "│    └─Linear: 2-19                                          [1022, 64]                6,208\n",
       "├─Linear: 1-3                                                [1022, 64]                4,160\n",
       "├─Linear: 1-4                                                [1022, 64]                4,160\n",
       "├─Sampling: 1-5                                              [1022, 64]                --\n",
       "==============================================================================================================\n",
       "Total params: 109,288\n",
       "Trainable params: 109,288\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 86.25\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.16\n",
       "Forward/backward pass size (MB): 23.42\n",
       "Params size (MB): 0.28\n",
       "Estimated Total Size (MB): 23.87\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_encoder = VAE_Encoder(latent_dim=latent_dim)\n",
    "#print(\"Encoder Summary:\")\n",
    "summary(vae_encoder, input_size=(1022, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29dc46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(800, 39) \n",
    "steps_output, _ = tabnet_model.encoder(x)\n",
    "encoded = steps_output[-1]\n",
    "#print(f\"Encoded shape: {encoded.shape}\")\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.randn(800, 39)  \n",
    "\n",
    "steps_output, _ = tabnet_model.encoder(x)\n",
    "#print(\"Shape of encoder output:\", [output.shape for output in steps_output])\n",
    "\n",
    "decoder_input = steps_output[-1] \n",
    "decoder_input = decoder_input[None, ...]\n",
    "try:\n",
    "    decoder_output = tabnet_model.decoder(decoder_input)\n",
    "    #print(f\"Decoder shape: {decoder_output.shape}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f06afebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "VAE_Decoder                                                  [700, 39]                 --\n",
       "├─Sequential: 1-1                                            [700, 16]                 --\n",
       "│    └─Linear: 2-1                                           [700, 32]                 2,080\n",
       "│    └─ReLU: 2-2                                             [700, 32]                 --\n",
       "│    └─Linear: 2-3                                           [700, 96]                 3,168\n",
       "│    └─ReLU: 2-4                                             [700, 96]                 --\n",
       "│    └─Linear: 2-5                                           [700, 96]                 9,312\n",
       "│    └─ReLU: 2-6                                             [700, 96]                 --\n",
       "│    └─Linear: 2-7                                           [700, 16]                 1,552\n",
       "├─TabNetDecoder: 1-2                                         [700, 39]                 --\n",
       "│    └─ModuleList: 2-8                                       --                        --\n",
       "│    │    └─FeatTransformer: 3-1                             [700, 16]                 1,152\n",
       "│    │    └─FeatTransformer: 3-2                             --                        1,152\n",
       "│    │    └─FeatTransformer: 3-3                             --                        (recursive)\n",
       "│    └─Linear: 2-9                                           [700, 39]                 624\n",
       "==============================================================================================================\n",
       "Total params: 19,680\n",
       "Trainable params: 19,680\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 12.52\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.18\n",
       "Forward/backward pass size (MB): 2.28\n",
       "Params size (MB): 0.07\n",
       "Estimated Total Size (MB): 2.53\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_decoder = VAE_Decoder(latent_dim=latent_dim, encoded_dim=encoded_dim, output_dim=output_dim)\n",
    "#print(\"Decoder Summary:\")\n",
    "summary(vae_decoder, input_size=(700, latent_dim), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345d90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                                            Output Shape              Param #\n",
       "===================================================================================================================\n",
       "VAE                                                               [700, 39]                 4,290\n",
       "├─VAE_Encoder: 1-1                                                [700, 64]                 --\n",
       "│    └─TabNetEncoder: 2-1                                         [700, 16]                 --\n",
       "│    │    └─BatchNorm1d: 3-1                                      [700, 39]                 78\n",
       "│    │    └─FeatTransformer: 3-2                                  [700, 32]                 9,152\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-6                                  --                        (recursive)\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-6                                  --                        (recursive)\n",
       "│    │    └─ModuleList: 3-11                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-11                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-11                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    └─Sequential: 2-2                                            [700, 64]                 --\n",
       "│    │    └─Linear: 3-13                                          [700, 128]                2,176\n",
       "│    │    └─ReLU: 3-14                                            [700, 128]                --\n",
       "│    │    └─Linear: 3-15                                          [700, 128]                16,512\n",
       "│    │    └─ReLU: 3-16                                            [700, 128]                --\n",
       "│    │    └─Linear: 3-17                                          [700, 96]                 12,384\n",
       "│    │    └─ReLU: 3-18                                            [700, 96]                 --\n",
       "│    │    └─Linear: 3-19                                          [700, 64]                 6,208\n",
       "│    └─Linear: 2-3                                                [700, 64]                 4,160\n",
       "│    └─Linear: 2-4                                                [700, 64]                 4,160\n",
       "│    └─Sampling: 2-5                                              [700, 64]                 --\n",
       "├─VAE_Decoder: 1-2                                                [700, 39]                 --\n",
       "│    └─Sequential: 2-6                                            [700, 16]                 --\n",
       "│    │    └─Linear: 3-20                                          [700, 32]                 2,080\n",
       "│    │    └─ReLU: 3-21                                            [700, 32]                 --\n",
       "│    │    └─Linear: 3-22                                          [700, 96]                 3,168\n",
       "│    │    └─ReLU: 3-23                                            [700, 96]                 --\n",
       "│    │    └─Linear: 3-24                                          [700, 96]                 9,312\n",
       "│    │    └─ReLU: 3-25                                            [700, 96]                 --\n",
       "│    │    └─Linear: 3-26                                          [700, 16]                 1,552\n",
       "│    └─TabNetDecoder: 2-7                                         [700, 39]                 --\n",
       "│    │    └─ModuleList: 3-27                                      --                        2,432\n",
       "│    │    └─Linear: 3-28                                          [700, 39]                 624\n",
       "===================================================================================================================\n",
       "Total params: 133,258\n",
       "Trainable params: 133,258\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 71.60\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 18.32\n",
       "Params size (MB): 0.35\n",
       "Estimated Total Size (MB): 18.79\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "learning_rate=0.0001\n",
    "classifier = SimpleClassifier(latent_dim, num_classes=2)\n",
    "vae = VAE(encoder=vae_encoder, decoder=vae_decoder, classifier=classifier, loss=criterion, learning_rate=learning_rate)\n",
    "summary(vae, input_size=(700, input_dim), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467dd58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "\n",
      "  | Name         | Type               | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | encoder      | VAE_Encoder        | 70.8 K | train\n",
      "1 | decoder      | VAE_Decoder        | 19.2 K | train\n",
      "2 | classifier   | SimpleClassifier   | 4.3 K  | train\n",
      "3 | loss         | CrossEntropyLoss   | 0      | train\n",
      "4 | val_accuracy | MulticlassAccuracy | 0      | train\n",
      "5 | val_auroc    | MulticlassAUROC    | 0      | train\n",
      "6 | val_f1       | MulticlassF1Score  | 0      | train\n",
      "------------------------------------------------------------\n",
      "94.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "94.2 K    Total params\n",
      "0.377     Total estimated model params size (MB)\n",
      "168       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:310: The number of training batches (16) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 16/16 [00:00<00:00, 26.76it/s, v_num=17, train_loss_step=0.623, val_loss=-3.02, val_acc=0.406, val_auroc=0.481, val_f1=0.406, train_loss_epoch=3.090]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved. New best score: 0.406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 16/16 [00:00<00:00, 26.69it/s, v_num=17, train_loss_step=-4.09, val_loss=-6.83, val_acc=0.379, val_auroc=0.479, val_f1=0.379, train_loss_epoch=-1.22]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.027 >= min_delta = 0.0. New best score: 0.379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 16/16 [00:00<00:00, 27.01it/s, v_num=17, train_loss_step=-7.46, val_loss=-9.93, val_acc=0.309, val_auroc=0.477, val_f1=0.309, train_loss_epoch=-4.55]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.070 >= min_delta = 0.0. New best score: 0.309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 16/16 [00:00<00:00, 26.79it/s, v_num=17, train_loss_step=-8.39, val_loss=-12.3, val_acc=0.297, val_auroc=0.477, val_f1=0.297, train_loss_epoch=-7.46]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.012 >= min_delta = 0.0. New best score: 0.297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16/16 [00:00<00:00, 26.94it/s, v_num=17, train_loss_step=-13.6, val_loss=-14.3, val_acc=0.291, val_auroc=0.480, val_f1=0.291, train_loss_epoch=-10.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.006 >= min_delta = 0.0. New best score: 0.291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 16/16 [00:00<00:00, 27.18it/s, v_num=17, train_loss_step=-11.1, val_loss=-16.7, val_acc=0.288, val_auroc=0.470, val_f1=0.288, train_loss_epoch=-12.4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.003 >= min_delta = 0.0. New best score: 0.288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 16/16 [00:00<00:00, 25.99it/s, v_num=17, train_loss_step=-15.0, val_loss=-18.1, val_acc=0.282, val_auroc=0.466, val_f1=0.282, train_loss_epoch=-14.1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.006 >= min_delta = 0.0. New best score: 0.282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 16/16 [00:00<00:00, 26.05it/s, v_num=17, train_loss_step=-15.0, val_loss=-19.4, val_acc=0.267, val_auroc=0.465, val_f1=0.267, train_loss_epoch=-15.3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved by 0.015 >= min_delta = 0.0. New best score: 0.267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34:   6%|▋         | 1/16 [00:00<00:00, 38.83it/s, v_num=17, train_loss_step=-17.4, val_loss=-23.1, val_acc=0.267, val_auroc=0.467, val_f1=0.267, train_loss_epoch=-19.2] "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=100, callbacks=[early_stopping, checkpoint_callback], accelerator=\"cpu\", devices=1, enable_progress_bar=True, enable_model_summary=True, profiler=\"simple\")\n",
    "trainer.fit(vae, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate=0.0001\n",
    "# optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "# num_epochs = 10\n",
    "# for epoch in range(num_epochs):\n",
    "#     vae.train()\n",
    "#     train_loss = 0\n",
    "#     for batch_data, _ in train_loader:\n",
    "#         # #print(batch_data)\n",
    "#         loss, rec_loss, kl_loss = vae.train_step(batch_data, optimizer)\n",
    "#         train_loss += loss\n",
    "\n",
    "#     train_loss /= len(train_loader)\n",
    "#     #print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
