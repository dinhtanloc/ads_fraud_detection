{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  \n",
    "print(torch.cuda.current_device())  \n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Data\\ads_fraud_detection\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "__script_path=os.path.abspath(globals().get('__file__','.'))\n",
    "__script_dir = os.path.dirname(__script_path)\n",
    "root_dir = os.path.abspath(f'{__script_dir}/../../../../..')\n",
    "print(root_dir)\n",
    "for lib in [root_dir][::-1]:\n",
    "    if lib in sys.path:\n",
    "        sys.path.remove(lib)\n",
    "    sys.path.insert(0,lib)\n",
    "from config.config import *\n",
    "# from libs.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=f\"{exps_dir}/exp1/exp_smote\"\n",
    "if os.path.exists(save_dir) == False: \n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6555772994129159, 1: 2.106918238993711}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "class_weights_dict=dict(np.load(f'{save_dir}/class_weights_dict.npz',allow_pickle=True))['class_weights_dict']\n",
    "class_weights_dict = {key: value for key, value in class_weights_dict.item().items()}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1022, 39]) torch.Size([1022, 1, 2]) torch.Size([330, 39]) torch.Size([330, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
    "num_classes = 2  # Assuming binary classification\n",
    "y_train = F.one_hot(y_train, num_classes=num_classes)\n",
    "y_test = F.one_hot(y_test, num_classes=num_classes)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 29.53251| val_0_unsup_loss_numpy: 91734.125|  0:00:00s\n",
      "epoch 1  | loss: 147.08255| val_0_unsup_loss_numpy: 5981.91796875|  0:00:00s\n",
      "epoch 2  | loss: 65.22984| val_0_unsup_loss_numpy: 347.4918518066406|  0:00:00s\n",
      "epoch 3  | loss: 21.57448| val_0_unsup_loss_numpy: 553.1861572265625|  0:00:00s\n",
      "epoch 4  | loss: 15.4741 | val_0_unsup_loss_numpy: 286.1898498535156|  0:00:00s\n",
      "epoch 5  | loss: 10.12379| val_0_unsup_loss_numpy: 146.8248748779297|  0:00:00s\n",
      "epoch 6  | loss: 7.87988 | val_0_unsup_loss_numpy: 44.57017135620117|  0:00:00s\n",
      "epoch 7  | loss: 4.95427 | val_0_unsup_loss_numpy: 44.70695877075195|  0:00:00s\n",
      "epoch 8  | loss: 3.78906 | val_0_unsup_loss_numpy: 35.38682174682617|  0:00:00s\n",
      "epoch 9  | loss: 3.04353 | val_0_unsup_loss_numpy: 24.55137062072754|  0:00:01s\n",
      "epoch 10 | loss: 2.60534 | val_0_unsup_loss_numpy: 21.95918083190918|  0:00:01s\n",
      "epoch 11 | loss: 2.40304 | val_0_unsup_loss_numpy: 20.599590301513672|  0:00:01s\n",
      "epoch 12 | loss: 2.15829 | val_0_unsup_loss_numpy: 10.312970161437988|  0:00:01s\n",
      "epoch 13 | loss: 1.91978 | val_0_unsup_loss_numpy: 11.203339576721191|  0:00:01s\n",
      "epoch 14 | loss: 1.76877 | val_0_unsup_loss_numpy: 9.208279609680176|  0:00:01s\n",
      "epoch 15 | loss: 1.62466 | val_0_unsup_loss_numpy: 4.604450225830078|  0:00:01s\n",
      "epoch 16 | loss: 1.57548 | val_0_unsup_loss_numpy: 2.970669984817505|  0:00:01s\n",
      "epoch 17 | loss: 1.52475 | val_0_unsup_loss_numpy: 4.819250106811523|  0:00:01s\n",
      "epoch 18 | loss: 1.42738 | val_0_unsup_loss_numpy: 3.017169952392578|  0:00:01s\n",
      "epoch 19 | loss: 1.32035 | val_0_unsup_loss_numpy: 5.972710132598877|  0:00:02s\n",
      "epoch 20 | loss: 1.31684 | val_0_unsup_loss_numpy: 3.9411299228668213|  0:00:02s\n",
      "epoch 21 | loss: 1.29611 | val_0_unsup_loss_numpy: 6.166800022125244|  0:00:02s\n",
      "epoch 22 | loss: 1.2675  | val_0_unsup_loss_numpy: 4.128119945526123|  0:00:02s\n",
      "epoch 23 | loss: 1.21248 | val_0_unsup_loss_numpy: 2.8689401149749756|  0:00:02s\n",
      "epoch 24 | loss: 1.19415 | val_0_unsup_loss_numpy: 1.9503999948501587|  0:00:02s\n",
      "epoch 25 | loss: 1.18664 | val_0_unsup_loss_numpy: 3.2872700691223145|  0:00:02s\n",
      "epoch 26 | loss: 1.15632 | val_0_unsup_loss_numpy: 1.8152799606323242|  0:00:02s\n",
      "epoch 27 | loss: 1.13995 | val_0_unsup_loss_numpy: 2.4816699028015137|  0:00:02s\n",
      "epoch 28 | loss: 1.12597 | val_0_unsup_loss_numpy: 6.730020046234131|  0:00:02s\n",
      "epoch 29 | loss: 1.13432 | val_0_unsup_loss_numpy: 2.0741701126098633|  0:00:02s\n",
      "epoch 30 | loss: 1.10314 | val_0_unsup_loss_numpy: 3.421950101852417|  0:00:02s\n",
      "epoch 31 | loss: 1.08903 | val_0_unsup_loss_numpy: 1.918910026550293|  0:00:03s\n",
      "epoch 32 | loss: 1.08901 | val_0_unsup_loss_numpy: 1.6220500469207764|  0:00:03s\n",
      "epoch 33 | loss: 1.07019 | val_0_unsup_loss_numpy: 3.796329975128174|  0:00:03s\n",
      "epoch 34 | loss: 1.0759  | val_0_unsup_loss_numpy: 2.4807798862457275|  0:00:03s\n",
      "epoch 35 | loss: 1.05291 | val_0_unsup_loss_numpy: 2.2633800506591797|  0:00:03s\n",
      "epoch 36 | loss: 1.04182 | val_0_unsup_loss_numpy: 1.2874499559402466|  0:00:03s\n",
      "epoch 37 | loss: 1.04555 | val_0_unsup_loss_numpy: 1.9453099966049194|  0:00:03s\n",
      "epoch 38 | loss: 1.05062 | val_0_unsup_loss_numpy: 1.3992500305175781|  0:00:03s\n",
      "epoch 39 | loss: 1.04512 | val_0_unsup_loss_numpy: 1.4176499843597412|  0:00:03s\n",
      "epoch 40 | loss: 1.03239 | val_0_unsup_loss_numpy: 1.4379500150680542|  0:00:03s\n",
      "epoch 41 | loss: 1.01706 | val_0_unsup_loss_numpy: 1.1536099910736084|  0:00:03s\n",
      "epoch 42 | loss: 1.02752 | val_0_unsup_loss_numpy: 2.1022400856018066|  0:00:04s\n",
      "epoch 43 | loss: 1.02369 | val_0_unsup_loss_numpy: 1.2365200519561768|  0:00:04s\n",
      "epoch 44 | loss: 1.00742 | val_0_unsup_loss_numpy: 1.1993900537490845|  0:00:04s\n",
      "epoch 45 | loss: 1.01407 | val_0_unsup_loss_numpy: 1.1032099723815918|  0:00:04s\n",
      "epoch 46 | loss: 1.0042  | val_0_unsup_loss_numpy: 1.800819993019104|  0:00:04s\n",
      "epoch 47 | loss: 1.01623 | val_0_unsup_loss_numpy: 1.1177599430084229|  0:00:04s\n",
      "epoch 48 | loss: 1.00933 | val_0_unsup_loss_numpy: 1.5143500566482544|  0:00:04s\n",
      "epoch 49 | loss: 1.00201 | val_0_unsup_loss_numpy: 1.147879958152771|  0:00:04s\n",
      "epoch 50 | loss: 1.00033 | val_0_unsup_loss_numpy: 1.1203099489212036|  0:00:04s\n",
      "epoch 51 | loss: 0.98974 | val_0_unsup_loss_numpy: 1.0885800123214722|  0:00:04s\n",
      "epoch 52 | loss: 0.99321 | val_0_unsup_loss_numpy: 1.055609941482544|  0:00:04s\n",
      "epoch 53 | loss: 0.97763 | val_0_unsup_loss_numpy: 1.0555599927902222|  0:00:05s\n",
      "epoch 54 | loss: 0.9943  | val_0_unsup_loss_numpy: 2.879159927368164|  0:00:05s\n",
      "epoch 55 | loss: 0.99396 | val_0_unsup_loss_numpy: 1.257159948348999|  0:00:05s\n",
      "epoch 56 | loss: 0.9887  | val_0_unsup_loss_numpy: 1.1045399904251099|  0:00:05s\n",
      "epoch 57 | loss: 0.98389 | val_0_unsup_loss_numpy: 1.3156299591064453|  0:00:05s\n",
      "epoch 58 | loss: 0.99209 | val_0_unsup_loss_numpy: 1.2005200386047363|  0:00:05s\n",
      "epoch 59 | loss: 0.98572 | val_0_unsup_loss_numpy: 1.082319974899292|  0:00:05s\n",
      "epoch 60 | loss: 0.98991 | val_0_unsup_loss_numpy: 1.0548800230026245|  0:00:05s\n",
      "epoch 61 | loss: 0.98195 | val_0_unsup_loss_numpy: 1.0298500061035156|  0:00:05s\n",
      "epoch 62 | loss: 0.9838  | val_0_unsup_loss_numpy: 1.1190600395202637|  0:00:05s\n",
      "epoch 63 | loss: 0.98249 | val_0_unsup_loss_numpy: 1.1189899444580078|  0:00:05s\n",
      "epoch 64 | loss: 0.97118 | val_0_unsup_loss_numpy: 1.0421099662780762|  0:00:06s\n",
      "epoch 65 | loss: 0.98361 | val_0_unsup_loss_numpy: 1.11627995967865|  0:00:06s\n",
      "epoch 66 | loss: 0.97107 | val_0_unsup_loss_numpy: 1.1315900087356567|  0:00:06s\n",
      "epoch 67 | loss: 0.994   | val_0_unsup_loss_numpy: 1.0898000001907349|  0:00:06s\n",
      "epoch 68 | loss: 0.98584 | val_0_unsup_loss_numpy: 1.1143200397491455|  0:00:06s\n",
      "epoch 69 | loss: 0.97981 | val_0_unsup_loss_numpy: 1.031350016593933|  0:00:06s\n",
      "epoch 70 | loss: 0.9817  | val_0_unsup_loss_numpy: 1.1109399795532227|  0:00:06s\n",
      "epoch 71 | loss: 0.97616 | val_0_unsup_loss_numpy: 0.995710015296936|  0:00:06s\n",
      "epoch 72 | loss: 0.96653 | val_0_unsup_loss_numpy: 1.0369000434875488|  0:00:06s\n",
      "epoch 73 | loss: 0.98232 | val_0_unsup_loss_numpy: 0.9919499754905701|  0:00:06s\n",
      "epoch 74 | loss: 0.96015 | val_0_unsup_loss_numpy: 0.9806600213050842|  0:00:06s\n",
      "epoch 75 | loss: 0.9753  | val_0_unsup_loss_numpy: 1.057360053062439|  0:00:06s\n",
      "epoch 76 | loss: 0.97155 | val_0_unsup_loss_numpy: 1.0078699588775635|  0:00:07s\n",
      "epoch 77 | loss: 0.96912 | val_0_unsup_loss_numpy: 1.0110100507736206|  0:00:07s\n",
      "epoch 78 | loss: 0.9642  | val_0_unsup_loss_numpy: 1.033370018005371|  0:00:07s\n",
      "epoch 79 | loss: 0.96647 | val_0_unsup_loss_numpy: 1.016950011253357|  0:00:07s\n",
      "epoch 80 | loss: 0.96468 | val_0_unsup_loss_numpy: 1.0079100131988525|  0:00:07s\n",
      "epoch 81 | loss: 0.96429 | val_0_unsup_loss_numpy: 1.0018999576568604|  0:00:07s\n",
      "epoch 82 | loss: 0.95704 | val_0_unsup_loss_numpy: 1.0027300119400024|  0:00:07s\n",
      "epoch 83 | loss: 0.97159 | val_0_unsup_loss_numpy: 1.001330018043518|  0:00:07s\n",
      "epoch 84 | loss: 0.97079 | val_0_unsup_loss_numpy: 0.9732099771499634|  0:00:07s\n",
      "epoch 85 | loss: 0.9669  | val_0_unsup_loss_numpy: 0.9809499979019165|  0:00:07s\n",
      "epoch 86 | loss: 0.95186 | val_0_unsup_loss_numpy: 1.0089800357818604|  0:00:08s\n",
      "epoch 87 | loss: 0.95779 | val_0_unsup_loss_numpy: 0.9831600189208984|  0:00:08s\n",
      "epoch 88 | loss: 0.96482 | val_0_unsup_loss_numpy: 1.0218000411987305|  0:00:08s\n",
      "epoch 89 | loss: 0.95869 | val_0_unsup_loss_numpy: 1.010890007019043|  0:00:08s\n",
      "epoch 90 | loss: 0.96108 | val_0_unsup_loss_numpy: 0.9980900287628174|  0:00:08s\n",
      "epoch 91 | loss: 0.95158 | val_0_unsup_loss_numpy: 1.0229500532150269|  0:00:08s\n",
      "epoch 92 | loss: 0.97204 | val_0_unsup_loss_numpy: 1.076799988746643|  0:00:08s\n",
      "epoch 93 | loss: 0.96845 | val_0_unsup_loss_numpy: 1.0242999792099|  0:00:08s\n",
      "epoch 94 | loss: 0.96878 | val_0_unsup_loss_numpy: 1.0393999814987183|  0:00:08s\n",
      "\n",
      "Early stopping occurred at epoch 94 with best_epoch = 84 and best_val_0_unsup_loss_numpy = 0.9732099771499634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "tabnet_params = {\n",
    "    \"n_d\": 512,\n",
    "    \"n_a\": 512,\n",
    "    \"n_steps\": 3,\n",
    "    \"n_shared\": 2,\n",
    "    \"n_independent\": 2,\n",
    "    \"gamma\": 1.3,\n",
    "    \"epsilon\": 1e-15,\n",
    "    \"momentum\": 0.98,\n",
    "    \"mask_type\": \"sparsemax\",\n",
    "    \"lambda_sparse\": 1e-3,\n",
    "    \"device_name\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    **tabnet_params\n",
    ")\n",
    " \n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train,\n",
    "    eval_set=[X_test],  \n",
    "    pretraining_ratio=0.8,\n",
    "    max_epochs=101,\n",
    "    patience=10,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "TabNetPretraining                                            [1022, 39]                --\n",
       "├─EmbeddingGenerator: 1-1                                    [1022, 39]                --\n",
       "├─TabNetEncoder: 1-2                                         [1022, 512]               --\n",
       "│    └─BatchNorm1d: 2-1                                      [1022, 39]                78\n",
       "│    └─FeatTransformer: 2-2                                  [1022, 1024]              4,202,496\n",
       "│    │    └─GLU_Block: 3-1                                   [1022, 1024]              2,185,216\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-6                                   [1022, 1024]              4,202,496\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-7                        [1022, 39]                20,046\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-8                             [1022, 1024]              6,387,712\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-13                       [1022, 39]                20,046\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-14                            [1022, 1024]              6,387,712\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-19                       [1022, 39]                20,046\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-20                            [1022, 1024]              6,387,712\n",
       "├─TabNetDecoder: 1-3                                         [1022, 39]                --\n",
       "│    └─ModuleList: 2-13                                      --                        --\n",
       "│    │    └─FeatTransformer: 3-21                            [1022, 512]               1,052,672\n",
       "│    │    └─FeatTransformer: 3-25                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-23                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-24                            [1022, 512]               1,052,672\n",
       "│    │    └─FeatTransformer: 3-25                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-26                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-27                            [1022, 512]               1,052,672\n",
       "│    └─Linear: 2-14                                          [1022, 39]                19,968\n",
       "==============================================================================================================\n",
       "Total params: 51,482,936\n",
       "Trainable params: 51,482,936\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 29.42\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.16\n",
       "Forward/backward pass size (MB): 638.84\n",
       "Params size (MB): 84.84\n",
       "Estimated Total Size (MB): 723.84\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truy cập vào mô hình TabNet bên trong\n",
    "from torchinfo import summary\n",
    "\n",
    "tabnet_model = unsupervised_model.network.to(device)\n",
    "\n",
    "summary(tabnet_model, input_size=X_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoder Summary:\n",
      "TabNetEncoder(\n",
      "  (initial_bn): BatchNorm1d(39, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "  (initial_splitter): FeatTransformer(\n",
      "    (shared): GLU_Block(\n",
      "      (shared_layers): ModuleList(\n",
      "        (0): Linear(in_features=39, out_features=2048, bias=False)\n",
      "        (1): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "      )\n",
      "      (glu_layers): ModuleList(\n",
      "        (0): GLU_Layer(\n",
      "          (fc): Linear(in_features=39, out_features=2048, bias=False)\n",
      "          (bn): GBN(\n",
      "            (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): GLU_Layer(\n",
      "          (fc): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "          (bn): GBN(\n",
      "            (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (specifics): GLU_Block(\n",
      "      (glu_layers): ModuleList(\n",
      "        (0-1): 2 x GLU_Layer(\n",
      "          (fc): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "          (bn): GBN(\n",
      "            (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feat_transformers): ModuleList(\n",
      "    (0-2): 3 x FeatTransformer(\n",
      "      (shared): GLU_Block(\n",
      "        (shared_layers): ModuleList(\n",
      "          (0): Linear(in_features=39, out_features=2048, bias=False)\n",
      "          (1): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "        )\n",
      "        (glu_layers): ModuleList(\n",
      "          (0): GLU_Layer(\n",
      "            (fc): Linear(in_features=39, out_features=2048, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): GLU_Layer(\n",
      "            (fc): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (specifics): GLU_Block(\n",
      "        (glu_layers): ModuleList(\n",
      "          (0-1): 2 x GLU_Layer(\n",
      "            (fc): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (att_transformers): ModuleList(\n",
      "    (0-2): 3 x AttentiveTransformer(\n",
      "      (fc): Linear(in_features=512, out_features=39, bias=False)\n",
      "      (bn): GBN(\n",
      "        (bn): BatchNorm1d(39, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (selector): Sparsemax()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = tabnet_model.encoder\n",
    "\n",
    "print(\"\\nEncoder Summary:\")\n",
    "print(encoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoder Summary:\n",
      "TabNetDecoder(\n",
      "  (feat_transformers): ModuleList(\n",
      "    (0-2): 3 x FeatTransformer(\n",
      "      (shared): GLU_Block(\n",
      "        (shared_layers): ModuleList(\n",
      "          (0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        )\n",
      "        (glu_layers): ModuleList(\n",
      "          (0): GLU_Layer(\n",
      "            (fc): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (specifics): GLU_Block(\n",
      "        (glu_layers): ModuleList(\n",
      "          (0): GLU_Layer(\n",
      "            (fc): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (reconstruction_layer): Linear(in_features=512, out_features=39, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "decoder = tabnet_model.decoder\n",
    "\n",
    "print(\"\\nDecoder Summary:\")\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNet encoder trả về 2 giá trị.\n",
      "Đã xảy ra lỗi: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_15368\\3356785120.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample_input = torch.tensor(X_train[:5]).to(device)\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.tensor(X_train[:5]).to(device)  \n",
    "\n",
    "try:\n",
    "    result = tabnet_model.encoder(sample_input)\n",
    "    if isinstance(result, tuple):\n",
    "        print(f'TabNet encoder trả về {len(result)} giá trị.')\n",
    "        for i, res in enumerate(result):\n",
    "            print(f'Giá trị {i + 1} shape: {res.shape}')\n",
    "    else:\n",
    "        print('TabNet encoder chỉ trả về một giá trị.')\n",
    "        print(f'Giá trị shape: {result.shape}')\n",
    "except Exception as e:\n",
    "    print(f'Đã xảy ra lỗi: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(nn.Module):\n",
    "    def __init__(self, seed=1337):\n",
    "        super(Sampling, self).__init__()\n",
    "        self.seed = seed\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = z_mean.size(0)\n",
    "        dim = z_mean.size(1)\n",
    "        # print(batch, dim)\n",
    "        epsilon = torch.randn(batch, dim, generator=torch.Generator().manual_seed(self.seed)).to(device)\n",
    "        return z_mean + torch.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VAE_Encoder(nn.Module):\n",
    "#     def __init__(self, latent_dim):\n",
    "#         super(VAE_Encoder, self).__init__()\n",
    "#         self.tabnet_encoder = tabnet_model.encoder\n",
    "#         self.mlp = nn.Sequential(\n",
    "#             nn.Linear(512, 256),  \n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 96),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(96, 96),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(96, 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32, latent_dim)\n",
    "#         ).to(device)\n",
    "#         self.fc_mean = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "#         self.fc_log_var = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "#         self.sampling = Sampling().to(device)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.to(device)\n",
    "#         steps_output, _ = self.tabnet_encoder(x)\n",
    "#         encoded = steps_output[-1]\n",
    "#         # print(\"Shape of encoded tensor:\", encoded.shape)\n",
    "#         encoded = self.mlp(encoded)\n",
    "#         z_mean = self.fc_mean(encoded)\n",
    "#         z_log_var = self.fc_log_var(encoded)\n",
    "#         z = self.sampling((z_mean, z_log_var))\n",
    "#         # print(f'Shape of z: {z.shape} - {z_log_var.shape} -{z_log_var.shape}')\n",
    "#         return z_mean, z_log_var, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE_Encoder, self).__init__()\n",
    "        self.tabnet_encoder = tabnet_model.encoder\n",
    "\n",
    "        self.mlp_0 = nn.Sequential(\n",
    "            nn.Linear(512, 256),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        ).to(device)\n",
    "\n",
    "        self.mlp_1 = nn.Sequential(\n",
    "            nn.Linear(512, 256),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        ).to(device)\n",
    "\n",
    "        self.fc_mean_0 = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "        self.fc_log_var_0 = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "\n",
    "        self.fc_mean_1 = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "        self.fc_log_var_1 = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "\n",
    "        self.sampling = Sampling().to(device)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        steps_output, _ = self.tabnet_encoder(x)\n",
    "        encoded = steps_output[-1]\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        latent_dim = self.fc_mean_0.out_features\n",
    "\n",
    "        z_mean = torch.zeros(batch_size, latent_dim).to(device)\n",
    "        z_log_var = torch.zeros(batch_size, latent_dim).to(device)\n",
    "        z = torch.zeros(batch_size, latent_dim).to(device)\n",
    "\n",
    "        idx_0 = (labels == 0)\n",
    "        idx_1 = (labels == 1)\n",
    "\n",
    "        if idx_0.sum() > 0:\n",
    "            encoded_0 = encoded[idx_0]\n",
    "            out_0 = self.mlp_0(encoded_0)\n",
    "            mu_0 = self.fc_mean_0(out_0)\n",
    "            logvar_0 = self.fc_log_var_0(out_0)\n",
    "            z_0 = self.sampling((mu_0, logvar_0))\n",
    "\n",
    "            z_mean[idx_0] = mu_0\n",
    "            z_log_var[idx_0] = logvar_0\n",
    "            z[idx_0] = z_0\n",
    "\n",
    "        if idx_1.sum() > 0:\n",
    "            encoded_1 = encoded[idx_1]\n",
    "            out_1 = self.mlp_1(encoded_1)\n",
    "            mu_1 = self.fc_mean_1(out_1)\n",
    "            logvar_1 = self.fc_log_var_1(out_1)\n",
    "            z_1 = self.sampling((mu_1, logvar_1))\n",
    "\n",
    "            z_mean[idx_1] = mu_1\n",
    "            z_log_var[idx_1] = logvar_1\n",
    "            z[idx_1] = z_1\n",
    "\n",
    "        return z_mean, z_log_var, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim,encoded_dim, output_dim):\n",
    "        super(VAE_Decoder, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),   \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, encoded_dim),  \n",
    "        )\n",
    "        self.tabnet_decoder = tabnet_model.decoder\n",
    "        self.reshape = nn.Unflatten(1, (encoded_dim,))\n",
    "        self.output_dim=output_dim\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = F.relu(self.mlp(z))\n",
    "\n",
    "        # print(\"Shape before reshape:\", x.shape)\n",
    "        x = self.reshape(x)\n",
    "        x = x[None, ...]\n",
    "\n",
    "        # print(\"Shape after reshape:\", x.shape)\n",
    "        # x = x.view(x.size(0), output_dim)\n",
    "        \n",
    "        output = self.tabnet_decoder(x)\n",
    "        # print(output.shape)\n",
    "        # print(\"Shape of output from tabnet_decoder:\", output.shape)\n",
    "        output = torch.softmax(output, dim=-1)  # Assuming the output is a probability distribution\n",
    "        output = output.view(-1, self.output_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_range(tensor, name):\n",
    "    if not torch.all((tensor >= 0) & (tensor <= 1)):\n",
    "        print(f\"{name} contains values outside the range [0, 1]\")\n",
    "        print(f\"{name} min: {tensor.min()}, max: {tensor.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Tabnet_MLPS(nn.Module):\n",
    "    def __init__(self, encoder, decoder, classifier):\n",
    "        super(VAE_Tabnet_MLPS, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.classifier = classifier\n",
    "        self.total_loss_tracker = []\n",
    "        self.reconstruction_loss_tracker = []\n",
    "        self.kl_loss_tracker = []\n",
    "        self.classification_loss_tracker = []\n",
    "        self.accuracy_tracker = []\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        z_mean, z_log_var, z = self.encoder(x, labels)\n",
    "        reconstruction = self.decoder(z)\n",
    "        classification_output = self.classifier(z)\n",
    "        return reconstruction, z_mean, z_log_var, classification_output\n",
    "\n",
    "    def train_step(self, data, labels, optimizer):\n",
    "        labels = labels.squeeze(1) \n",
    "        labels = torch.argmax(labels, dim=1).long()\n",
    "        labels = labels.to(device)\n",
    "        # print(f\"Shape of labels: {labels.shape}\")\n",
    "        # optimizer.zero_grad()\n",
    "        # z_mean, z_log_var, z = self.encoder(data)\n",
    "        # reconstruction = self.decoder(z)\n",
    "        reconstruction, z_mean, z_log_var, classification_output = self.forward(data, labels)\n",
    "        # print('classifi',classification_output.shape)\n",
    "        # print(check_data_range(data, 'data'))\n",
    "        # print(check_data_range(reconstruction, 'reconstruction'))\n",
    "        # reconstruction_loss = torch.mean(\n",
    "        #     torch.sum(\n",
    "        #         F.binary_cross_entropy(reconstruction, data, reduction='none'),\n",
    "        #         dim=1\n",
    "        #     )\n",
    "        # )\n",
    "        reconstruction_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                F.binary_cross_entropy_with_logits(reconstruction, data, reduction='none'),\n",
    "                dim=1\n",
    "                # dim=(1, 2)\n",
    "                )  \n",
    "        )\n",
    "\n",
    "        # print(\"labels:\", labels)\n",
    "        # print(\"labels.shape:\", labels.shape)\n",
    "        # print(\"labels.dtype:\", labels.dtype)\n",
    "        # print(\"labels.min():\", labels.min().item(), \"labels.max():\", labels.max().item())\n",
    "        # print(\"classification_output.shape:\", classification_output.shape)\n",
    "\n",
    "        classification_loss = F.cross_entropy(classification_output, labels)\n",
    "                # dim=1\n",
    "                # dim=(1, 2)\n",
    "                \n",
    "        \n",
    "        kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=1)\n",
    "        kl_loss = torch.mean(torch.sum(kl_loss))\n",
    "        total_loss = reconstruction_loss + kl_loss + classification_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        self.total_loss_tracker.append(total_loss.item())\n",
    "        self.reconstruction_loss_tracker.append(reconstruction_loss.item())\n",
    "        self.kl_loss_tracker.append(kl_loss.item())\n",
    "        self.classification_loss_tracker.append(classification_loss.item())\n",
    "        # print(classification_output.shape, labels.shape)\n",
    "\n",
    "        preds = torch.softmax(classification_output, dim=1)\n",
    "        pred_labels = torch.argmax(preds, dim=1)\n",
    "        correct = (pred_labels == labels).float().sum()\n",
    "        accuracy = correct / labels.size(0)\n",
    "        self.accuracy_tracker.append(accuracy.item())\n",
    "\n",
    "        return {\n",
    "            \"loss\": total_loss.item(),\n",
    "            \"reconstruction_loss\": reconstruction_loss.item(),\n",
    "            \"kl_loss\": kl_loss.item(),\n",
    "            \"classification_loss\": classification_loss.item(),\n",
    "            \"accuracy\": accuracy.item()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "encoded_dim = 512\n",
    "output_dim = X_train.shape[1]\n",
    "input_dim = X_train.shape[1]\n",
    "print(input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(32, output_dim),\n",
    "            # nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('input: ',x.shape)\n",
    "        output = self.fc_layers(x)\n",
    "        # output = output.view(-1)\n",
    "        # print('output',output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SimpleClassifier(latent_dim, output_dim=2).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([32, 64])\n",
      "Output size: torch.Size([32, 1])\n",
      "Output: tensor([[ 0.2251],\n",
      "        [-0.0212],\n",
      "        [-1.0684],\n",
      "        [-0.6204],\n",
      "        [-0.8287],\n",
      "        [ 0.1150],\n",
      "        [-0.6822],\n",
      "        [-0.4576],\n",
      "        [-0.5331],\n",
      "        [-0.1956],\n",
      "        [-0.1393],\n",
      "        [-0.2319],\n",
      "        [-0.4192],\n",
      "        [-0.3321],\n",
      "        [ 0.0387],\n",
      "        [ 0.1634],\n",
      "        [-1.0403],\n",
      "        [-0.5110],\n",
      "        [-0.7737],\n",
      "        [ 0.4728],\n",
      "        [-0.9170],\n",
      "        [-1.0290],\n",
      "        [-0.2032],\n",
      "        [-0.1186],\n",
      "        [-0.6675],\n",
      "        [-0.1837],\n",
      "        [-0.2925],\n",
      "        [-0.0863],\n",
      "        [-0.5102],\n",
      "        [-0.2662],\n",
      "        [-0.2039],\n",
      "        [-0.2969]])\n"
     ]
    }
   ],
   "source": [
    "def check_output(model, input_tensor):\n",
    "    with torch.no_grad():  \n",
    "        output = model(input_tensor)\n",
    "        print(f\"Input size: {input_tensor.size()}\")\n",
    "        print(f\"Output size: {output.size()}\")\n",
    "        print(f\"Output: {output}\")\n",
    "\n",
    "model = SimpleClassifier(latent_dim, output_dim=1)\n",
    "\n",
    "input_tensor = torch.randn(32,latent_dim)  \n",
    "\n",
    "check_output(model, input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_encoder = VAE_Encoder(latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae_encoder = VAE_Encoder(latent_dim=latent_dim)\n",
    "# print(\"Encoder Summary:\")\n",
    "# # vae_encoder.to(device)\n",
    "\n",
    "# summary(vae_encoder, input_size=(32, input_dim), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shape: torch.Size([800, 512])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(800,39 ).to(device)\n",
    "steps_output, _ = tabnet_model.encoder(x)\n",
    "encoded = steps_output[-1]\n",
    "print(f\"Encoded shape: {encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoder output: [torch.Size([800, 512]), torch.Size([800, 512]), torch.Size([800, 512])]\n",
      "Decoder shape: torch.Size([800, 39])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(800, 39).to(device)  # Đầu vào có kích thước (batch_size, features)\n",
    "\n",
    "steps_output, _ = tabnet_model.encoder(x)\n",
    "print(\"Shape of encoder output:\", [output.shape for output in steps_output])\n",
    "\n",
    "decoder_input = steps_output[-1]  \n",
    "decoder_input = decoder_input[None, ...]\n",
    "try:\n",
    "    decoder_output = tabnet_model.decoder(decoder_input)\n",
    "    print(f\"Decoder shape: {decoder_output.shape}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 39)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "VAE_Decoder                                                  [32, 39]                  --\n",
       "├─Sequential: 1-1                                            [32, 512]                 --\n",
       "│    └─Linear: 2-1                                           [32, 32]                  2,080\n",
       "│    └─ReLU: 2-2                                             [32, 32]                  --\n",
       "│    └─Linear: 2-3                                           [32, 96]                  3,168\n",
       "│    └─ReLU: 2-4                                             [32, 96]                  --\n",
       "│    └─Linear: 2-5                                           [32, 96]                  9,312\n",
       "│    └─ReLU: 2-6                                             [32, 96]                  --\n",
       "│    └─Linear: 2-7                                           [32, 128]                 12,416\n",
       "│    └─ReLU: 2-8                                             [32, 128]                 --\n",
       "│    └─Linear: 2-9                                           [32, 256]                 33,024\n",
       "│    └─ReLU: 2-10                                            [32, 256]                 --\n",
       "│    └─Linear: 2-11                                          [32, 512]                 131,584\n",
       "├─Unflatten: 1-2                                             [32, 512]                 --\n",
       "├─TabNetDecoder: 1-3                                         [32, 39]                  --\n",
       "│    └─ModuleList: 2-12                                      --                        --\n",
       "│    │    └─FeatTransformer: 3-1                             [32, 512]                 1,052,672\n",
       "│    │    └─FeatTransformer: 3-2                             --                        1,052,672\n",
       "│    │    └─FeatTransformer: 3-3                             --                        (recursive)\n",
       "│    └─Linear: 2-13                                          [32, 39]                  19,968\n",
       "==============================================================================================================\n",
       "Total params: 2,845,280\n",
       "Trainable params: 2,845,280\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 40.46\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.35\n",
       "Params size (MB): 5.06\n",
       "Estimated Total Size (MB): 6.41\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_decoder = VAE_Decoder(latent_dim=latent_dim, encoded_dim=encoded_dim, output_dim=output_dim).to(device)\n",
    "print(\"Decoder Summary:\")\n",
    "summary(vae_decoder, input_size=(32, latent_dim), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE_Tabnet_MLPS(encoder=vae_encoder, decoder=vae_decoder,classifier=classifier).to(device)\n",
    "# summary(vae, input_size=(32, input_dim), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 22.5496, Reconstruction Loss: 11.7630, KL Loss: 10.0801, Classification Loss: 0.7065, Accuracy: 0.5167\n",
      "Epoch 2/10, Loss: 15.7452, Reconstruction Loss: 10.0034, KL Loss: 5.0573, Classification Loss: 0.6845, Accuracy: 0.5498\n",
      "Epoch 3/10, Loss: 12.0356, Reconstruction Loss: 9.1090, KL Loss: 2.2242, Classification Loss: 0.7024, Accuracy: 0.5421\n",
      "Epoch 4/10, Loss: 10.8429, Reconstruction Loss: 8.7973, KL Loss: 1.3292, Classification Loss: 0.7165, Accuracy: 0.5068\n",
      "Epoch 5/10, Loss: 10.6935, Reconstruction Loss: 8.7474, KL Loss: 1.2341, Classification Loss: 0.7119, Accuracy: 0.5040\n",
      "Epoch 6/10, Loss: 10.7532, Reconstruction Loss: 8.7077, KL Loss: 1.3402, Classification Loss: 0.7054, Accuracy: 0.5027\n",
      "Epoch 7/10, Loss: 10.7184, Reconstruction Loss: 8.7038, KL Loss: 1.3126, Classification Loss: 0.7020, Accuracy: 0.5087\n",
      "Epoch 8/10, Loss: 10.6552, Reconstruction Loss: 8.6939, KL Loss: 1.2567, Classification Loss: 0.7046, Accuracy: 0.4934\n",
      "Epoch 9/10, Loss: 10.5301, Reconstruction Loss: 8.6982, KL Loss: 1.1374, Classification Loss: 0.6945, Accuracy: 0.5128\n",
      "Epoch 10/10, Loss: 10.4537, Reconstruction Loss: 8.6914, KL Loss: 1.0637, Classification Loss: 0.6986, Accuracy: 0.4844\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    rec_loss = 0\n",
    "    kl_loss = 0\n",
    "    classification_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        # print(f\"Batch data shape: {batch_data.shape}, Batch labels shape: {batch_labels.shape}\")\n",
    "        results = vae.train_step(batch_data, batch_labels, optimizer)\n",
    "        \n",
    "        train_loss += results[\"loss\"]\n",
    "        rec_loss += results[\"reconstruction_loss\"]\n",
    "        kl_loss += results[\"kl_loss\"]\n",
    "        classification_loss += results[\"classification_loss\"]\n",
    "        accuracy += results[\"accuracy\"]\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    rec_loss /= len(train_loader)\n",
    "    kl_loss /= len(train_loader)\n",
    "    classification_loss /= len(train_loader)\n",
    "    accuracy /= len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Reconstruction Loss: {rec_loss:.4f}, KL Loss: {kl_loss:.4f}, Classification Loss: {classification_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vae.encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 10.3270, Reconstruction Loss: 8.6919, KL Loss: 0.9367, Classification Loss: 0.6984, Accuracy: 0.4913\n",
      "Epoch 2/10, Loss: 10.3347, Reconstruction Loss: 8.7012, KL Loss: 0.9367, Classification Loss: 0.6968, Accuracy: 0.5119\n",
      "Epoch 3/10, Loss: 10.3273, Reconstruction Loss: 8.6925, KL Loss: 0.9362, Classification Loss: 0.6986, Accuracy: 0.4904\n",
      "Epoch 4/10, Loss: 10.3295, Reconstruction Loss: 8.6983, KL Loss: 0.9363, Classification Loss: 0.6950, Accuracy: 0.4921\n",
      "Epoch 5/10, Loss: 10.3268, Reconstruction Loss: 8.6959, KL Loss: 0.9373, Classification Loss: 0.6936, Accuracy: 0.5060\n",
      "Epoch 6/10, Loss: 10.3248, Reconstruction Loss: 8.6923, KL Loss: 0.9364, Classification Loss: 0.6960, Accuracy: 0.4930\n",
      "Epoch 7/10, Loss: 10.3202, Reconstruction Loss: 8.6888, KL Loss: 0.9362, Classification Loss: 0.6952, Accuracy: 0.4862\n",
      "Epoch 8/10, Loss: 10.3277, Reconstruction Loss: 8.6999, KL Loss: 0.9370, Classification Loss: 0.6908, Accuracy: 0.5302\n",
      "Epoch 9/10, Loss: 10.3282, Reconstruction Loss: 8.6971, KL Loss: 0.9364, Classification Loss: 0.6947, Accuracy: 0.5020\n",
      "Epoch 10/10, Loss: 10.3320, Reconstruction Loss: 8.7022, KL Loss: 0.9371, Classification Loss: 0.6926, Accuracy: 0.5040\n"
     ]
    }
   ],
   "source": [
    "vae_new = VAE_Tabnet_MLPS(vae.encoder, vae.decoder, vae.classifier).to(device)\n",
    "for param in vae_new.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, vae_new.parameters()), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    vae_new.train()\n",
    "    train_loss = 0\n",
    "    rec_loss = 0\n",
    "    kl_loss = 0\n",
    "    classification_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        results = vae.train_step(batch_data, batch_labels, optimizer)\n",
    "        \n",
    "        train_loss += results[\"loss\"]\n",
    "        rec_loss += results[\"reconstruction_loss\"]\n",
    "        kl_loss += results[\"kl_loss\"]\n",
    "        classification_loss += results[\"classification_loss\"]\n",
    "        accuracy += results[\"accuracy\"]\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    rec_loss /= len(train_loader)\n",
    "    kl_loss /= len(train_loader)\n",
    "    classification_loss /= len(train_loader)\n",
    "    accuracy /= len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Reconstruction Loss: {rec_loss:.4f}, KL Loss: {kl_loss:.4f}, Classification Loss: {classification_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleDiffusionModel(nn.Module):\n",
    "    def __init__(self, latent_dim, time_steps=1000):\n",
    "        super().__init__()\n",
    "        self.time_steps = time_steps\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Tạo các beta_schedule tuyến tính\n",
    "        beta = torch.linspace(0.0001, 0.02, time_steps)\n",
    "        alpha = 1. - beta\n",
    "        alpha_bar = torch.cumprod(alpha, dim=0)\n",
    "\n",
    "        self.register_buffer('beta', beta)\n",
    "        self.register_buffer('alpha', alpha)\n",
    "        self.register_buffer('alpha_bar', alpha_bar)\n",
    "\n",
    "        # Mạng neural đơn giản để dự đoán nhiễu\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim + 1, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z, t):\n",
    "        noise = torch.randn_like(z)\n",
    "        \n",
    "        # Đảm bảo t là long type và shape phù hợp\n",
    "        if isinstance(t, torch.Tensor):\n",
    "            t = t.to(dtype=torch.long)\n",
    "        else:\n",
    "            t = torch.tensor([t], device=z.device, dtype=torch.long).expand(z.shape[0])\n",
    "\n",
    "        sqrt_alpha_bar = torch.sqrt(self.alpha_bar[t])[:, None]\n",
    "        sqrt_one_minus_alpha_bar = torch.sqrt(1 - self.alpha_bar[t])[:, None]\n",
    "        noisy_z = sqrt_alpha_bar * z + sqrt_one_minus_alpha_bar * noise\n",
    "\n",
    "        predicted_noise = self.model(torch.cat([noisy_z, t.unsqueeze(1)], dim=1))\n",
    "        loss = F.mse_loss(predicted_noise, noise)\n",
    "        return loss\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        z = torch.randn(num_samples, self.latent_dim).to(next(self.parameters()).device)\n",
    "        for i in reversed(range(self.time_steps)):\n",
    "            t = torch.full((num_samples,), i, device=z.device, dtype=torch.long)\n",
    "            z = self.denoise_step(z, t)\n",
    "        return z\n",
    "    \n",
    "    def denoise_step(self, z, t):\n",
    "        timestep = t.item() if isinstance(t, torch.Tensor) else t\n",
    "        t_batch = torch.full((z.shape[0],), timestep, device=z.device, dtype=torch.long)\n",
    "\n",
    "        predicted_noise = self.model(torch.cat([z, t_batch.unsqueeze(1)], dim=1))\n",
    "\n",
    "        alpha = self.alpha[timestep]\n",
    "        alpha_bar = self.alpha_bar[timestep]\n",
    "        beta = self.beta[timestep]\n",
    "\n",
    "        z = (1 / torch.sqrt(alpha)) * (z - ((1 - alpha) / torch.sqrt(1 - alpha_bar)) * predicted_noise)\n",
    "        if timestep > 0:\n",
    "            noise = torch.randn_like(z)\n",
    "            z += torch.sqrt(beta) * noise\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thay đoạn lỗi này:\n",
    "# latent_dim = vae.encoder[-1].out_features\n",
    "\n",
    "# Bằng đoạn này:\n",
    "with torch.no_grad():\n",
    "    vae_new.encoder.eval()\n",
    "    dummy_input = torch.randn(1, input_dim).to(device)  # Thay input_dim theo đúng dữ liệu của bạn\n",
    "    dummy_labels = torch.zeros(1, dtype=torch.long).to(device)\n",
    "    z_mean, z_log_var, _ = vae_new.encoder(dummy_input, dummy_labels)\n",
    "    latent_dim = z_mean.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_dim = vae.encoder[-1].out_features  # Kích thước latent z\n",
    "diffusion_model = SimpleDiffusionModel(latent_dim=latent_dim).to(device)\n",
    "diffusion_optimizer = torch.optim.Adam(diffusion_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_diffusion(vae, diffusion_model, dataloader, optimizer, device, time_steps=1000, epochs=150):\n",
    "    diffusion_model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_data, batch_labels in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.squeeze().to(device)\n",
    "            if batch_labels.dim() > 1:  # nếu là one-hot hoặc có chiều phụ\n",
    "                batch_labels = batch_labels.argmax(dim=1)\n",
    "            with torch.no_grad():\n",
    "                z_mean, z_log_var, z = vae.encoder(batch_data, batch_labels)\n",
    "\n",
    "            t = torch.randint(0, time_steps, (z.shape[0],), device=device).long()\n",
    "            loss = diffusion_model(z, t)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Diffusion Loss: {total_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_diffusion_with_classifier(vae, diffusion_model, classifier, test_loader, device, time_steps=1000):\n",
    "    vae.eval()\n",
    "    diffusion_model.eval()\n",
    "    classifier.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in test_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.squeeze().to(device)\n",
    "            if batch_labels.ndim == 3 and batch_labels.shape[1] == 1:\n",
    "                batch_labels = batch_labels.squeeze(1)  # bỏ chiều 1\n",
    "\n",
    "            if batch_labels.ndim == 2 and batch_labels.shape[1] == 2:\n",
    "                batch_labels = torch.argmax(batch_labels, dim=1)\n",
    "            elif batch_labels.ndim == 2 and batch_labels.shape[1] == 1:\n",
    "                batch_labels = batch_labels.squeeze(1)\n",
    "\n",
    "            z_mean, z_log_var, z = vae.encoder(batch_data, batch_labels)\n",
    "\n",
    "            t_forward = time_steps - 1\n",
    "            sqrt_alpha_bar = torch.sqrt(diffusion_model.alpha_bar[t_forward])\n",
    "            sqrt_one_minus_alpha_bar = torch.sqrt(1 - diffusion_model.alpha_bar[t_forward])\n",
    "            noisy_z = sqrt_alpha_bar * z + sqrt_one_minus_alpha_bar * torch.randn_like(z)\n",
    "\n",
    "            z_recovered = noisy_z\n",
    "            for t in reversed(range(time_steps)):\n",
    "                z_recovered = diffusion_model.denoise_step(z_recovered, t)\n",
    "            logits = classifier(z_recovered)\n",
    "\n",
    "            # print(\"Logits shape:\", logits.shape)  # Debug\n",
    "\n",
    "            if len(logits.shape) == 1:\n",
    "                preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            elif len(logits.shape) == 2:\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected logits shape: {logits.shape}\")\n",
    "\n",
    "            # print(f\"preds shape: {preds.shape}, batch_labels shape: {batch_labels.shape}\")  # Debug\n",
    "\n",
    "            correct += (preds == batch_labels).sum().item()\n",
    "            total += batch_labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy on recovered z: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150: 100%|██████████| 32/32 [00:00<00:00, 103.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Diffusion Loss: 33.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/150: 100%|██████████| 32/32 [00:00<00:00, 102.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Diffusion Loss: 1.9369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/150: 100%|██████████| 32/32 [00:00<00:00, 109.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Diffusion Loss: 1.0284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/150: 100%|██████████| 32/32 [00:00<00:00, 112.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Diffusion Loss: 0.9629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/150: 100%|██████████| 32/32 [00:00<00:00, 109.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Diffusion Loss: 0.8899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/150: 100%|██████████| 32/32 [00:00<00:00, 108.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Diffusion Loss: 0.8317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/150: 100%|██████████| 32/32 [00:00<00:00, 105.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Diffusion Loss: 0.7904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/150: 100%|██████████| 32/32 [00:00<00:00, 105.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Diffusion Loss: 0.7352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/150: 100%|██████████| 32/32 [00:00<00:00, 110.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Diffusion Loss: 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/150: 100%|██████████| 32/32 [00:00<00:00, 105.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Diffusion Loss: 0.6148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/150: 100%|██████████| 32/32 [00:00<00:00, 107.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Diffusion Loss: 0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/150: 100%|██████████| 32/32 [00:00<00:00, 107.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Diffusion Loss: 0.5289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/150: 100%|██████████| 32/32 [00:00<00:00, 109.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Diffusion Loss: 0.4756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/150: 100%|██████████| 32/32 [00:00<00:00, 107.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Diffusion Loss: 0.4505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/150: 100%|██████████| 32/32 [00:00<00:00, 108.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Diffusion Loss: 0.4243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/150: 100%|██████████| 32/32 [00:00<00:00, 107.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Diffusion Loss: 0.3855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/150: 100%|██████████| 32/32 [00:00<00:00, 108.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Diffusion Loss: 0.3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/150: 100%|██████████| 32/32 [00:00<00:00, 104.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Diffusion Loss: 0.3358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/150: 100%|██████████| 32/32 [00:00<00:00, 107.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Diffusion Loss: 0.3154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/150: 100%|██████████| 32/32 [00:00<00:00, 103.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Diffusion Loss: 0.3164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/150: 100%|██████████| 32/32 [00:00<00:00, 106.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Diffusion Loss: 0.2854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/150: 100%|██████████| 32/32 [00:00<00:00, 109.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Diffusion Loss: 0.2595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/150: 100%|██████████| 32/32 [00:00<00:00, 109.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Diffusion Loss: 0.2693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/150: 100%|██████████| 32/32 [00:00<00:00, 105.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Diffusion Loss: 0.2452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/150: 100%|██████████| 32/32 [00:00<00:00, 104.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Diffusion Loss: 0.2270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/150: 100%|██████████| 32/32 [00:00<00:00, 106.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Diffusion Loss: 0.2193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/150: 100%|██████████| 32/32 [00:00<00:00, 103.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Diffusion Loss: 0.2305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/150: 100%|██████████| 32/32 [00:00<00:00, 106.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Diffusion Loss: 0.2047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/150: 100%|██████████| 32/32 [00:00<00:00, 108.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Diffusion Loss: 0.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/150: 100%|██████████| 32/32 [00:00<00:00, 109.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Diffusion Loss: 0.1928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/150: 100%|██████████| 32/32 [00:00<00:00, 109.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Diffusion Loss: 0.1898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/150: 100%|██████████| 32/32 [00:00<00:00, 103.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Diffusion Loss: 0.1804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/150: 100%|██████████| 32/32 [00:00<00:00, 109.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Diffusion Loss: 0.2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/150: 100%|██████████| 32/32 [00:00<00:00, 111.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Diffusion Loss: 0.1870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/150: 100%|██████████| 32/32 [00:00<00:00, 101.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Diffusion Loss: 0.1883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/150: 100%|██████████| 32/32 [00:00<00:00, 111.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Diffusion Loss: 0.2163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/150: 100%|██████████| 32/32 [00:00<00:00, 105.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Diffusion Loss: 0.1879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/150: 100%|██████████| 32/32 [00:00<00:00, 110.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Diffusion Loss: 0.1829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/150: 100%|██████████| 32/32 [00:00<00:00, 107.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Diffusion Loss: 0.1731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/150: 100%|██████████| 32/32 [00:00<00:00, 102.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Diffusion Loss: 0.1792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/150: 100%|██████████| 32/32 [00:00<00:00, 107.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Diffusion Loss: 0.1734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/150: 100%|██████████| 32/32 [00:00<00:00, 108.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Diffusion Loss: 0.1753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/150: 100%|██████████| 32/32 [00:00<00:00, 106.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Diffusion Loss: 0.1832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/150: 100%|██████████| 32/32 [00:00<00:00, 109.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Diffusion Loss: 0.1702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/150: 100%|██████████| 32/32 [00:00<00:00, 106.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Diffusion Loss: 0.1603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/150: 100%|██████████| 32/32 [00:00<00:00, 109.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Diffusion Loss: 0.1746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/150: 100%|██████████| 32/32 [00:00<00:00, 108.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Diffusion Loss: 0.1646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/150: 100%|██████████| 32/32 [00:00<00:00, 107.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Diffusion Loss: 0.1641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/150: 100%|██████████| 32/32 [00:00<00:00, 105.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Diffusion Loss: 0.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/150: 100%|██████████| 32/32 [00:00<00:00, 107.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Diffusion Loss: 0.1830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/150: 100%|██████████| 32/32 [00:00<00:00, 106.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Diffusion Loss: 0.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/150: 100%|██████████| 32/32 [00:00<00:00, 107.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Diffusion Loss: 0.1727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/150: 100%|██████████| 32/32 [00:00<00:00, 106.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Diffusion Loss: 0.1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/150: 100%|██████████| 32/32 [00:00<00:00, 107.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Diffusion Loss: 0.1762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/150: 100%|██████████| 32/32 [00:00<00:00, 107.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Diffusion Loss: 0.1965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/150: 100%|██████████| 32/32 [00:00<00:00, 108.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Diffusion Loss: 0.1903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/150: 100%|██████████| 32/32 [00:00<00:00, 107.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Diffusion Loss: 0.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/150: 100%|██████████| 32/32 [00:00<00:00, 104.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Diffusion Loss: 0.1645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/150: 100%|██████████| 32/32 [00:00<00:00, 106.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Diffusion Loss: 0.1646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/150: 100%|██████████| 32/32 [00:00<00:00, 102.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Diffusion Loss: 0.1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/150: 100%|██████████| 32/32 [00:00<00:00, 105.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Diffusion Loss: 0.1826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/150: 100%|██████████| 32/32 [00:00<00:00, 109.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Diffusion Loss: 0.3160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/150: 100%|██████████| 32/32 [00:00<00:00, 99.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Diffusion Loss: 0.2072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/150: 100%|██████████| 32/32 [00:00<00:00, 110.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, Diffusion Loss: 0.1894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/150: 100%|██████████| 32/32 [00:00<00:00, 103.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, Diffusion Loss: 0.4524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/150: 100%|██████████| 32/32 [00:00<00:00, 111.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, Diffusion Loss: 0.2264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/150: 100%|██████████| 32/32 [00:00<00:00, 110.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Diffusion Loss: 0.1796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/150: 100%|██████████| 32/32 [00:00<00:00, 104.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Diffusion Loss: 0.1765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/150: 100%|██████████| 32/32 [00:00<00:00, 108.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, Diffusion Loss: 0.1673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/150: 100%|██████████| 32/32 [00:00<00:00, 108.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Diffusion Loss: 0.1720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/150: 100%|██████████| 32/32 [00:00<00:00, 109.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, Diffusion Loss: 0.1558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/150: 100%|██████████| 32/32 [00:00<00:00, 105.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, Diffusion Loss: 0.1705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/150: 100%|██████████| 32/32 [00:00<00:00, 104.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73, Diffusion Loss: 0.1757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/150: 100%|██████████| 32/32 [00:00<00:00, 110.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74, Diffusion Loss: 0.1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/150: 100%|██████████| 32/32 [00:00<00:00, 106.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Diffusion Loss: 0.2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/150: 100%|██████████| 32/32 [00:00<00:00, 102.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, Diffusion Loss: 0.1852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/150: 100%|██████████| 32/32 [00:00<00:00, 105.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, Diffusion Loss: 0.1874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/150: 100%|██████████| 32/32 [00:00<00:00, 104.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, Diffusion Loss: 0.1728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/150: 100%|██████████| 32/32 [00:00<00:00, 106.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, Diffusion Loss: 0.1689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/150: 100%|██████████| 32/32 [00:00<00:00, 104.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Diffusion Loss: 0.1759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/150: 100%|██████████| 32/32 [00:00<00:00, 106.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, Diffusion Loss: 0.1794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/150: 100%|██████████| 32/32 [00:00<00:00, 105.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, Diffusion Loss: 0.1761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/150: 100%|██████████| 32/32 [00:00<00:00, 106.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, Diffusion Loss: 0.1855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/150: 100%|██████████| 32/32 [00:00<00:00, 107.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84, Diffusion Loss: 0.1824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/150: 100%|██████████| 32/32 [00:00<00:00, 110.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, Diffusion Loss: 0.1977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/150: 100%|██████████| 32/32 [00:00<00:00, 109.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, Diffusion Loss: 0.2062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/150: 100%|██████████| 32/32 [00:00<00:00, 109.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, Diffusion Loss: 0.1854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/150: 100%|██████████| 32/32 [00:00<00:00, 107.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88, Diffusion Loss: 0.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/150: 100%|██████████| 32/32 [00:00<00:00, 108.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, Diffusion Loss: 0.1904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/150: 100%|██████████| 32/32 [00:00<00:00, 102.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Diffusion Loss: 0.1703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/150: 100%|██████████| 32/32 [00:00<00:00, 103.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91, Diffusion Loss: 0.1907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/150: 100%|██████████| 32/32 [00:00<00:00, 109.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92, Diffusion Loss: 0.1769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/150: 100%|██████████| 32/32 [00:00<00:00, 104.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93, Diffusion Loss: 0.2057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/150: 100%|██████████| 32/32 [00:00<00:00, 105.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94, Diffusion Loss: 0.2110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/150: 100%|██████████| 32/32 [00:00<00:00, 105.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, Diffusion Loss: 0.1901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/150: 100%|██████████| 32/32 [00:00<00:00, 111.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96, Diffusion Loss: 0.1903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/150: 100%|██████████| 32/32 [00:00<00:00, 104.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97, Diffusion Loss: 0.4036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/150: 100%|██████████| 32/32 [00:00<00:00, 98.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98, Diffusion Loss: 0.4270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/150: 100%|██████████| 32/32 [00:00<00:00, 108.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, Diffusion Loss: 0.1836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/150: 100%|██████████| 32/32 [00:00<00:00, 106.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Diffusion Loss: 0.1638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101/150: 100%|██████████| 32/32 [00:00<00:00, 108.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101, Diffusion Loss: 0.1530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 102/150: 100%|██████████| 32/32 [00:00<00:00, 107.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102, Diffusion Loss: 0.1658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 103/150: 100%|██████████| 32/32 [00:00<00:00, 103.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103, Diffusion Loss: 0.1684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 104/150: 100%|██████████| 32/32 [00:00<00:00, 104.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104, Diffusion Loss: 0.2190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 105/150: 100%|██████████| 32/32 [00:00<00:00, 107.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105, Diffusion Loss: 0.1525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 106/150: 100%|██████████| 32/32 [00:00<00:00, 109.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106, Diffusion Loss: 0.1658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 107/150: 100%|██████████| 32/32 [00:00<00:00, 105.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107, Diffusion Loss: 0.1624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 108/150: 100%|██████████| 32/32 [00:00<00:00, 105.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108, Diffusion Loss: 0.1566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 109/150: 100%|██████████| 32/32 [00:00<00:00, 108.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109, Diffusion Loss: 0.1478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 110/150: 100%|██████████| 32/32 [00:00<00:00, 105.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110, Diffusion Loss: 0.1679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 111/150: 100%|██████████| 32/32 [00:00<00:00, 107.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111, Diffusion Loss: 0.2107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 112/150: 100%|██████████| 32/32 [00:00<00:00, 104.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112, Diffusion Loss: 0.1784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 113/150: 100%|██████████| 32/32 [00:00<00:00, 106.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113, Diffusion Loss: 0.2063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 114/150: 100%|██████████| 32/32 [00:00<00:00, 104.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114, Diffusion Loss: 0.1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 115/150: 100%|██████████| 32/32 [00:00<00:00, 104.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115, Diffusion Loss: 0.1786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 116/150: 100%|██████████| 32/32 [00:00<00:00, 102.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116, Diffusion Loss: 0.1917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 117/150: 100%|██████████| 32/32 [00:00<00:00, 106.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117, Diffusion Loss: 0.2109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 118/150: 100%|██████████| 32/32 [00:00<00:00, 107.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118, Diffusion Loss: 0.1719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 119/150: 100%|██████████| 32/32 [00:00<00:00, 108.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119, Diffusion Loss: 0.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 120/150: 100%|██████████| 32/32 [00:00<00:00, 110.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, Diffusion Loss: 0.1510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 121/150: 100%|██████████| 32/32 [00:00<00:00, 104.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121, Diffusion Loss: 0.1685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 122/150: 100%|██████████| 32/32 [00:00<00:00, 106.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122, Diffusion Loss: 0.1595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 123/150: 100%|██████████| 32/32 [00:00<00:00, 110.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123, Diffusion Loss: 0.1742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 124/150: 100%|██████████| 32/32 [00:00<00:00, 108.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124, Diffusion Loss: 0.1548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 125/150: 100%|██████████| 32/32 [00:00<00:00, 104.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125, Diffusion Loss: 0.1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 126/150: 100%|██████████| 32/32 [00:00<00:00, 104.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126, Diffusion Loss: 0.1811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 127/150: 100%|██████████| 32/32 [00:00<00:00, 109.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127, Diffusion Loss: 0.2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 128/150: 100%|██████████| 32/32 [00:00<00:00, 104.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128, Diffusion Loss: 0.1902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 129/150: 100%|██████████| 32/32 [00:00<00:00, 106.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129, Diffusion Loss: 0.1505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 130/150: 100%|██████████| 32/32 [00:00<00:00, 108.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130, Diffusion Loss: 0.1879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 131/150: 100%|██████████| 32/32 [00:00<00:00, 107.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131, Diffusion Loss: 0.2286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 132/150: 100%|██████████| 32/32 [00:00<00:00, 105.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132, Diffusion Loss: 0.1776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 133/150: 100%|██████████| 32/32 [00:00<00:00, 106.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133, Diffusion Loss: 0.1780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 134/150: 100%|██████████| 32/32 [00:00<00:00, 110.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134, Diffusion Loss: 0.1550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 135/150: 100%|██████████| 32/32 [00:00<00:00, 108.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135, Diffusion Loss: 0.1853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 136/150: 100%|██████████| 32/32 [00:00<00:00, 102.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136, Diffusion Loss: 0.1964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 137/150: 100%|██████████| 32/32 [00:00<00:00, 107.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137, Diffusion Loss: 0.1636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 138/150: 100%|██████████| 32/32 [00:00<00:00, 108.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138, Diffusion Loss: 0.2152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 139/150: 100%|██████████| 32/32 [00:00<00:00, 100.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139, Diffusion Loss: 0.1940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 140/150: 100%|██████████| 32/32 [00:00<00:00, 102.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140, Diffusion Loss: 0.1725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 141/150: 100%|██████████| 32/32 [00:00<00:00, 104.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141, Diffusion Loss: 0.1648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 142/150: 100%|██████████| 32/32 [00:00<00:00, 93.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142, Diffusion Loss: 0.1643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 143/150: 100%|██████████| 32/32 [00:00<00:00, 98.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143, Diffusion Loss: 0.1577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 144/150: 100%|██████████| 32/32 [00:00<00:00, 107.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144, Diffusion Loss: 0.1597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 145/150: 100%|██████████| 32/32 [00:00<00:00, 107.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145, Diffusion Loss: 0.1571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 146/150: 100%|██████████| 32/32 [00:00<00:00, 101.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146, Diffusion Loss: 0.1509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 147/150: 100%|██████████| 32/32 [00:00<00:00, 106.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147, Diffusion Loss: 0.1521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 148/150: 100%|██████████| 32/32 [00:00<00:00, 104.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148, Diffusion Loss: 0.1523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 149/150: 100%|██████████| 32/32 [00:00<00:00, 107.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149, Diffusion Loss: 0.1593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 150/150: 100%|██████████| 32/32 [00:00<00:00, 104.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, Diffusion Loss: 0.1449\n",
      "Accuracy on recovered z: 0.5394\n"
     ]
    }
   ],
   "source": [
    "# latent_dim = vae.encoder[-1].out_features\n",
    "diffusion_model = SimpleDiffusionModel(latent_dim=latent_dim).to(device)\n",
    "diffusion_optimizer = optim.Adam(diffusion_model.parameters(), lr=1e-3)\n",
    "\n",
    "train_diffusion(vae_new, diffusion_model, train_loader, diffusion_optimizer, device)\n",
    "\n",
    "evaluate_diffusion_with_classifier(vae, diffusion_model, vae.classifier, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
