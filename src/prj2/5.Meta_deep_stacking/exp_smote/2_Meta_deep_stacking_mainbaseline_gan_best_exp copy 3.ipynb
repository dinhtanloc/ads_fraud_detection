{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1dd1c5b",
   "metadata": {
    "id": "c1dd1c5b",
    "outputId": "09170fb9-8be1-475b-8a18-39640a3620b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Data\\ads_fraud_detection\n",
      "c:/Users/Admin/Data/ads_fraud_detection\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.35.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys,os\n",
    "__script_path=os.path.abspath(globals().get('__file__','.'))\n",
    "__script_dir = os.path.dirname(__script_path)\n",
    "root_dir = os.path.abspath(f'{__script_dir}/../../..')\n",
    "print(root_dir)\n",
    "for lib in [root_dir][::-1]:\n",
    "    if lib in sys.path:\n",
    "        sys.path.remove(lib)\n",
    "    sys.path.insert(0,lib)\n",
    "from config.config import *\n",
    "from libs.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622aee0d",
   "metadata": {
    "id": "622aee0d"
   },
   "outputs": [],
   "source": [
    "save_dir=f\"{exps_dir}/exp2/exp_gan\"\n",
    "if os.path.exists(save_dir) == False:\n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee0c5839",
   "metadata": {
    "id": "ee0c5839",
    "outputId": "884cf8cb-6205-4a6a-b127-4095bf3f5fda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR': ['AccidentArea',\n",
       "  'AddressChange_Claim',\n",
       "  'AgentType',\n",
       "  'Days_Policy_Claim',\n",
       "  'Fault',\n",
       "  'NumberOfCars',\n",
       "  'NumberOfSuppliments',\n",
       "  'Sex',\n",
       "  'WitnessPresent',\n",
       "  'Year'],\n",
       " 'LDA': ['AccidentArea',\n",
       "  'AddressChange_Claim',\n",
       "  'AgentType',\n",
       "  'BasePolicy',\n",
       "  'Days_Policy_Claim',\n",
       "  'Fault',\n",
       "  'NumberOfCars',\n",
       "  'NumberOfSuppliments',\n",
       "  'WitnessPresent',\n",
       "  'Year'],\n",
       " 'DTC': ['Age',\n",
       "  'Make',\n",
       "  'Month',\n",
       "  'MonthClaimed',\n",
       "  'PolicyNumber',\n",
       "  'RepNumber',\n",
       "  'WeekOfMonth',\n",
       "  'WeekOfMonthClaimed',\n",
       "  'week_claimed',\n",
       "  'week_incident'],\n",
       " 'RD': ['Age',\n",
       "  'AgeOfPolicyHolder',\n",
       "  'DayOfWeekClaimed',\n",
       "  'Make',\n",
       "  'Month',\n",
       "  'MonthClaimed',\n",
       "  'PolicyNumber',\n",
       "  'RepNumber',\n",
       "  'week_claimed',\n",
       "  'week_incident'],\n",
       " 'LGBM': ['Age',\n",
       "  'AgeOfVehicle',\n",
       "  'Make',\n",
       "  'Month',\n",
       "  'MonthClaimed',\n",
       "  'PolicyNumber',\n",
       "  'PolicyType',\n",
       "  'RepNumber',\n",
       "  'week_claimed',\n",
       "  'week_incident'],\n",
       " 'XGB': ['AccidentArea',\n",
       "  'AddressChange_Claim',\n",
       "  'AgentType',\n",
       "  'BasePolicy',\n",
       "  'Days_Policy_Claim',\n",
       "  'Fault',\n",
       "  'NumberOfCars',\n",
       "  'PolicyType',\n",
       "  'WitnessPresent',\n",
       "  'Year'],\n",
       " 'KNC': ['DayOfWeek',\n",
       "  'AccidentArea',\n",
       "  'Sex',\n",
       "  'Fault',\n",
       "  'DriverRating',\n",
       "  'Days_Policy_Claim',\n",
       "  'AgeOfVehicle',\n",
       "  'WitnessPresent',\n",
       "  'NumberOfSuppliments',\n",
       "  'AddressChange_Claim',\n",
       "  'Year'],\n",
       " 'GNB': ['DayOfWeek',\n",
       "  'AccidentArea',\n",
       "  'Sex',\n",
       "  'Fault',\n",
       "  'DriverRating',\n",
       "  'Days_Policy_Claim',\n",
       "  'AgeOfVehicle',\n",
       "  'WitnessPresent',\n",
       "  'NumberOfSuppliments',\n",
       "  'AddressChange_Claim',\n",
       "  'Year'],\n",
       " 'NN': ['DayOfWeek',\n",
       "  'AccidentArea',\n",
       "  'Sex',\n",
       "  'Fault',\n",
       "  'DriverRating',\n",
       "  'Days_Policy_Claim',\n",
       "  'AgeOfVehicle',\n",
       "  'WitnessPresent',\n",
       "  'NumberOfSuppliments',\n",
       "  'AddressChange_Claim',\n",
       "  'Year'],\n",
       " 'BG': ['DayOfWeek',\n",
       "  'AccidentArea',\n",
       "  'Sex',\n",
       "  'Fault',\n",
       "  'DriverRating',\n",
       "  'Days_Policy_Claim',\n",
       "  'AgeOfVehicle',\n",
       "  'WitnessPresent',\n",
       "  'NumberOfSuppliments',\n",
       "  'AddressChange_Claim',\n",
       "  'Year'],\n",
       " 'NB': ['DayOfWeek',\n",
       "  'AccidentArea',\n",
       "  'Sex',\n",
       "  'Fault',\n",
       "  'DriverRating',\n",
       "  'Days_Policy_Claim',\n",
       "  'AgeOfVehicle',\n",
       "  'WitnessPresent',\n",
       "  'NumberOfSuppliments',\n",
       "  'AddressChange_Claim',\n",
       "  'Year'],\n",
       " 'SVM': ['DayOfWeek',\n",
       "  'AccidentArea',\n",
       "  'Sex',\n",
       "  'Fault',\n",
       "  'DriverRating',\n",
       "  'Days_Policy_Claim',\n",
       "  'AgeOfVehicle',\n",
       "  'WitnessPresent',\n",
       "  'NumberOfSuppliments',\n",
       "  'AddressChange_Claim',\n",
       "  'Year']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selection=dict(np.load(f'{save_dir}/feature_model_selection.npz',allow_pickle=True))['feature_model_selection']\n",
    "feature_selection = {key: value for key, value in feature_selection.item().items()}\n",
    "feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d162d6",
   "metadata": {
    "id": "79d162d6"
   },
   "source": [
    "* kiểm tra và tạo các thư mục (nếu chưa có)\n",
    "* tập test 33%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7e092",
   "metadata": {
    "id": "5cf7e092"
   },
   "source": [
    "# 5. Xây dựng và đánh giá mô hình học sâu Neutual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84bdb3c",
   "metadata": {
    "id": "d84bdb3c"
   },
   "outputs": [],
   "source": [
    "xgb_model=joblib.load(f'{save_dir}/xgb_model.joblib')\n",
    "rf_model=joblib.load(f'{save_dir}/rf_model.joblib')\n",
    "lgbm_model=joblib.load(f'{save_dir}/lgbm_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e81211d",
   "metadata": {
    "id": "2e81211d",
    "outputId": "11c037bb-b65a-420c-b24c-5aeb07d22aad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0352032938754503, 1: 0.9671122223290701}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "class_weights_dict=dict(np.load(f'{save_dir}/class_weights_dict.npz',allow_pickle=True))['class_weights_dict']\n",
    "class_weights_dict = {key: value for key, value in class_weights_dict.item().items()}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd43638",
   "metadata": {
    "id": "9dd43638",
    "outputId": "a02718e1-24fc-4e1d-d937-903d57955f80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5089, 2) (20422, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Dữ liệu label đã được mã hóa\n",
    "def oneHot(arr):\n",
    "    labels = np.array(arr)\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "    labels_reshaped = labels.reshape(-1, 1)\n",
    "\n",
    "    encoder.fit(labels_reshaped)\n",
    "\n",
    "    onehot_labels = encoder.transform(labels_reshaped)\n",
    "    # onehot_labels=pd.DataFrame(onehot_labels)\n",
    "    return onehot_labels\n",
    "\n",
    "y_train_onehot=oneHot(y_train)\n",
    "y_test_onehot=oneHot(y_test)\n",
    "print(y_test_onehot.shape,y_train_onehot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf5d7b4",
   "metadata": {
    "id": "9cf5d7b4",
    "outputId": "0e8b29fd-22f8-44e5-91c7-85f7e47b75c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5089, 2)\n"
     ]
    }
   ],
   "source": [
    "y_test_onehot.reshape(-1, 1)\n",
    "print(y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dda6290",
   "metadata": {
    "id": "6dda6290",
    "outputId": "bbb38491-0401-4e47-fdee-da1323b81029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5089, 34)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1c3ac7a",
   "metadata": {
    "id": "f1c3ac7a",
    "outputId": "38eb9f4a-5bdb-429c-f4ab-98bdac97ee7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20422, 34)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d31efd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FraudFound_P\n",
       "1               10707\n",
       "0                9715\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "848e48fb",
   "metadata": {
    "id": "848e48fb"
   },
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Macro F1 score metric.\n",
    "    \"\"\"\n",
    "    y_pred = K.round(y_pred)\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)\n",
    "    false_positives = K.sum(K.round(K.clip(y_pred - y_true, 0, 1)), axis=0)\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)), axis=0)\n",
    "    precision = true_positives / (true_positives + false_positives + K.epsilon())\n",
    "    recall = true_positives / (true_positives + false_negatives + K.epsilon())\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    macro_f1_score = K.mean(f1_scores)\n",
    "\n",
    "    return macro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01f5fcdf",
   "metadata": {
    "id": "01f5fcdf",
    "outputId": "187e7cd9-8f70-4eae-d11d-c40e1c08c506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6de984",
   "metadata": {
    "id": "cb6de984"
   },
   "source": [
    "#### * Xây dựng model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "732f9456",
   "metadata": {
    "id": "732f9456"
   },
   "outputs": [],
   "source": [
    "\n",
    "early_stopping = EarlyStopping(monitor='f1_score',\n",
    "                                mode='max',\n",
    "    min_delta=0.00005,\n",
    "    patience=100,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='f1_score',\n",
    "    mode='max',\n",
    "    factor=0.5,\n",
    "    patience=10,\n",
    "    min_lr=0.000001,\n",
    "    verbose=1,\n",
    ")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_model.h5',  # Đường dẫn để lưu model\n",
    "    monitor='f1_score',  # Theo dõi val_loss\n",
    "    mode='max',\n",
    "    save_best_only=True,  # Lưu lại chỉ model có val_loss tốt nhất\n",
    "    verbose=1  # Hiển thị thông báo khi lưu model\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abee8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "tabnet_params = {\n",
    "    \"decision_dim\": 16,\n",
    "    \"attention_dim\": 16,\n",
    "    \"n_steps\": 3,\n",
    "    \"n_shared_glus\": 2,\n",
    "    \"n_dependent_glus\": 2,\n",
    "    \"relaxation_factor\": 1.3,\n",
    "    \"epsilon\": 1e-15,\n",
    "    \"momentum\": 0.98,\n",
    "    \"mask_type\": \"softmax\", # can be 'sparsemax' or 'softmax'\n",
    "    \"lambda_sparse\": 1e-3, \n",
    "    \"virtual_batch_splits\": 8 #number of splits for ghost batch normalization, ideally should evenly divide the batch_size\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "### Classification\n",
    "tabnet = TabNetClassifier(n_classes = 1, out_activation = 'sigmoid', **tabnet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a46595d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabnet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate), loss='categorical_crossentropy', metrics=['accuracy',f1_score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa1373fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.49934542]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabnet.build(input_shape=(None, 34))\n",
    "dummy_input = tf.random.normal((1, 34)) \n",
    "tabnet(dummy_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "014f5cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tab_net_classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tab_net_encoder (TabNetEnc  multiple                  26880     \n",
      " oder)                                                           \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26896 (105.06 KB)\n",
      "Trainable params: 24576 (96.00 KB)\n",
      "Non-trainable params: 2320 (9.06 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# tabnet.load_weights('weights/tabnet_categorical.h5')\n",
    "tabnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9141149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tabnet_feature(model,input_shape=(34), proba=False):\n",
    "    input = Input(shape=input_shape)\n",
    "    feature = tabnet.get_layer('tab_net_encoder')(input)\n",
    "    probability=tabnet.get_layer('classifier')(feature)\n",
    "    if proba:\n",
    "        output=Concatenate()([feature,probability])\n",
    "    else:\n",
    "        output=feature\n",
    "    model = Model(inputs=input,outputs=[output])\n",
    "    return model\n",
    "tabnet_model=tabnet_feature(tabnet, proba=True)\n",
    "# output=feat_model(dummy_input)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fbe20f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639/639 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20422, 17)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=tabnet_model.predict(x_train)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec895de",
   "metadata": {
    "id": "5ec895de"
   },
   "source": [
    "#### * Xây dựng Stacked_model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b807d4e",
   "metadata": {
    "id": "9b807d4e"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tabnet_keras import TabNetClassifier\n",
    "\n",
    "class TabNetWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = TabNetClassifier(n_classes = 1, out_activation = 'sigmoid',**self.kwargs)\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss=tf.keras.losses.binary_focal_crossentropy, metrics=['accuracy',f1_score])\n",
    "\n",
    "        self.model.fit(x=x_train, y=y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          batch_size=32,\n",
    "          epochs=1200,\n",
    "          callbacks=[early_stopping, lr_scheduler], class_weight=class_weights_dict)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.model.predict(X)\n",
    "        return (proba > 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def summary(self):\n",
    "        return self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071a8a46",
   "metadata": {
    "id": "071a8a46"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14004dd7",
   "metadata": {
    "id": "14004dd7"
   },
   "outputs": [],
   "source": [
    "tabnet_params = {\n",
    "    \"decision_dim\": 16,\n",
    "    \"attention_dim\": 16,\n",
    "    \"n_steps\": 3,\n",
    "    \"n_shared_glus\": 2,\n",
    "    \"n_dependent_glus\": 2,\n",
    "    \"relaxation_factor\": 1.3,\n",
    "    \"epsilon\": 1e-15,\n",
    "    \"momentum\": 0.98,\n",
    "    \"mask_type\": \"softmax\", # can be 'sparsemax' or 'softmax'\n",
    "    \"lambda_sparse\": 1e-3,\n",
    "    \"virtual_batch_splits\": 8 #number of splits for ghost batch normalization, ideally should evenly divide the batch_size\n",
    "}\n",
    "tabnet = TabNetWrapper(**tabnet_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354520a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09abb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8c4c3c3",
   "metadata": {
    "id": "c8c4c3c3",
    "outputId": "b67a4e4d-52bc-4374-e74d-f8a02a4829fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 1ms/step\n",
      "(5089, 23)\n",
      "(5089, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# def create_keras_model():\n",
    "#     # Thêm các lớp khác vào đây\n",
    "#     best_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',f1_score])\n",
    "#     best_model.load_weights('weights.h5')\n",
    "#     return best_model\n",
    "\n",
    "# tabnet = KerasClassifier(build_fn=create_keras_model, epochs=10)\n",
    "\n",
    "# rf_model=RandomForestClassifier(n_estimators=100, random_state=seed)\n",
    "# bg_model=GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=seed)\n",
    "# svm_model=SVC(kernel='rbf',probability=True, gamma='scale' , random_state=seed)\n",
    "\n",
    "# # Huấn luyện các mô hình cơ sở\n",
    "# rf_model.fit(x_train, y_train)\n",
    "# bg_model.fit(x_train, y_train)\n",
    "# svm_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Dự đoán đầu ra của các mô hình cơ sở\n",
    "rf_pred = rf_model.predict_proba(x_test[feature_selection['RD']])\n",
    "svm_pred = lgbm_model.predict_proba(x_test[feature_selection['LGBM']])\n",
    "bg_pred = xgb_model.predict_proba(x_test[feature_selection['XGB']])\n",
    "tabnet_pred=tabnet_model.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "# keras_pred = tabnet.predict(x_test)\n",
    "stacked_input = np.column_stack((rf_pred,svm_pred,bg_pred, tabnet_pred))\n",
    "\n",
    "\n",
    "#history=model.fit(x=x_train,y=y_train,\n",
    "          #validation_data=(x_test,y_test),class_weight=class_weights_dict ,\n",
    "          #batch_size=64,epochs=120, callbacks=[confusion_matrix_callback])\n",
    "\n",
    "# tabnet = KerasClassifier(build_fn=model_output, tabnet_params=tabnet_params,batch_size=64,epochs=10000,callbacks=[early_stopping,lr_scheduler])\n",
    "\n",
    "# Clone lại để tránh thay đổi trực tiếp vào mô hình gốc\n",
    "# tabnet = clone(tabnet)\n",
    "# Xây dựng mô hình stacking\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=[('rf',rf_model), ('lgbm',lgbm_model),('xgb',xgb_model)],\n",
    "    final_estimator=tabnet\n",
    ")\n",
    "print(stacked_input.shape)\n",
    "print(y_test.shape)\n",
    "# Tiếp tục với việc huấn luyện và đánh giá mô hình stacking\n",
    "# stacked_model.fit(stacked_input, y_train)\n",
    "# stacked_pred = stacked_model.predict(stacked_input)\n",
    "# stacked_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dNc8zm7wMpMO",
   "metadata": {
    "id": "dNc8zm7wMpMO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 246, number of negative: 3825\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2487\n",
      "[LightGBM] [Info] Number of data points in the train set: 4071, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.060427 -> initscore=-2.743982\n",
      "[LightGBM] [Info] Start training from score -2.743982\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Number of positive: 196, number of negative: 3060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2311\n",
      "[LightGBM] [Info] Number of data points in the train set: 3256, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.060197 -> initscore=-2.748056\n",
      "[LightGBM] [Info] Start training from score -2.748056\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Number of positive: 197, number of negative: 3060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2294\n",
      "[LightGBM] [Info] Number of data points in the train set: 3257, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.060485 -> initscore=-2.742966\n",
      "[LightGBM] [Info] Start training from score -2.742966\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Number of positive: 197, number of negative: 3060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 3257, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.060485 -> initscore=-2.742966\n",
      "[LightGBM] [Info] Start training from score -2.742966\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Number of positive: 197, number of negative: 3060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2302\n",
      "[LightGBM] [Info] Number of data points in the train set: 3257, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.060485 -> initscore=-2.742966\n",
      "[LightGBM] [Info] Start training from score -2.742966\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Number of positive: 197, number of negative: 3060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2303\n",
      "[LightGBM] [Info] Number of data points in the train set: 3257, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.060485 -> initscore=-2.742966\n",
      "[LightGBM] [Info] Start training from score -2.742966\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Epoch 1/1200\n",
      "639/639 [==============================] - 9s 6ms/step - loss: 0.0929 - accuracy: 0.8575 - f1_score: 0.8531 - val_loss: 0.0836 - val_accuracy: 0.9310 - val_f1_score: 0.0168 - lr: 0.1000\n",
      "Epoch 2/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0700 - accuracy: 0.9020 - f1_score: 0.8993 - val_loss: 0.0863 - val_accuracy: 0.8998 - val_f1_score: 0.0772 - lr: 0.1000\n",
      "Epoch 3/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0702 - accuracy: 0.9034 - f1_score: 0.9025 - val_loss: 0.0685 - val_accuracy: 0.9242 - val_f1_score: 0.0430 - lr: 0.1000\n",
      "Epoch 4/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0652 - accuracy: 0.9049 - f1_score: 0.9039 - val_loss: 0.0641 - val_accuracy: 0.9342 - val_f1_score: 0.0185 - lr: 0.1000\n",
      "Epoch 5/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0611 - accuracy: 0.9138 - f1_score: 0.9117 - val_loss: 0.0578 - val_accuracy: 0.9336 - val_f1_score: 0.0077 - lr: 0.1000\n",
      "Epoch 6/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0591 - accuracy: 0.9159 - f1_score: 0.9141 - val_loss: 0.0590 - val_accuracy: 0.9283 - val_f1_score: 0.0399 - lr: 0.1000\n",
      "Epoch 7/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0583 - accuracy: 0.9153 - f1_score: 0.9129 - val_loss: 0.0832 - val_accuracy: 0.9194 - val_f1_score: 0.0816 - lr: 0.1000\n",
      "Epoch 8/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0589 - accuracy: 0.9172 - f1_score: 0.9155 - val_loss: 0.0607 - val_accuracy: 0.9124 - val_f1_score: 0.0892 - lr: 0.1000\n",
      "Epoch 9/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0547 - accuracy: 0.9218 - f1_score: 0.9203 - val_loss: 0.0591 - val_accuracy: 0.9332 - val_f1_score: 0.0089 - lr: 0.1000\n",
      "Epoch 10/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0561 - accuracy: 0.9168 - f1_score: 0.9152 - val_loss: 0.0572 - val_accuracy: 0.9365 - val_f1_score: 0.0140 - lr: 0.1000\n",
      "Epoch 11/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0550 - accuracy: 0.9192 - f1_score: 0.9179 - val_loss: 0.0582 - val_accuracy: 0.9365 - val_f1_score: 0.0083 - lr: 0.1000\n",
      "Epoch 12/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0676 - accuracy: 0.9153 - f1_score: 0.9129 - val_loss: 0.0730 - val_accuracy: 0.9375 - val_f1_score: 0.0165 - lr: 0.1000\n",
      "Epoch 13/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0598 - accuracy: 0.9187 - f1_score: 0.9164 - val_loss: 0.0615 - val_accuracy: 0.9348 - val_f1_score: 0.0271 - lr: 0.1000\n",
      "Epoch 14/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0600 - accuracy: 0.9192 - f1_score: 0.9172 - val_loss: 0.0795 - val_accuracy: 0.9352 - val_f1_score: 0.0212 - lr: 0.1000\n",
      "Epoch 15/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0619 - accuracy: 0.9229 - f1_score: 0.9217 - val_loss: 0.0850 - val_accuracy: 0.9336 - val_f1_score: 0.0315 - lr: 0.1000\n",
      "Epoch 16/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0592 - accuracy: 0.9275 - f1_score: 0.9246 - val_loss: 0.0834 - val_accuracy: 0.9377 - val_f1_score: 0.0146 - lr: 0.1000\n",
      "Epoch 17/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0648 - accuracy: 0.9178 - f1_score: 0.9162 - val_loss: 0.0907 - val_accuracy: 0.8174 - val_f1_score: 0.1883 - lr: 0.1000\n",
      "Epoch 18/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0572 - accuracy: 0.9220 - f1_score: 0.9203 - val_loss: 0.0877 - val_accuracy: 0.8803 - val_f1_score: 0.1425 - lr: 0.1000\n",
      "Epoch 19/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0552 - accuracy: 0.9221 - f1_score: 0.9192 - val_loss: 0.0751 - val_accuracy: 0.9367 - val_f1_score: 0.0177 - lr: 0.1000\n",
      "Epoch 20/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0626 - accuracy: 0.9107 - f1_score: 0.9066 - val_loss: 0.1184 - val_accuracy: 0.9340 - val_f1_score: 0.0186 - lr: 0.1000\n",
      "Epoch 21/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0571 - accuracy: 0.9228 - f1_score: 0.9204 - val_loss: 0.0733 - val_accuracy: 0.9316 - val_f1_score: 0.0196 - lr: 0.1000\n",
      "Epoch 22/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0547 - accuracy: 0.9257 - f1_score: 0.9237 - val_loss: 0.0671 - val_accuracy: 0.9357 - val_f1_score: 0.0135 - lr: 0.1000\n",
      "Epoch 23/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0576 - accuracy: 0.9200 - f1_score: 0.9178 - val_loss: 0.3558 - val_accuracy: 0.4647 - val_f1_score: 0.1537 - lr: 0.1000\n",
      "Epoch 24/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0546 - accuracy: 0.9238 - f1_score: 0.9212 - val_loss: 0.0604 - val_accuracy: 0.9377 - val_f1_score: 0.0046 - lr: 0.1000\n",
      "Epoch 25/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0527 - accuracy: 0.9241 - f1_score: 0.9205 - val_loss: 0.0613 - val_accuracy: 0.9371 - val_f1_score: 0.0046 - lr: 0.1000\n",
      "Epoch 26/1200\n",
      "632/639 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9151 - f1_score: 0.9110\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.05000000074505806.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0585 - accuracy: 0.9150 - f1_score: 0.9107 - val_loss: 0.0729 - val_accuracy: 0.9352 - val_f1_score: 0.0049 - lr: 0.1000\n",
      "Epoch 27/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0525 - accuracy: 0.9232 - f1_score: 0.9206 - val_loss: 0.0681 - val_accuracy: 0.9363 - val_f1_score: 0.0112 - lr: 0.0500\n",
      "Epoch 28/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0493 - accuracy: 0.9277 - f1_score: 0.9251 - val_loss: 0.0715 - val_accuracy: 0.9263 - val_f1_score: 0.0315 - lr: 0.0500\n",
      "Epoch 29/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0517 - accuracy: 0.9201 - f1_score: 0.9182 - val_loss: 0.0668 - val_accuracy: 0.9234 - val_f1_score: 0.0389 - lr: 0.0500\n",
      "Epoch 30/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0486 - accuracy: 0.9263 - f1_score: 0.9237 - val_loss: 0.0643 - val_accuracy: 0.9381 - val_f1_score: 0.0021 - lr: 0.0500\n",
      "Epoch 31/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0480 - accuracy: 0.9272 - f1_score: 0.9242 - val_loss: 0.0691 - val_accuracy: 0.9363 - val_f1_score: 0.0021 - lr: 0.0500\n",
      "Epoch 32/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0481 - accuracy: 0.9277 - f1_score: 0.9252 - val_loss: 0.0642 - val_accuracy: 0.9336 - val_f1_score: 0.0083 - lr: 0.0500\n",
      "Epoch 33/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0466 - accuracy: 0.9317 - f1_score: 0.9284 - val_loss: 0.0553 - val_accuracy: 0.9336 - val_f1_score: 0.0198 - lr: 0.0500\n",
      "Epoch 34/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0474 - accuracy: 0.9279 - f1_score: 0.9250 - val_loss: 0.0539 - val_accuracy: 0.9385 - val_f1_score: 0.0000e+00 - lr: 0.0500\n",
      "Epoch 35/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0474 - accuracy: 0.9268 - f1_score: 0.9242 - val_loss: 0.0693 - val_accuracy: 0.9265 - val_f1_score: 0.0515 - lr: 0.0500\n",
      "Epoch 36/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0474 - accuracy: 0.9306 - f1_score: 0.9280 - val_loss: 0.0538 - val_accuracy: 0.9365 - val_f1_score: 0.0042 - lr: 0.0500\n",
      "Epoch 37/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0464 - accuracy: 0.9321 - f1_score: 0.9298 - val_loss: 0.0663 - val_accuracy: 0.9367 - val_f1_score: 0.0046 - lr: 0.0500\n",
      "Epoch 38/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0466 - accuracy: 0.9304 - f1_score: 0.9277 - val_loss: 0.0626 - val_accuracy: 0.9359 - val_f1_score: 0.0060 - lr: 0.0500\n",
      "Epoch 39/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0457 - accuracy: 0.9328 - f1_score: 0.9304 - val_loss: 0.0555 - val_accuracy: 0.9365 - val_f1_score: 0.0203 - lr: 0.0500\n",
      "Epoch 40/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0453 - accuracy: 0.9322 - f1_score: 0.9297 - val_loss: 0.0555 - val_accuracy: 0.9369 - val_f1_score: 0.0115 - lr: 0.0500\n",
      "Epoch 41/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0460 - accuracy: 0.9308 - f1_score: 0.9284 - val_loss: 0.0854 - val_accuracy: 0.9192 - val_f1_score: 0.0500 - lr: 0.0500\n",
      "Epoch 42/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0567 - accuracy: 0.9297 - f1_score: 0.9269 - val_loss: 0.0696 - val_accuracy: 0.9363 - val_f1_score: 0.0198 - lr: 0.0500\n",
      "Epoch 43/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0495 - accuracy: 0.9303 - f1_score: 0.9286 - val_loss: 0.0814 - val_accuracy: 0.8894 - val_f1_score: 0.1876 - lr: 0.0500\n",
      "Epoch 44/1200\n",
      "639/639 [==============================] - 2s 4ms/step - loss: 0.0458 - accuracy: 0.9326 - f1_score: 0.9306 - val_loss: 0.0670 - val_accuracy: 0.9336 - val_f1_score: 0.0294 - lr: 0.0500\n",
      "Epoch 45/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0449 - accuracy: 0.9344 - f1_score: 0.9318 - val_loss: 0.0603 - val_accuracy: 0.9371 - val_f1_score: 0.0233 - lr: 0.0500\n",
      "Epoch 46/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0474 - accuracy: 0.9320 - f1_score: 0.9284 - val_loss: 0.0607 - val_accuracy: 0.9298 - val_f1_score: 0.0619 - lr: 0.0500\n",
      "Epoch 47/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0485 - accuracy: 0.9326 - f1_score: 0.9304 - val_loss: 0.0566 - val_accuracy: 0.9357 - val_f1_score: 0.0283 - lr: 0.0500\n",
      "Epoch 48/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0472 - accuracy: 0.9319 - f1_score: 0.9305 - val_loss: 0.0531 - val_accuracy: 0.9371 - val_f1_score: 0.0342 - lr: 0.0500\n",
      "Epoch 49/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0454 - accuracy: 0.9344 - f1_score: 0.9322 - val_loss: 0.8001 - val_accuracy: 0.6687 - val_f1_score: 0.1135 - lr: 0.0500\n",
      "Epoch 50/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0454 - accuracy: 0.9328 - f1_score: 0.9309 - val_loss: 0.0645 - val_accuracy: 0.9253 - val_f1_score: 0.0929 - lr: 0.0500\n",
      "Epoch 51/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0482 - accuracy: 0.9315 - f1_score: 0.9295 - val_loss: 0.0553 - val_accuracy: 0.9365 - val_f1_score: 0.0198 - lr: 0.0500\n",
      "Epoch 52/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0439 - accuracy: 0.9347 - f1_score: 0.9325 - val_loss: 0.0549 - val_accuracy: 0.9348 - val_f1_score: 0.0219 - lr: 0.0500\n",
      "Epoch 53/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0445 - accuracy: 0.9352 - f1_score: 0.9338 - val_loss: 0.0581 - val_accuracy: 0.9385 - val_f1_score: 0.0140 - lr: 0.0500\n",
      "Epoch 54/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0444 - accuracy: 0.9353 - f1_score: 0.9333 - val_loss: 0.0529 - val_accuracy: 0.9355 - val_f1_score: 0.0212 - lr: 0.0500\n",
      "Epoch 55/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0445 - accuracy: 0.9349 - f1_score: 0.9326 - val_loss: 0.0696 - val_accuracy: 0.9238 - val_f1_score: 0.1171 - lr: 0.0500\n",
      "Epoch 56/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0440 - accuracy: 0.9349 - f1_score: 0.9327 - val_loss: 0.0603 - val_accuracy: 0.9346 - val_f1_score: 0.0398 - lr: 0.0500\n",
      "Epoch 57/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0440 - accuracy: 0.9357 - f1_score: 0.9337 - val_loss: 0.0574 - val_accuracy: 0.9365 - val_f1_score: 0.0527 - lr: 0.0500\n",
      "Epoch 58/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0447 - accuracy: 0.9359 - f1_score: 0.9342 - val_loss: 0.0523 - val_accuracy: 0.9387 - val_f1_score: 0.0083 - lr: 0.0500\n",
      "Epoch 59/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0445 - accuracy: 0.9341 - f1_score: 0.9325 - val_loss: 0.0655 - val_accuracy: 0.9318 - val_f1_score: 0.0409 - lr: 0.0500\n",
      "Epoch 60/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0436 - accuracy: 0.9358 - f1_score: 0.9340 - val_loss: 0.0879 - val_accuracy: 0.8499 - val_f1_score: 0.2112 - lr: 0.0500\n",
      "Epoch 61/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0428 - accuracy: 0.9367 - f1_score: 0.9345 - val_loss: 0.0552 - val_accuracy: 0.9371 - val_f1_score: 0.0269 - lr: 0.0500\n",
      "Epoch 62/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0426 - accuracy: 0.9373 - f1_score: 0.9355 - val_loss: 0.0567 - val_accuracy: 0.9342 - val_f1_score: 0.0346 - lr: 0.0500\n",
      "Epoch 63/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0430 - accuracy: 0.9370 - f1_score: 0.9353 - val_loss: 0.0563 - val_accuracy: 0.9377 - val_f1_score: 0.0135 - lr: 0.0500\n",
      "Epoch 64/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0433 - accuracy: 0.9357 - f1_score: 0.9335 - val_loss: 0.0613 - val_accuracy: 0.9300 - val_f1_score: 0.0521 - lr: 0.0500\n",
      "Epoch 65/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0422 - accuracy: 0.9372 - f1_score: 0.9354 - val_loss: 0.0592 - val_accuracy: 0.9397 - val_f1_score: 0.0140 - lr: 0.0500\n",
      "Epoch 66/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0418 - accuracy: 0.9382 - f1_score: 0.9361 - val_loss: 0.0540 - val_accuracy: 0.9385 - val_f1_score: 0.0135 - lr: 0.0500\n",
      "Epoch 67/1200\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0429 - accuracy: 0.9372 - f1_score: 0.9359 - val_loss: 0.1473 - val_accuracy: 0.6669 - val_f1_score: 0.2121 - lr: 0.0500\n",
      "Epoch 68/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0432 - accuracy: 0.9363 - f1_score: 0.9344 - val_loss: 0.0534 - val_accuracy: 0.9375 - val_f1_score: 0.0104 - lr: 0.0500\n",
      "Epoch 69/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0424 - accuracy: 0.9373 - f1_score: 0.9357 - val_loss: 0.0569 - val_accuracy: 0.9373 - val_f1_score: 0.0181 - lr: 0.0500\n",
      "Epoch 70/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0424 - accuracy: 0.9370 - f1_score: 0.9348 - val_loss: 0.0554 - val_accuracy: 0.9387 - val_f1_score: 0.0077 - lr: 0.0500\n",
      "Epoch 71/1200\n",
      "639/639 [==============================] - 3s 5ms/step - loss: 0.0431 - accuracy: 0.9352 - f1_score: 0.9330 - val_loss: 0.1381 - val_accuracy: 0.6944 - val_f1_score: 0.2039 - lr: 0.0500\n",
      "Epoch 72/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0430 - accuracy: 0.9376 - f1_score: 0.9357 - val_loss: 0.0609 - val_accuracy: 0.9308 - val_f1_score: 0.0718 - lr: 0.0500\n",
      "Epoch 73/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0416 - accuracy: 0.9372 - f1_score: 0.9349 - val_loss: 0.1695 - val_accuracy: 0.7799 - val_f1_score: 0.1879 - lr: 0.0500\n",
      "Epoch 74/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0422 - accuracy: 0.9384 - f1_score: 0.9362 - val_loss: 0.0561 - val_accuracy: 0.9387 - val_f1_score: 0.0087 - lr: 0.0500\n",
      "Epoch 75/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0423 - accuracy: 0.9377 - f1_score: 0.9354 - val_loss: 0.0526 - val_accuracy: 0.9393 - val_f1_score: 0.0150 - lr: 0.0500\n",
      "Epoch 76/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0419 - accuracy: 0.9385 - f1_score: 0.9374 - val_loss: 0.0561 - val_accuracy: 0.9350 - val_f1_score: 0.0262 - lr: 0.0500\n",
      "Epoch 77/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0413 - accuracy: 0.9374 - f1_score: 0.9359 - val_loss: 0.0749 - val_accuracy: 0.9320 - val_f1_score: 0.0756 - lr: 0.0500\n",
      "Epoch 78/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0410 - accuracy: 0.9374 - f1_score: 0.9349 - val_loss: 0.0540 - val_accuracy: 0.9365 - val_f1_score: 0.0177 - lr: 0.0500\n",
      "Epoch 79/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0423 - accuracy: 0.9375 - f1_score: 0.9353 - val_loss: 0.0822 - val_accuracy: 0.9033 - val_f1_score: 0.1774 - lr: 0.0500\n",
      "Epoch 80/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0418 - accuracy: 0.9374 - f1_score: 0.9357 - val_loss: 0.0584 - val_accuracy: 0.9344 - val_f1_score: 0.0537 - lr: 0.0500\n",
      "Epoch 81/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0413 - accuracy: 0.9381 - f1_score: 0.9361 - val_loss: 0.0548 - val_accuracy: 0.9373 - val_f1_score: 0.0185 - lr: 0.0500\n",
      "Epoch 82/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0411 - accuracy: 0.9385 - f1_score: 0.9362 - val_loss: 0.0536 - val_accuracy: 0.9371 - val_f1_score: 0.0042 - lr: 0.0500\n",
      "Epoch 83/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0433 - accuracy: 0.9373 - f1_score: 0.9355 - val_loss: 0.0795 - val_accuracy: 0.9389 - val_f1_score: 0.0042 - lr: 0.0500\n",
      "Epoch 84/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0416 - accuracy: 0.9387 - f1_score: 0.9365 - val_loss: 0.1448 - val_accuracy: 0.6940 - val_f1_score: 0.2017 - lr: 0.0500\n",
      "Epoch 85/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0407 - accuracy: 0.9377 - f1_score: 0.9357 - val_loss: 0.1236 - val_accuracy: 0.7495 - val_f1_score: 0.2214 - lr: 0.0500\n",
      "Epoch 86/1200\n",
      "628/639 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9393 - f1_score: 0.9372\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0402 - accuracy: 0.9394 - f1_score: 0.9375 - val_loss: 0.0580 - val_accuracy: 0.9338 - val_f1_score: 0.0348 - lr: 0.0500\n",
      "Epoch 87/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0386 - accuracy: 0.9411 - f1_score: 0.9389 - val_loss: 0.0634 - val_accuracy: 0.9363 - val_f1_score: 0.0355 - lr: 0.0250\n",
      "Epoch 88/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0426 - accuracy: 0.9409 - f1_score: 0.9395 - val_loss: 0.0598 - val_accuracy: 0.9342 - val_f1_score: 0.0349 - lr: 0.0250\n",
      "Epoch 89/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0396 - accuracy: 0.9404 - f1_score: 0.9378 - val_loss: 0.0588 - val_accuracy: 0.9352 - val_f1_score: 0.0327 - lr: 0.0250\n",
      "Epoch 90/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0390 - accuracy: 0.9412 - f1_score: 0.9398 - val_loss: 0.0570 - val_accuracy: 0.9377 - val_f1_score: 0.0181 - lr: 0.0250\n",
      "Epoch 91/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0387 - accuracy: 0.9409 - f1_score: 0.9394 - val_loss: 0.0640 - val_accuracy: 0.9291 - val_f1_score: 0.0743 - lr: 0.0250\n",
      "Epoch 92/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0387 - accuracy: 0.9406 - f1_score: 0.9385 - val_loss: 0.0580 - val_accuracy: 0.9377 - val_f1_score: 0.0140 - lr: 0.0250\n",
      "Epoch 93/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0386 - accuracy: 0.9416 - f1_score: 0.9401 - val_loss: 0.0557 - val_accuracy: 0.9361 - val_f1_score: 0.0140 - lr: 0.0250\n",
      "Epoch 94/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0390 - accuracy: 0.9402 - f1_score: 0.9377 - val_loss: 0.0659 - val_accuracy: 0.9383 - val_f1_score: 0.0046 - lr: 0.0250\n",
      "Epoch 95/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0389 - accuracy: 0.9406 - f1_score: 0.9381 - val_loss: 0.0670 - val_accuracy: 0.9377 - val_f1_score: 0.0077 - lr: 0.0250\n",
      "Epoch 96/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0392 - accuracy: 0.9408 - f1_score: 0.9385 - val_loss: 0.0585 - val_accuracy: 0.9344 - val_f1_score: 0.0418 - lr: 0.0250\n",
      "Epoch 97/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0386 - accuracy: 0.9417 - f1_score: 0.9398 - val_loss: 0.0865 - val_accuracy: 0.8740 - val_f1_score: 0.2072 - lr: 0.0250\n",
      "Epoch 98/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0384 - accuracy: 0.9405 - f1_score: 0.9386 - val_loss: 0.0608 - val_accuracy: 0.9302 - val_f1_score: 0.0512 - lr: 0.0250\n",
      "Epoch 99/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0387 - accuracy: 0.9404 - f1_score: 0.9386 - val_loss: 0.0560 - val_accuracy: 0.9359 - val_f1_score: 0.0115 - lr: 0.0250\n",
      "Epoch 100/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0385 - accuracy: 0.9420 - f1_score: 0.9407 - val_loss: 0.0561 - val_accuracy: 0.9365 - val_f1_score: 0.0219 - lr: 0.0250\n",
      "Epoch 101/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0380 - accuracy: 0.9411 - f1_score: 0.9391 - val_loss: 0.0593 - val_accuracy: 0.9344 - val_f1_score: 0.0390 - lr: 0.0250\n",
      "Epoch 102/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0382 - accuracy: 0.9412 - f1_score: 0.9393 - val_loss: 0.0798 - val_accuracy: 0.9043 - val_f1_score: 0.1562 - lr: 0.0250\n",
      "Epoch 103/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0381 - accuracy: 0.9424 - f1_score: 0.9410 - val_loss: 0.0650 - val_accuracy: 0.9273 - val_f1_score: 0.0711 - lr: 0.0250\n",
      "Epoch 104/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0393 - accuracy: 0.9417 - f1_score: 0.9388 - val_loss: 0.0877 - val_accuracy: 0.8711 - val_f1_score: 0.1992 - lr: 0.0250\n",
      "Epoch 105/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0388 - accuracy: 0.9422 - f1_score: 0.9404 - val_loss: 0.0551 - val_accuracy: 0.9377 - val_f1_score: 0.0156 - lr: 0.0250\n",
      "Epoch 106/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0378 - accuracy: 0.9420 - f1_score: 0.9392 - val_loss: 0.0576 - val_accuracy: 0.9365 - val_f1_score: 0.0042 - lr: 0.0250\n",
      "Epoch 107/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0382 - accuracy: 0.9407 - f1_score: 0.9382 - val_loss: 0.0563 - val_accuracy: 0.9357 - val_f1_score: 0.0150 - lr: 0.0250\n",
      "Epoch 108/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0404 - accuracy: 0.9416 - f1_score: 0.9404 - val_loss: 0.0632 - val_accuracy: 0.9355 - val_f1_score: 0.0156 - lr: 0.0250\n",
      "Epoch 109/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0381 - accuracy: 0.9420 - f1_score: 0.9402 - val_loss: 0.0595 - val_accuracy: 0.9324 - val_f1_score: 0.0474 - lr: 0.0250\n",
      "Epoch 110/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0379 - accuracy: 0.9426 - f1_score: 0.9407 - val_loss: 0.0568 - val_accuracy: 0.9355 - val_f1_score: 0.0168 - lr: 0.0250\n",
      "Epoch 111/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0378 - accuracy: 0.9420 - f1_score: 0.9406 - val_loss: 0.0582 - val_accuracy: 0.9355 - val_f1_score: 0.0241 - lr: 0.0250\n",
      "Epoch 112/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0382 - accuracy: 0.9407 - f1_score: 0.9386 - val_loss: 0.1109 - val_accuracy: 0.7974 - val_f1_score: 0.2223 - lr: 0.0250\n",
      "Epoch 113/1200\n",
      "628/639 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9414 - f1_score: 0.9397\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0377 - accuracy: 0.9412 - f1_score: 0.9390 - val_loss: 0.0569 - val_accuracy: 0.9359 - val_f1_score: 0.0366 - lr: 0.0250\n",
      "Epoch 114/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0375 - accuracy: 0.9423 - f1_score: 0.9409 - val_loss: 0.0617 - val_accuracy: 0.9326 - val_f1_score: 0.0599 - lr: 0.0125\n",
      "Epoch 115/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0371 - accuracy: 0.9430 - f1_score: 0.9405 - val_loss: 0.0592 - val_accuracy: 0.9338 - val_f1_score: 0.0470 - lr: 0.0125\n",
      "Epoch 116/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0373 - accuracy: 0.9425 - f1_score: 0.9401 - val_loss: 0.0712 - val_accuracy: 0.9179 - val_f1_score: 0.1082 - lr: 0.0125\n",
      "Epoch 117/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0366 - accuracy: 0.9433 - f1_score: 0.9418 - val_loss: 0.0575 - val_accuracy: 0.9346 - val_f1_score: 0.0355 - lr: 0.0125\n",
      "Epoch 118/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0363 - accuracy: 0.9438 - f1_score: 0.9419 - val_loss: 0.0586 - val_accuracy: 0.9363 - val_f1_score: 0.0439 - lr: 0.0125\n",
      "Epoch 119/1200\n",
      "639/639 [==============================] - 2s 4ms/step - loss: 0.0359 - accuracy: 0.9436 - f1_score: 0.9418 - val_loss: 0.0952 - val_accuracy: 0.8556 - val_f1_score: 0.2077 - lr: 0.0125\n",
      "Epoch 120/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0365 - accuracy: 0.9427 - f1_score: 0.9410 - val_loss: 0.0604 - val_accuracy: 0.9369 - val_f1_score: 0.0327 - lr: 0.0125\n",
      "Epoch 121/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0366 - accuracy: 0.9431 - f1_score: 0.9413 - val_loss: 0.0587 - val_accuracy: 0.9359 - val_f1_score: 0.0431 - lr: 0.0125\n",
      "Epoch 122/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0365 - accuracy: 0.9427 - f1_score: 0.9406 - val_loss: 0.0598 - val_accuracy: 0.9344 - val_f1_score: 0.0528 - lr: 0.0125\n",
      "Epoch 123/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0364 - accuracy: 0.9429 - f1_score: 0.9414 - val_loss: 0.0604 - val_accuracy: 0.9326 - val_f1_score: 0.0620 - lr: 0.0125\n",
      "Epoch 124/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0364 - accuracy: 0.9442 - f1_score: 0.9426 - val_loss: 0.0591 - val_accuracy: 0.9373 - val_f1_score: 0.0156 - lr: 0.0125\n",
      "Epoch 125/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0368 - accuracy: 0.9436 - f1_score: 0.9417 - val_loss: 0.0573 - val_accuracy: 0.9375 - val_f1_score: 0.0431 - lr: 0.0125\n",
      "Epoch 126/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0363 - accuracy: 0.9437 - f1_score: 0.9424 - val_loss: 0.0691 - val_accuracy: 0.9194 - val_f1_score: 0.1066 - lr: 0.0125\n",
      "Epoch 127/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0358 - accuracy: 0.9434 - f1_score: 0.9417 - val_loss: 0.0596 - val_accuracy: 0.9344 - val_f1_score: 0.0462 - lr: 0.0125\n",
      "Epoch 128/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0368 - accuracy: 0.9432 - f1_score: 0.9418 - val_loss: 0.0583 - val_accuracy: 0.9348 - val_f1_score: 0.0358 - lr: 0.0125\n",
      "Epoch 129/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0362 - accuracy: 0.9435 - f1_score: 0.9419 - val_loss: 0.0617 - val_accuracy: 0.9298 - val_f1_score: 0.0698 - lr: 0.0125\n",
      "Epoch 130/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0365 - accuracy: 0.9433 - f1_score: 0.9416 - val_loss: 0.0566 - val_accuracy: 0.9354 - val_f1_score: 0.0421 - lr: 0.0125\n",
      "Epoch 131/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0363 - accuracy: 0.9434 - f1_score: 0.9418 - val_loss: 0.0594 - val_accuracy: 0.9322 - val_f1_score: 0.0635 - lr: 0.0125\n",
      "Epoch 132/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0364 - accuracy: 0.9437 - f1_score: 0.9417 - val_loss: 0.0645 - val_accuracy: 0.9255 - val_f1_score: 0.0948 - lr: 0.0125\n",
      "Epoch 133/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0361 - accuracy: 0.9437 - f1_score: 0.9421 - val_loss: 0.0574 - val_accuracy: 0.9377 - val_f1_score: 0.0192 - lr: 0.0125\n",
      "Epoch 134/1200\n",
      "624/639 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9431 - f1_score: 0.9416\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0366 - accuracy: 0.9432 - f1_score: 0.9416 - val_loss: 0.0569 - val_accuracy: 0.9357 - val_f1_score: 0.0385 - lr: 0.0125\n",
      "Epoch 135/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0361 - accuracy: 0.9432 - f1_score: 0.9412 - val_loss: 0.0606 - val_accuracy: 0.9328 - val_f1_score: 0.0522 - lr: 0.0063\n",
      "Epoch 136/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0360 - accuracy: 0.9443 - f1_score: 0.9427 - val_loss: 0.0583 - val_accuracy: 0.9336 - val_f1_score: 0.0424 - lr: 0.0063\n",
      "Epoch 137/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0359 - accuracy: 0.9438 - f1_score: 0.9417 - val_loss: 0.0577 - val_accuracy: 0.9342 - val_f1_score: 0.0466 - lr: 0.0063\n",
      "Epoch 138/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9451 - f1_score: 0.9426 - val_loss: 0.0613 - val_accuracy: 0.9312 - val_f1_score: 0.0673 - lr: 0.0063\n",
      "Epoch 139/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0353 - accuracy: 0.9437 - f1_score: 0.9423 - val_loss: 0.0600 - val_accuracy: 0.9328 - val_f1_score: 0.0487 - lr: 0.0063\n",
      "Epoch 140/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0359 - accuracy: 0.9429 - f1_score: 0.9403 - val_loss: 0.0635 - val_accuracy: 0.9310 - val_f1_score: 0.0586 - lr: 0.0063\n",
      "Epoch 141/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0356 - accuracy: 0.9442 - f1_score: 0.9427 - val_loss: 0.0590 - val_accuracy: 0.9355 - val_f1_score: 0.0302 - lr: 0.0063\n",
      "Epoch 142/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0355 - accuracy: 0.9445 - f1_score: 0.9427 - val_loss: 0.0571 - val_accuracy: 0.9350 - val_f1_score: 0.0156 - lr: 0.0063\n",
      "Epoch 143/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0357 - accuracy: 0.9449 - f1_score: 0.9432 - val_loss: 0.0581 - val_accuracy: 0.9332 - val_f1_score: 0.0348 - lr: 0.0063\n",
      "Epoch 144/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0361 - accuracy: 0.9433 - f1_score: 0.9415 - val_loss: 0.0634 - val_accuracy: 0.9293 - val_f1_score: 0.0707 - lr: 0.0063\n",
      "Epoch 145/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0360 - accuracy: 0.9431 - f1_score: 0.9419 - val_loss: 0.0627 - val_accuracy: 0.9287 - val_f1_score: 0.0662 - lr: 0.0063\n",
      "Epoch 146/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0355 - accuracy: 0.9446 - f1_score: 0.9424 - val_loss: 0.0586 - val_accuracy: 0.9344 - val_f1_score: 0.0348 - lr: 0.0063\n",
      "Epoch 147/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0353 - accuracy: 0.9449 - f1_score: 0.9437 - val_loss: 0.0586 - val_accuracy: 0.9342 - val_f1_score: 0.0390 - lr: 0.0063\n",
      "Epoch 148/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0362 - accuracy: 0.9440 - f1_score: 0.9420 - val_loss: 0.0601 - val_accuracy: 0.9320 - val_f1_score: 0.0589 - lr: 0.0063\n",
      "Epoch 149/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0354 - accuracy: 0.9452 - f1_score: 0.9436 - val_loss: 0.0572 - val_accuracy: 0.9348 - val_f1_score: 0.0421 - lr: 0.0063\n",
      "Epoch 150/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0356 - accuracy: 0.9445 - f1_score: 0.9422 - val_loss: 0.0577 - val_accuracy: 0.9361 - val_f1_score: 0.0125 - lr: 0.0063\n",
      "Epoch 151/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0356 - accuracy: 0.9446 - f1_score: 0.9436 - val_loss: 0.0587 - val_accuracy: 0.9332 - val_f1_score: 0.0418 - lr: 0.0063\n",
      "Epoch 152/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.9448 - f1_score: 0.9434 - val_loss: 0.0587 - val_accuracy: 0.9348 - val_f1_score: 0.0460 - lr: 0.0063\n",
      "Epoch 153/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0353 - accuracy: 0.9448 - f1_score: 0.9429 - val_loss: 0.0636 - val_accuracy: 0.9265 - val_f1_score: 0.0725 - lr: 0.0063\n",
      "Epoch 154/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0357 - accuracy: 0.9445 - f1_score: 0.9426 - val_loss: 0.0629 - val_accuracy: 0.9287 - val_f1_score: 0.0751 - lr: 0.0063\n",
      "Epoch 155/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0355 - accuracy: 0.9439 - f1_score: 0.9423 - val_loss: 0.0611 - val_accuracy: 0.9320 - val_f1_score: 0.0630 - lr: 0.0063\n",
      "Epoch 156/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0356 - accuracy: 0.9449 - f1_score: 0.9437 - val_loss: 0.0580 - val_accuracy: 0.9340 - val_f1_score: 0.0314 - lr: 0.0063\n",
      "Epoch 157/1200\n",
      "627/639 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9445 - f1_score: 0.9426\n",
      "Epoch 157: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0365 - accuracy: 0.9444 - f1_score: 0.9421 - val_loss: 0.0584 - val_accuracy: 0.9334 - val_f1_score: 0.0537 - lr: 0.0063\n",
      "Epoch 158/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0355 - accuracy: 0.9437 - f1_score: 0.9417 - val_loss: 0.0643 - val_accuracy: 0.9253 - val_f1_score: 0.0791 - lr: 0.0031\n",
      "Epoch 159/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0355 - accuracy: 0.9438 - f1_score: 0.9421 - val_loss: 0.0618 - val_accuracy: 0.9298 - val_f1_score: 0.0703 - lr: 0.0031\n",
      "Epoch 160/1200\n",
      "639/639 [==============================] - 2s 4ms/step - loss: 0.0359 - accuracy: 0.9444 - f1_score: 0.9424 - val_loss: 0.0607 - val_accuracy: 0.9316 - val_f1_score: 0.0610 - lr: 0.0031\n",
      "Epoch 161/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0353 - accuracy: 0.9441 - f1_score: 0.9420 - val_loss: 0.0618 - val_accuracy: 0.9304 - val_f1_score: 0.0630 - lr: 0.0031\n",
      "Epoch 162/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9452 - f1_score: 0.9426 - val_loss: 0.0607 - val_accuracy: 0.9308 - val_f1_score: 0.0599 - lr: 0.0031\n",
      "Epoch 163/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9445 - f1_score: 0.9426 - val_loss: 0.0578 - val_accuracy: 0.9346 - val_f1_score: 0.0324 - lr: 0.0031\n",
      "Epoch 164/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0361 - accuracy: 0.9440 - f1_score: 0.9421 - val_loss: 0.0590 - val_accuracy: 0.9332 - val_f1_score: 0.0585 - lr: 0.0031\n",
      "Epoch 165/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9451 - f1_score: 0.9431 - val_loss: 0.0617 - val_accuracy: 0.9283 - val_f1_score: 0.0740 - lr: 0.0031\n",
      "Epoch 166/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9444 - f1_score: 0.9429 - val_loss: 0.0642 - val_accuracy: 0.9267 - val_f1_score: 0.0724 - lr: 0.0031\n",
      "Epoch 167/1200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9449 - f1_score: 0.9427\n",
      "Epoch 167: ReduceLROnPlateau reducing learning rate to 0.0015625000232830644.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9446 - f1_score: 0.9425 - val_loss: 0.0618 - val_accuracy: 0.9300 - val_f1_score: 0.0682 - lr: 0.0031\n",
      "Epoch 168/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9451 - f1_score: 0.9438 - val_loss: 0.0596 - val_accuracy: 0.9332 - val_f1_score: 0.0522 - lr: 0.0016\n",
      "Epoch 169/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0351 - accuracy: 0.9446 - f1_score: 0.9429 - val_loss: 0.0598 - val_accuracy: 0.9334 - val_f1_score: 0.0610 - lr: 0.0016\n",
      "Epoch 170/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9444 - f1_score: 0.9422 - val_loss: 0.0596 - val_accuracy: 0.9336 - val_f1_score: 0.0672 - lr: 0.0016\n",
      "Epoch 171/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9454 - f1_score: 0.9432 - val_loss: 0.0608 - val_accuracy: 0.9312 - val_f1_score: 0.0630 - lr: 0.0016\n",
      "Epoch 172/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0354 - accuracy: 0.9445 - f1_score: 0.9420 - val_loss: 0.0634 - val_accuracy: 0.9281 - val_f1_score: 0.0762 - lr: 0.0016\n",
      "Epoch 173/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9456 - f1_score: 0.9442 - val_loss: 0.0612 - val_accuracy: 0.9308 - val_f1_score: 0.0662 - lr: 0.0016\n",
      "Epoch 174/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9441 - f1_score: 0.9421 - val_loss: 0.0601 - val_accuracy: 0.9316 - val_f1_score: 0.0647 - lr: 0.0016\n",
      "Epoch 175/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9449 - f1_score: 0.9432 - val_loss: 0.0601 - val_accuracy: 0.9328 - val_f1_score: 0.0662 - lr: 0.0016\n",
      "Epoch 176/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0351 - accuracy: 0.9449 - f1_score: 0.9432 - val_loss: 0.0604 - val_accuracy: 0.9318 - val_f1_score: 0.0610 - lr: 0.0016\n",
      "Epoch 177/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0356 - accuracy: 0.9442 - f1_score: 0.9421 - val_loss: 0.0612 - val_accuracy: 0.9320 - val_f1_score: 0.0651 - lr: 0.0016\n",
      "Epoch 178/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0351 - accuracy: 0.9446 - f1_score: 0.9431 - val_loss: 0.0614 - val_accuracy: 0.9306 - val_f1_score: 0.0620 - lr: 0.0016\n",
      "Epoch 179/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9452 - f1_score: 0.9430 - val_loss: 0.0607 - val_accuracy: 0.9312 - val_f1_score: 0.0564 - lr: 0.0016\n",
      "Epoch 180/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0343 - accuracy: 0.9456 - f1_score: 0.9440 - val_loss: 0.0620 - val_accuracy: 0.9316 - val_f1_score: 0.0714 - lr: 0.0016\n",
      "Epoch 181/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9452 - f1_score: 0.9439 - val_loss: 0.0604 - val_accuracy: 0.9326 - val_f1_score: 0.0585 - lr: 0.0016\n",
      "Epoch 182/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9448 - f1_score: 0.9433 - val_loss: 0.0610 - val_accuracy: 0.9308 - val_f1_score: 0.0585 - lr: 0.0016\n",
      "Epoch 183/1200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9447 - f1_score: 0.9432\n",
      "Epoch 183: ReduceLROnPlateau reducing learning rate to 0.0007812500116415322.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9448 - f1_score: 0.9434 - val_loss: 0.0604 - val_accuracy: 0.9330 - val_f1_score: 0.0522 - lr: 0.0016\n",
      "Epoch 184/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9451 - f1_score: 0.9434 - val_loss: 0.0626 - val_accuracy: 0.9300 - val_f1_score: 0.0770 - lr: 7.8125e-04\n",
      "Epoch 185/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9459 - f1_score: 0.9443 - val_loss: 0.0613 - val_accuracy: 0.9318 - val_f1_score: 0.0605 - lr: 7.8125e-04\n",
      "Epoch 186/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9455 - f1_score: 0.9438 - val_loss: 0.0618 - val_accuracy: 0.9306 - val_f1_score: 0.0620 - lr: 7.8125e-04\n",
      "Epoch 187/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9453 - f1_score: 0.9437 - val_loss: 0.0623 - val_accuracy: 0.9304 - val_f1_score: 0.0697 - lr: 7.8125e-04\n",
      "Epoch 188/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.9460 - f1_score: 0.9441 - val_loss: 0.0624 - val_accuracy: 0.9302 - val_f1_score: 0.0755 - lr: 7.8125e-04\n",
      "Epoch 189/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0343 - accuracy: 0.9449 - f1_score: 0.9433 - val_loss: 0.0599 - val_accuracy: 0.9328 - val_f1_score: 0.0543 - lr: 7.8125e-04\n",
      "Epoch 190/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9439 - f1_score: 0.9423 - val_loss: 0.0611 - val_accuracy: 0.9314 - val_f1_score: 0.0593 - lr: 7.8125e-04\n",
      "Epoch 191/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0355 - accuracy: 0.9448 - f1_score: 0.9426 - val_loss: 0.0598 - val_accuracy: 0.9330 - val_f1_score: 0.0543 - lr: 7.8125e-04\n",
      "Epoch 192/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0351 - accuracy: 0.9441 - f1_score: 0.9423 - val_loss: 0.0605 - val_accuracy: 0.9322 - val_f1_score: 0.0595 - lr: 7.8125e-04\n",
      "Epoch 193/1200\n",
      "631/639 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9443 - f1_score: 0.9425\n",
      "Epoch 193: ReduceLROnPlateau reducing learning rate to 0.0003906250058207661.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9442 - f1_score: 0.9424 - val_loss: 0.0617 - val_accuracy: 0.9304 - val_f1_score: 0.0739 - lr: 7.8125e-04\n",
      "Epoch 194/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9447 - f1_score: 0.9427 - val_loss: 0.0602 - val_accuracy: 0.9326 - val_f1_score: 0.0605 - lr: 3.9063e-04\n",
      "Epoch 195/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9459 - f1_score: 0.9442 - val_loss: 0.0614 - val_accuracy: 0.9318 - val_f1_score: 0.0657 - lr: 3.9063e-04\n",
      "Epoch 196/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9448 - f1_score: 0.9429 - val_loss: 0.0607 - val_accuracy: 0.9302 - val_f1_score: 0.0557 - lr: 3.9063e-04\n",
      "Epoch 197/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9444 - f1_score: 0.9424 - val_loss: 0.0607 - val_accuracy: 0.9316 - val_f1_score: 0.0589 - lr: 3.9063e-04\n",
      "Epoch 198/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9438 - f1_score: 0.9421 - val_loss: 0.0605 - val_accuracy: 0.9326 - val_f1_score: 0.0637 - lr: 3.9063e-04\n",
      "Epoch 199/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9450 - f1_score: 0.9430 - val_loss: 0.0600 - val_accuracy: 0.9326 - val_f1_score: 0.0585 - lr: 3.9063e-04\n",
      "Epoch 200/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9449 - f1_score: 0.9440 - val_loss: 0.0607 - val_accuracy: 0.9316 - val_f1_score: 0.0651 - lr: 3.9063e-04\n",
      "Epoch 201/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9444 - f1_score: 0.9418 - val_loss: 0.0612 - val_accuracy: 0.9330 - val_f1_score: 0.0599 - lr: 3.9063e-04\n",
      "Epoch 202/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0355 - accuracy: 0.9446 - f1_score: 0.9428 - val_loss: 0.0607 - val_accuracy: 0.9326 - val_f1_score: 0.0578 - lr: 3.9063e-04\n",
      "Epoch 203/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9455 - f1_score: 0.9444 - val_loss: 0.0611 - val_accuracy: 0.9306 - val_f1_score: 0.0616 - lr: 3.9063e-04\n",
      "Epoch 204/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9449 - f1_score: 0.9427 - val_loss: 0.0619 - val_accuracy: 0.9304 - val_f1_score: 0.0641 - lr: 3.9063e-04\n",
      "Epoch 205/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.9453 - f1_score: 0.9434 - val_loss: 0.0604 - val_accuracy: 0.9318 - val_f1_score: 0.0647 - lr: 3.9063e-04\n",
      "Epoch 206/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9450 - f1_score: 0.9434 - val_loss: 0.0606 - val_accuracy: 0.9320 - val_f1_score: 0.0574 - lr: 3.9063e-04\n",
      "Epoch 207/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9460 - f1_score: 0.9446 - val_loss: 0.0611 - val_accuracy: 0.9322 - val_f1_score: 0.0693 - lr: 3.9063e-04\n",
      "Epoch 208/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0351 - accuracy: 0.9441 - f1_score: 0.9427 - val_loss: 0.0614 - val_accuracy: 0.9302 - val_f1_score: 0.0620 - lr: 3.9063e-04\n",
      "Epoch 209/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9455 - f1_score: 0.9439 - val_loss: 0.0607 - val_accuracy: 0.9316 - val_f1_score: 0.0703 - lr: 3.9063e-04\n",
      "Epoch 210/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9459 - f1_score: 0.9443 - val_loss: 0.0608 - val_accuracy: 0.9312 - val_f1_score: 0.0605 - lr: 3.9063e-04\n",
      "Epoch 211/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0341 - accuracy: 0.9446 - f1_score: 0.9429 - val_loss: 0.0606 - val_accuracy: 0.9320 - val_f1_score: 0.0537 - lr: 3.9063e-04\n",
      "Epoch 212/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9449 - f1_score: 0.9433 - val_loss: 0.0605 - val_accuracy: 0.9318 - val_f1_score: 0.0599 - lr: 3.9063e-04\n",
      "Epoch 213/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0342 - accuracy: 0.9465 - f1_score: 0.9454 - val_loss: 0.0614 - val_accuracy: 0.9318 - val_f1_score: 0.0657 - lr: 3.9063e-04\n",
      "Epoch 214/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9443 - f1_score: 0.9423 - val_loss: 0.0622 - val_accuracy: 0.9293 - val_f1_score: 0.0678 - lr: 3.9063e-04\n",
      "Epoch 215/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9447 - f1_score: 0.9429 - val_loss: 0.0619 - val_accuracy: 0.9306 - val_f1_score: 0.0662 - lr: 3.9063e-04\n",
      "Epoch 216/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9450 - f1_score: 0.9432 - val_loss: 0.0619 - val_accuracy: 0.9304 - val_f1_score: 0.0689 - lr: 3.9063e-04\n",
      "Epoch 217/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9454 - f1_score: 0.9439 - val_loss: 0.0617 - val_accuracy: 0.9314 - val_f1_score: 0.0605 - lr: 3.9063e-04\n",
      "Epoch 218/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9445 - f1_score: 0.9426 - val_loss: 0.0612 - val_accuracy: 0.9318 - val_f1_score: 0.0657 - lr: 3.9063e-04\n",
      "Epoch 219/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9448 - f1_score: 0.9428 - val_loss: 0.0613 - val_accuracy: 0.9318 - val_f1_score: 0.0630 - lr: 3.9063e-04\n",
      "Epoch 220/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0353 - accuracy: 0.9447 - f1_score: 0.9430 - val_loss: 0.0615 - val_accuracy: 0.9302 - val_f1_score: 0.0593 - lr: 3.9063e-04\n",
      "Epoch 221/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9448 - f1_score: 0.9437 - val_loss: 0.0631 - val_accuracy: 0.9259 - val_f1_score: 0.0665 - lr: 3.9063e-04\n",
      "Epoch 222/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0344 - accuracy: 0.9454 - f1_score: 0.9441 - val_loss: 0.0606 - val_accuracy: 0.9310 - val_f1_score: 0.0589 - lr: 3.9063e-04\n",
      "Epoch 223/1200\n",
      "631/639 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9440 - f1_score: 0.9417\n",
      "Epoch 223: ReduceLROnPlateau reducing learning rate to 0.00019531250291038305.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9439 - f1_score: 0.9413 - val_loss: 0.0608 - val_accuracy: 0.9322 - val_f1_score: 0.0666 - lr: 3.9063e-04\n",
      "Epoch 224/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0351 - accuracy: 0.9447 - f1_score: 0.9432 - val_loss: 0.0608 - val_accuracy: 0.9324 - val_f1_score: 0.0610 - lr: 1.9531e-04\n",
      "Epoch 225/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0354 - accuracy: 0.9444 - f1_score: 0.9426 - val_loss: 0.0615 - val_accuracy: 0.9306 - val_f1_score: 0.0662 - lr: 1.9531e-04\n",
      "Epoch 226/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9442 - f1_score: 0.9419 - val_loss: 0.0607 - val_accuracy: 0.9302 - val_f1_score: 0.0599 - lr: 1.9531e-04\n",
      "Epoch 227/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.9451 - f1_score: 0.9435 - val_loss: 0.0605 - val_accuracy: 0.9326 - val_f1_score: 0.0522 - lr: 1.9531e-04\n",
      "Epoch 228/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9445 - f1_score: 0.9428 - val_loss: 0.0603 - val_accuracy: 0.9328 - val_f1_score: 0.0620 - lr: 1.9531e-04\n",
      "Epoch 229/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0342 - accuracy: 0.9439 - f1_score: 0.9419 - val_loss: 0.0613 - val_accuracy: 0.9308 - val_f1_score: 0.0656 - lr: 1.9531e-04\n",
      "Epoch 230/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9449 - f1_score: 0.9436 - val_loss: 0.0607 - val_accuracy: 0.9316 - val_f1_score: 0.0578 - lr: 1.9531e-04\n",
      "Epoch 231/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0354 - accuracy: 0.9450 - f1_score: 0.9435 - val_loss: 0.0621 - val_accuracy: 0.9297 - val_f1_score: 0.0724 - lr: 1.9531e-04\n",
      "Epoch 232/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0342 - accuracy: 0.9452 - f1_score: 0.9442 - val_loss: 0.0612 - val_accuracy: 0.9308 - val_f1_score: 0.0599 - lr: 1.9531e-04\n",
      "Epoch 233/1200\n",
      "624/639 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9446 - f1_score: 0.9427\n",
      "Epoch 233: ReduceLROnPlateau reducing learning rate to 9.765625145519152e-05.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0344 - accuracy: 0.9445 - f1_score: 0.9426 - val_loss: 0.0618 - val_accuracy: 0.9304 - val_f1_score: 0.0672 - lr: 1.9531e-04\n",
      "Epoch 234/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9442 - f1_score: 0.9420 - val_loss: 0.0623 - val_accuracy: 0.9304 - val_f1_score: 0.0689 - lr: 9.7656e-05\n",
      "Epoch 235/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9453 - f1_score: 0.9436 - val_loss: 0.0627 - val_accuracy: 0.9297 - val_f1_score: 0.0766 - lr: 9.7656e-05\n",
      "Epoch 236/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9459 - f1_score: 0.9440 - val_loss: 0.0602 - val_accuracy: 0.9322 - val_f1_score: 0.0605 - lr: 9.7656e-05\n",
      "Epoch 237/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0343 - accuracy: 0.9454 - f1_score: 0.9440 - val_loss: 0.0608 - val_accuracy: 0.9322 - val_f1_score: 0.0626 - lr: 9.7656e-05\n",
      "Epoch 238/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0344 - accuracy: 0.9447 - f1_score: 0.9437 - val_loss: 0.0621 - val_accuracy: 0.9318 - val_f1_score: 0.0729 - lr: 9.7656e-05\n",
      "Epoch 239/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9445 - f1_score: 0.9429 - val_loss: 0.0612 - val_accuracy: 0.9320 - val_f1_score: 0.0657 - lr: 9.7656e-05\n",
      "Epoch 240/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0342 - accuracy: 0.9452 - f1_score: 0.9442 - val_loss: 0.0621 - val_accuracy: 0.9308 - val_f1_score: 0.0620 - lr: 9.7656e-05\n",
      "Epoch 241/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0351 - accuracy: 0.9436 - f1_score: 0.9419 - val_loss: 0.0611 - val_accuracy: 0.9320 - val_f1_score: 0.0616 - lr: 9.7656e-05\n",
      "Epoch 242/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.9446 - f1_score: 0.9430 - val_loss: 0.0604 - val_accuracy: 0.9314 - val_f1_score: 0.0543 - lr: 9.7656e-05\n",
      "Epoch 243/1200\n",
      "636/639 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9452 - f1_score: 0.9432\n",
      "Epoch 243: ReduceLROnPlateau reducing learning rate to 4.882812572759576e-05.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9452 - f1_score: 0.9433 - val_loss: 0.0613 - val_accuracy: 0.9310 - val_f1_score: 0.0574 - lr: 9.7656e-05\n",
      "Epoch 244/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.9446 - f1_score: 0.9427 - val_loss: 0.0608 - val_accuracy: 0.9320 - val_f1_score: 0.0626 - lr: 4.8828e-05\n",
      "Epoch 245/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9442 - f1_score: 0.9427 - val_loss: 0.0619 - val_accuracy: 0.9306 - val_f1_score: 0.0682 - lr: 4.8828e-05\n",
      "Epoch 246/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.9455 - f1_score: 0.9437 - val_loss: 0.0609 - val_accuracy: 0.9316 - val_f1_score: 0.0599 - lr: 4.8828e-05\n",
      "Epoch 247/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0351 - accuracy: 0.9434 - f1_score: 0.9408 - val_loss: 0.0605 - val_accuracy: 0.9326 - val_f1_score: 0.0610 - lr: 4.8828e-05\n",
      "Epoch 248/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9445 - f1_score: 0.9422 - val_loss: 0.0616 - val_accuracy: 0.9314 - val_f1_score: 0.0595 - lr: 4.8828e-05\n",
      "Epoch 249/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9444 - f1_score: 0.9430 - val_loss: 0.0613 - val_accuracy: 0.9324 - val_f1_score: 0.0641 - lr: 4.8828e-05\n",
      "Epoch 250/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0351 - accuracy: 0.9441 - f1_score: 0.9424 - val_loss: 0.0621 - val_accuracy: 0.9300 - val_f1_score: 0.0624 - lr: 4.8828e-05\n",
      "Epoch 251/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9443 - f1_score: 0.9428 - val_loss: 0.0605 - val_accuracy: 0.9328 - val_f1_score: 0.0605 - lr: 4.8828e-05\n",
      "Epoch 252/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9450 - f1_score: 0.9436 - val_loss: 0.0631 - val_accuracy: 0.9298 - val_f1_score: 0.0724 - lr: 4.8828e-05\n",
      "Epoch 253/1200\n",
      "635/639 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9449 - f1_score: 0.9432\n",
      "Epoch 253: ReduceLROnPlateau reducing learning rate to 2.441406286379788e-05.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9449 - f1_score: 0.9433 - val_loss: 0.0608 - val_accuracy: 0.9316 - val_f1_score: 0.0641 - lr: 4.8828e-05\n",
      "Epoch 254/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9454 - f1_score: 0.9436 - val_loss: 0.0618 - val_accuracy: 0.9314 - val_f1_score: 0.0657 - lr: 2.4414e-05\n",
      "Epoch 255/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9441 - f1_score: 0.9417 - val_loss: 0.0616 - val_accuracy: 0.9312 - val_f1_score: 0.0637 - lr: 2.4414e-05\n",
      "Epoch 256/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9446 - f1_score: 0.9438 - val_loss: 0.0616 - val_accuracy: 0.9302 - val_f1_score: 0.0662 - lr: 2.4414e-05\n",
      "Epoch 257/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9446 - f1_score: 0.9429 - val_loss: 0.0615 - val_accuracy: 0.9306 - val_f1_score: 0.0595 - lr: 2.4414e-05\n",
      "Epoch 258/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9450 - f1_score: 0.9428 - val_loss: 0.0616 - val_accuracy: 0.9306 - val_f1_score: 0.0616 - lr: 2.4414e-05\n",
      "Epoch 259/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9448 - f1_score: 0.9426 - val_loss: 0.0607 - val_accuracy: 0.9324 - val_f1_score: 0.0610 - lr: 2.4414e-05\n",
      "Epoch 260/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9454 - f1_score: 0.9437 - val_loss: 0.0629 - val_accuracy: 0.9295 - val_f1_score: 0.0710 - lr: 2.4414e-05\n",
      "Epoch 261/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9453 - f1_score: 0.9438 - val_loss: 0.0606 - val_accuracy: 0.9326 - val_f1_score: 0.0585 - lr: 2.4414e-05\n",
      "Epoch 262/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.9452 - f1_score: 0.9437 - val_loss: 0.0606 - val_accuracy: 0.9322 - val_f1_score: 0.0610 - lr: 2.4414e-05\n",
      "Epoch 263/1200\n",
      "624/639 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9445 - f1_score: 0.9426\n",
      "Epoch 263: ReduceLROnPlateau reducing learning rate to 1.220703143189894e-05.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.9446 - f1_score: 0.9426 - val_loss: 0.0608 - val_accuracy: 0.9324 - val_f1_score: 0.0585 - lr: 2.4414e-05\n",
      "Epoch 264/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9442 - f1_score: 0.9418 - val_loss: 0.0611 - val_accuracy: 0.9322 - val_f1_score: 0.0657 - lr: 1.2207e-05\n",
      "Epoch 265/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0351 - accuracy: 0.9443 - f1_score: 0.9422 - val_loss: 0.0613 - val_accuracy: 0.9316 - val_f1_score: 0.0599 - lr: 1.2207e-05\n",
      "Epoch 266/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9450 - f1_score: 0.9430 - val_loss: 0.0606 - val_accuracy: 0.9314 - val_f1_score: 0.0585 - lr: 1.2207e-05\n",
      "Epoch 267/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0342 - accuracy: 0.9464 - f1_score: 0.9452 - val_loss: 0.0620 - val_accuracy: 0.9314 - val_f1_score: 0.0672 - lr: 1.2207e-05\n",
      "Epoch 268/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9451 - f1_score: 0.9435 - val_loss: 0.0616 - val_accuracy: 0.9318 - val_f1_score: 0.0699 - lr: 1.2207e-05\n",
      "Epoch 269/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0342 - accuracy: 0.9455 - f1_score: 0.9444 - val_loss: 0.0624 - val_accuracy: 0.9302 - val_f1_score: 0.0672 - lr: 1.2207e-05\n",
      "Epoch 270/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9454 - f1_score: 0.9440 - val_loss: 0.0612 - val_accuracy: 0.9308 - val_f1_score: 0.0599 - lr: 1.2207e-05\n",
      "Epoch 271/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9451 - f1_score: 0.9439 - val_loss: 0.0614 - val_accuracy: 0.9314 - val_f1_score: 0.0599 - lr: 1.2207e-05\n",
      "Epoch 272/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0351 - accuracy: 0.9449 - f1_score: 0.9438 - val_loss: 0.0622 - val_accuracy: 0.9304 - val_f1_score: 0.0703 - lr: 1.2207e-05\n",
      "Epoch 273/1200\n",
      "628/639 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9454 - f1_score: 0.9439\n",
      "Epoch 273: ReduceLROnPlateau reducing learning rate to 6.10351571594947e-06.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0343 - accuracy: 0.9449 - f1_score: 0.9434 - val_loss: 0.0607 - val_accuracy: 0.9324 - val_f1_score: 0.0595 - lr: 1.2207e-05\n",
      "Epoch 274/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9455 - f1_score: 0.9439 - val_loss: 0.0614 - val_accuracy: 0.9322 - val_f1_score: 0.0637 - lr: 6.1035e-06\n",
      "Epoch 275/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0342 - accuracy: 0.9454 - f1_score: 0.9428 - val_loss: 0.0612 - val_accuracy: 0.9308 - val_f1_score: 0.0574 - lr: 6.1035e-06\n",
      "Epoch 276/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9448 - f1_score: 0.9439 - val_loss: 0.0619 - val_accuracy: 0.9308 - val_f1_score: 0.0641 - lr: 6.1035e-06\n",
      "Epoch 277/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0344 - accuracy: 0.9458 - f1_score: 0.9441 - val_loss: 0.0616 - val_accuracy: 0.9306 - val_f1_score: 0.0641 - lr: 6.1035e-06\n",
      "Epoch 278/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9451 - f1_score: 0.9436 - val_loss: 0.0614 - val_accuracy: 0.9308 - val_f1_score: 0.0605 - lr: 6.1035e-06\n",
      "Epoch 279/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9451 - f1_score: 0.9435 - val_loss: 0.0625 - val_accuracy: 0.9295 - val_f1_score: 0.0703 - lr: 6.1035e-06\n",
      "Epoch 280/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9446 - f1_score: 0.9436 - val_loss: 0.0610 - val_accuracy: 0.9310 - val_f1_score: 0.0599 - lr: 6.1035e-06\n",
      "Epoch 281/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9446 - f1_score: 0.9434 - val_loss: 0.0602 - val_accuracy: 0.9324 - val_f1_score: 0.0605 - lr: 6.1035e-06\n",
      "Epoch 282/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9452 - f1_score: 0.9436 - val_loss: 0.0609 - val_accuracy: 0.9312 - val_f1_score: 0.0585 - lr: 6.1035e-06\n",
      "Epoch 283/1200\n",
      "627/639 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9453 - f1_score: 0.9438\n",
      "Epoch 283: ReduceLROnPlateau reducing learning rate to 3.051757857974735e-06.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0353 - accuracy: 0.9452 - f1_score: 0.9434 - val_loss: 0.0622 - val_accuracy: 0.9312 - val_f1_score: 0.0676 - lr: 6.1035e-06\n",
      "Epoch 284/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9448 - f1_score: 0.9430 - val_loss: 0.0618 - val_accuracy: 0.9310 - val_f1_score: 0.0620 - lr: 3.0518e-06\n",
      "Epoch 285/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9440 - f1_score: 0.9432 - val_loss: 0.0616 - val_accuracy: 0.9306 - val_f1_score: 0.0718 - lr: 3.0518e-06\n",
      "Epoch 286/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9452 - f1_score: 0.9439 - val_loss: 0.0619 - val_accuracy: 0.9314 - val_f1_score: 0.0647 - lr: 3.0518e-06\n",
      "Epoch 287/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0340 - accuracy: 0.9458 - f1_score: 0.9449 - val_loss: 0.0618 - val_accuracy: 0.9318 - val_f1_score: 0.0637 - lr: 3.0518e-06\n",
      "Epoch 288/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.9447 - f1_score: 0.9427 - val_loss: 0.0613 - val_accuracy: 0.9316 - val_f1_score: 0.0620 - lr: 3.0518e-06\n",
      "Epoch 289/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0344 - accuracy: 0.9454 - f1_score: 0.9442 - val_loss: 0.0612 - val_accuracy: 0.9310 - val_f1_score: 0.0599 - lr: 3.0518e-06\n",
      "Epoch 290/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9452 - f1_score: 0.9437 - val_loss: 0.0611 - val_accuracy: 0.9318 - val_f1_score: 0.0637 - lr: 3.0518e-06\n",
      "Epoch 291/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9448 - f1_score: 0.9432 - val_loss: 0.0619 - val_accuracy: 0.9302 - val_f1_score: 0.0657 - lr: 3.0518e-06\n",
      "Epoch 292/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0349 - accuracy: 0.9444 - f1_score: 0.9424 - val_loss: 0.0619 - val_accuracy: 0.9318 - val_f1_score: 0.0710 - lr: 3.0518e-06\n",
      "Epoch 293/1200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9443 - f1_score: 0.9432\n",
      "Epoch 293: ReduceLROnPlateau reducing learning rate to 1.5258789289873675e-06.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9443 - f1_score: 0.9431 - val_loss: 0.0612 - val_accuracy: 0.9316 - val_f1_score: 0.0599 - lr: 3.0518e-06\n",
      "Epoch 294/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0341 - accuracy: 0.9453 - f1_score: 0.9432 - val_loss: 0.0619 - val_accuracy: 0.9310 - val_f1_score: 0.0697 - lr: 1.5259e-06\n",
      "Epoch 295/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9447 - f1_score: 0.9431 - val_loss: 0.0613 - val_accuracy: 0.9318 - val_f1_score: 0.0605 - lr: 1.5259e-06\n",
      "Epoch 296/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9440 - f1_score: 0.9424 - val_loss: 0.0617 - val_accuracy: 0.9316 - val_f1_score: 0.0682 - lr: 1.5259e-06\n",
      "Epoch 297/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0355 - accuracy: 0.9448 - f1_score: 0.9435 - val_loss: 0.0612 - val_accuracy: 0.9318 - val_f1_score: 0.0630 - lr: 1.5259e-06\n",
      "Epoch 298/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0343 - accuracy: 0.9453 - f1_score: 0.9432 - val_loss: 0.0618 - val_accuracy: 0.9318 - val_f1_score: 0.0714 - lr: 1.5259e-06\n",
      "Epoch 299/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9436 - f1_score: 0.9418 - val_loss: 0.0610 - val_accuracy: 0.9306 - val_f1_score: 0.0656 - lr: 1.5259e-06\n",
      "Epoch 300/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0353 - accuracy: 0.9448 - f1_score: 0.9437 - val_loss: 0.0617 - val_accuracy: 0.9302 - val_f1_score: 0.0605 - lr: 1.5259e-06\n",
      "Epoch 301/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9449 - f1_score: 0.9425 - val_loss: 0.0610 - val_accuracy: 0.9324 - val_f1_score: 0.0605 - lr: 1.5259e-06\n",
      "Epoch 302/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9444 - f1_score: 0.9419 - val_loss: 0.0609 - val_accuracy: 0.9316 - val_f1_score: 0.0605 - lr: 1.5259e-06\n",
      "Epoch 303/1200\n",
      "625/639 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9451 - f1_score: 0.9440\n",
      "Epoch 303: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9453 - f1_score: 0.9442 - val_loss: 0.0614 - val_accuracy: 0.9322 - val_f1_score: 0.0693 - lr: 1.5259e-06\n",
      "Epoch 304/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9456 - f1_score: 0.9446 - val_loss: 0.0620 - val_accuracy: 0.9300 - val_f1_score: 0.0635 - lr: 1.0000e-06\n",
      "Epoch 305/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9442 - f1_score: 0.9431 - val_loss: 0.0613 - val_accuracy: 0.9322 - val_f1_score: 0.0657 - lr: 1.0000e-06\n",
      "Epoch 306/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0354 - accuracy: 0.9447 - f1_score: 0.9423 - val_loss: 0.0619 - val_accuracy: 0.9308 - val_f1_score: 0.0668 - lr: 1.0000e-06\n",
      "Epoch 307/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0356 - accuracy: 0.9448 - f1_score: 0.9429 - val_loss: 0.0611 - val_accuracy: 0.9314 - val_f1_score: 0.0637 - lr: 1.0000e-06\n",
      "Epoch 308/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0348 - accuracy: 0.9456 - f1_score: 0.9436 - val_loss: 0.0613 - val_accuracy: 0.9324 - val_f1_score: 0.0599 - lr: 1.0000e-06\n",
      "Epoch 309/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9455 - f1_score: 0.9435 - val_loss: 0.0619 - val_accuracy: 0.9295 - val_f1_score: 0.0630 - lr: 1.0000e-06\n",
      "Epoch 310/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9445 - f1_score: 0.9424 - val_loss: 0.0616 - val_accuracy: 0.9314 - val_f1_score: 0.0699 - lr: 1.0000e-06\n",
      "Epoch 311/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9453 - f1_score: 0.9434 - val_loss: 0.0612 - val_accuracy: 0.9304 - val_f1_score: 0.0578 - lr: 1.0000e-06\n",
      "Epoch 312/1200\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9457 - f1_score: 0.9431 - val_loss: 0.0632 - val_accuracy: 0.9295 - val_f1_score: 0.0714 - lr: 1.0000e-06\n",
      "Epoch 313/1200\n",
      "638/639 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9458 - f1_score: 0.9442Restoring model weights from the end of the best epoch: 213.\n",
      "639/639 [==============================] - 3s 4ms/step - loss: 0.0346 - accuracy: 0.9458 - f1_score: 0.9441 - val_loss: 0.0620 - val_accuracy: 0.9297 - val_f1_score: 0.0697 - lr: 1.0000e-06\n",
      "Epoch 313: early stopping\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\__autograph_generated_filebykjoj27.py\", line 10, in tf__call\n        ag__.ld(self).activations = ag__.converted_call(ag__.ld(self).tabnet_encoder, (ag__.ld(inputs),), dict(training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\__autograph_generated_filezzx_g2uv.py\", line 28, in tf__call\n        x = ag__.converted_call(ag__.ld(self).initial_bn, (ag__.ld(inputs),), dict(training=ag__.ld(training)), fscope)\n\n    ValueError: Exception encountered when calling layer 'tab_net_classifier_1' (type TabNetClassifier).\n    \n    in user code:\n    \n        File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\tabnet_keras\\models.py\", line 97, in call  *\n            self.activations = self.tabnet_encoder(inputs, training=training)\n        File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\__autograph_generated_filezzx_g2uv.py\", line 28, in tf__call\n            x = ag__.converted_call(ag__.ld(self).initial_bn, (ag__.ld(inputs),), dict(training=ag__.ld(training)), fscope)\n    \n        ValueError: Exception encountered when calling layer 'tab_net_encoder_1' (type TabNetEncoder).\n        \n        in user code:\n        \n            File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\tabnet_keras\\encoder.py\", line 143, in call  *\n                x = self.initial_bn(inputs, training=training)\n            File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n                raise ValueError(\n        \n            ValueError: Input 0 of layer \"batch_normalization_5\" is incompatible with the layer: expected axis 1 of input shape to have value 34, but received input with shape (None, 3)\n        \n        \n        Call arguments received by layer 'tab_net_encoder_1' (type TabNetEncoder):\n          • inputs=tf.Tensor(shape=(None, 3), dtype=float32)\n          • prior=None\n          • training=False\n    \n    \n    Call arguments received by layer 'tab_net_classifier_1' (type TabNetClassifier):\n      • inputs=tf.Tensor(shape=(None, 3), dtype=float32)\n      • training=False\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m y_train_fold, y_test_fold \u001b[38;5;241m=\u001b[39my_test\u001b[38;5;241m.\u001b[39miloc[train_index], y_test\u001b[38;5;241m.\u001b[39miloc[test_index]\n\u001b[0;32m     12\u001b[0m stacked_model\u001b[38;5;241m.\u001b[39mfit(stacked_input_fold, y_train_fold)    \n\u001b[1;32m---> 13\u001b[0m y_pred_fold \u001b[38;5;241m=\u001b[39m \u001b[43mstacked_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_fold\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m     14\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test_fold, y_pred_fold)\n\u001b[0;32m     15\u001b[0m fold_accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:681\u001b[0m, in \u001b[0;36mStackingClassifier.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;129m@available_if\u001b[39m(_estimator_has(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params):\n\u001b[0;32m    662\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \n\u001b[0;32m    664\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[38;5;124;03m        Predicted targets.\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    683\u001b[0m         \u001b[38;5;66;03m# Handle the multilabel-indicator case\u001b[39;00m\n\u001b[0;32m    684\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m    685\u001b[0m             [\n\u001b[0;32m    686\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_label_encoder[target_idx]\u001b[38;5;241m.\u001b[39minverse_transform(target)\n\u001b[0;32m    687\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m target_idx, target \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_pred\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m    688\u001b[0m             ]\n\u001b[0;32m    689\u001b[0m         )\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:369\u001b[0m, in \u001b[0;36m_BaseStacking.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict target for X.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m    Predicted targets.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpredict_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 22\u001b[0m, in \u001b[0;36mTabNetWrapper.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m---> 22\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (proba \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileu9dw7sea.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filebykjoj27.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mactivations \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtabnet_encoder, (ag__\u001b[38;5;241m.\u001b[39mld(inputs),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(training)), fscope)\n\u001b[0;32m     11\u001b[0m out \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mclf, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mactivations,), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filezzx_g2uv.py:28\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs, prior, training)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     27\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt((ag__\u001b[38;5;241m.\u001b[39mld(prior) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), if_body, else_body, get_state, set_state, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprior\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39minitial_bn, (ag__\u001b[38;5;241m.\u001b[39mld(inputs),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(training)), fscope)\n\u001b[0;32m     29\u001b[0m x_proc \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39minitial_feature_transformer, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(training)), fscope)\n\u001b[0;32m     30\u001b[0m (_, x_a) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39msplit_layer, (ag__\u001b[38;5;241m.\u001b[39mld(x_proc),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\__autograph_generated_filebykjoj27.py\", line 10, in tf__call\n        ag__.ld(self).activations = ag__.converted_call(ag__.ld(self).tabnet_encoder, (ag__.ld(inputs),), dict(training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\__autograph_generated_filezzx_g2uv.py\", line 28, in tf__call\n        x = ag__.converted_call(ag__.ld(self).initial_bn, (ag__.ld(inputs),), dict(training=ag__.ld(training)), fscope)\n\n    ValueError: Exception encountered when calling layer 'tab_net_classifier_1' (type TabNetClassifier).\n    \n    in user code:\n    \n        File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\tabnet_keras\\models.py\", line 97, in call  *\n            self.activations = self.tabnet_encoder(inputs, training=training)\n        File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\__autograph_generated_filezzx_g2uv.py\", line 28, in tf__call\n            x = ag__.converted_call(ag__.ld(self).initial_bn, (ag__.ld(inputs),), dict(training=ag__.ld(training)), fscope)\n    \n        ValueError: Exception encountered when calling layer 'tab_net_encoder_1' (type TabNetEncoder).\n        \n        in user code:\n        \n            File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\tabnet_keras\\encoder.py\", line 143, in call  *\n                x = self.initial_bn(inputs, training=training)\n            File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"c:\\Users\\Admin\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n                raise ValueError(\n        \n            ValueError: Input 0 of layer \"batch_normalization_5\" is incompatible with the layer: expected axis 1 of input shape to have value 34, but received input with shape (None, 3)\n        \n        \n        Call arguments received by layer 'tab_net_encoder_1' (type TabNetEncoder):\n          • inputs=tf.Tensor(shape=(None, 3), dtype=float32)\n          • prior=None\n          • training=False\n    \n    \n    Call arguments received by layer 'tab_net_classifier_1' (type TabNetClassifier):\n      • inputs=tf.Tensor(shape=(None, 3), dtype=float32)\n      • training=False\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Khởi tạo StratifiedKFold với 5 phần\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_accuracies = []\n",
    "\n",
    "for train_index, test_index in skf.split(stacked_input, y_test):\n",
    "    stacked_input_fold, X_test_fold =stacked_input[train_index],stacked_input[test_index]\n",
    "    y_train_fold, y_test_fold =y_test.iloc[train_index], y_test.iloc[test_index]\n",
    "    stacked_model.fit(stacked_input_fold, y_train_fold)    \n",
    "    y_pred_fold = stacked_model.predict(X_test_fold)    \n",
    "    accuracy = accuracy_score(y_test_fold, y_pred_fold)\n",
    "    fold_accuracies.append(accuracy)\n",
    "\n",
    "mean_accuracy = sum(fold_accuracies) / len(fold_accuracies)\n",
    "print(\"Accuracy on each fold:\", fold_accuracies)\n",
    "print(\"Mean accuracy across all folds:\", mean_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f05dd",
   "metadata": {
    "id": "939f05dd",
    "outputId": "d1daa1e7-bbda-4749-9836-617477c575dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# rf_pred = rf_model.predict_proba(x_test[feature_selection['RD']])\n",
    "# svm_pred = lgbm_model.predict_proba(x_test[feature_selection['LGBM']])\n",
    "# bg_pred = xgb_model.predict_proba(x_test[feature_selection['XGB']])\n",
    "# stacked_input = np.column_stack((rf_pred,svm_pred,bg_pred))\n",
    "stacked_pred = stacked_model.predict(stacked_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff75e76",
   "metadata": {
    "id": "dff75e76",
    "outputId": "ed0e4f8a-273a-42c8-eb75-85080e228b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 1ms/step\n",
      "Accuracy of Stacked Model: 0.5008842601689919\n"
     ]
    }
   ],
   "source": [
    "# stacked_model.fit(stacked_input, y_test)\n",
    "# Dự đoán và đánh giá mô hình stacked\n",
    "stacked_pred = stacked_model.predict(stacked_input)\n",
    "stacked_pred_labels = (stacked_pred > 0.3).astype(int)\n",
    "accuracy_stacked = accuracy_score(y_test, stacked_pred_labels)\n",
    "print(f'Accuracy of Stacked Model: {accuracy_stacked}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2cb867",
   "metadata": {
    "id": "0b2cb867"
   },
   "source": [
    "#### * Kết quả đánh giá mô hình:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07132b7e",
   "metadata": {
    "id": "07132b7e",
    "outputId": "8fb3e452-7905-484d-f5ef-04833da33634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5008842601689919\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.70      0.14       307\n",
      "           0       0.96      0.49      0.65      4782\n",
      "\n",
      "    accuracy                           0.50      5089\n",
      "   macro avg       0.52      0.59      0.40      5089\n",
      "weighted avg       0.91      0.50      0.62      5089\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, stacked_pred_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, stacked_pred_labels,labels=[1,0]))\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred,labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f218b86",
   "metadata": {
    "id": "6f218b86",
    "outputId": "495d4835-1288-416a-e66f-a491b28390ea"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dự đoán\n",
    "\n",
    "\n",
    "# Tính ma trận nhầm lẫn\n",
    "cm = confusion_matrix(y_test, stacked_pred_labels,labels=[1,0])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=[1,0], yticklabels=[1,0])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744c8a6",
   "metadata": {
    "id": "e744c8a6",
    "outputId": "13a87d53-c645-4b60-e4ad-1c59dba8ca90"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, stacked_pred)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "ax.plot(fpr, tpr, lw=4, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "ax.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate', fontsize=12, weight='bold')\n",
    "ax.set_ylabel('True Positive Rate', fontsize=12, weight='bold')\n",
    "ax.set_title(f'ROC of Voting',fontsize=20, weight='bold')\n",
    "ax.legend(loc=\"lower right\", prop={'size': 12, 'weight': 'bold'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe10617",
   "metadata": {
    "id": "ffe10617"
   },
   "outputs": [],
   "source": [
    "def check_result(prediction):\n",
    "    prediction = (prediction > 0.2).astype(int)\n",
    "    if isinstance(prediction, (np.ndarray, pd.Series)):\n",
    "        prediction = prediction.item()  # Hoặc sử dụng prediction[0] hoặc prediction.iloc[0]\n",
    "    if prediction==1:\n",
    "        return \"Y\"\n",
    "    else:\n",
    "        return \"N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3eefa4",
   "metadata": {
    "id": "8e3eefa4",
    "outputId": "1204a023-0e49-4835-c756-f6627fe4d438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x_test)):\n\u001b[0;32m      4\u001b[0m     y_predict \u001b[38;5;241m=\u001b[39m stacked_model\u001b[38;5;241m.\u001b[39mpredict(stacked_input)\n\u001b[1;32m----> 5\u001b[0m     stacked_pred_labels \u001b[38;5;241m=\u001b[39m \u001b[43my_predict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#print(y_predict[0][0])\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     Y_check \u001b[38;5;241m=\u001b[39m check_result(y_test\u001b[38;5;241m.\u001b[39miloc[indx])\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "solandung=0\n",
    "hopdonggianlan=0\n",
    "for indx in range(len(x_test)):\n",
    "    y_predict = stacked_model.predict(stacked_input)\n",
    "    stacked_pred_labels = y_predict.argmax(axis=1)\n",
    "\n",
    "    #print(y_predict[0][0])\n",
    "    Y_check = check_result(y_test.iloc[indx])\n",
    "    print('True:', Y_check)\n",
    "    print('Predicted:', check_result(stacked_pred_labels[indx]))\n",
    "    print(\"----------------------------\")\n",
    "    if Y_check==check_result(stacked_pred_labels[indx]):\n",
    "        solandung+=1\n",
    "        if Y_check=='Y':\n",
    "            hopdonggianlan+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a65590",
   "metadata": {
    "id": "a3a65590",
    "outputId": "4a195949-64b8-40aa-d25d-ce7db09267f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lần dự đoán đúng: 275 chiếm khoảng 83.33333333333334% tổng lần dự đoán\n",
      "Số hợp đồng gian lận trong lần kiểm tra: 75 chiếm khoảng 85.22727272727273% so với thực tế\n"
     ]
    }
   ],
   "source": [
    "print(f\"Số lần dự đoán đúng: {solandung} chiếm khoảng {(solandung/len(x_test))*100}% tổng lần dự đoán\")\n",
    "print(f\"Số hợp đồng gian lận trong lần kiểm tra: {hopdonggianlan} chiếm khoảng {(hopdonggianlan/len(y_test[y_test['fraud_reported']==1]))*100}% so với thực tế\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31643d6",
   "metadata": {
    "id": "c31643d6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e3467b",
   "metadata": {
    "id": "33e3467b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
