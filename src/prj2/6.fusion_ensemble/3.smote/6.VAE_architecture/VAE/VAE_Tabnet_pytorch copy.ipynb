{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([700, 42]) torch.Size([700]) torch.Size([300, 42]) torch.Size([300])\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame(np.random.rand(700, 42), columns=[f\"feature_{i}\" for i in range(42)])\n",
    "df_test = pd.DataFrame(np.random.rand(300, 42), columns=[f\"feature_{i}\" for i in range(42)])\n",
    "\n",
    "y_train = (np.random.rand(700) > 0.5).astype(np.float32)\n",
    "y_test = (np.random.rand(300) > 0.5).astype(np.float32)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(df_train.values)\n",
    "X_test = scaler.transform(df_test.values)\n",
    "\n",
    "# y_train = y_train.values.astype(np.float32)\n",
    "# y_test = y_test.values.astype(np.float32)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "        1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "        1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "        1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\pytorch_gpu\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 63.29478| val_0_unsup_loss_numpy: 11.113459587097168|  0:00:00s\n",
      "epoch 1  | loss: 42.20633| val_0_unsup_loss_numpy: 7.326720237731934|  0:00:00s\n",
      "epoch 2  | loss: 31.30164| val_0_unsup_loss_numpy: 7.264060020446777|  0:00:00s\n",
      "epoch 3  | loss: 23.71795| val_0_unsup_loss_numpy: 6.55974006652832|  0:00:00s\n",
      "epoch 4  | loss: 18.20707| val_0_unsup_loss_numpy: 4.412179946899414|  0:00:00s\n",
      "epoch 5  | loss: 14.25305| val_0_unsup_loss_numpy: 3.969019889831543|  0:00:00s\n",
      "epoch 6  | loss: 11.66744| val_0_unsup_loss_numpy: 3.8094499111175537|  0:00:00s\n",
      "epoch 7  | loss: 9.24326 | val_0_unsup_loss_numpy: 2.9063498973846436|  0:00:00s\n",
      "epoch 8  | loss: 7.45131 | val_0_unsup_loss_numpy: 2.6832098960876465|  0:00:00s\n",
      "epoch 9  | loss: 6.06207 | val_0_unsup_loss_numpy: 2.3764400482177734|  0:00:00s\n",
      "epoch 10 | loss: 4.91844 | val_0_unsup_loss_numpy: 2.1193299293518066|  0:00:00s\n",
      "epoch 11 | loss: 3.94771 | val_0_unsup_loss_numpy: 1.7430000305175781|  0:00:00s\n",
      "epoch 12 | loss: 3.25473 | val_0_unsup_loss_numpy: 1.5001499652862549|  0:00:00s\n",
      "epoch 13 | loss: 2.65848 | val_0_unsup_loss_numpy: 1.5896300077438354|  0:00:00s\n",
      "epoch 14 | loss: 2.25342 | val_0_unsup_loss_numpy: 1.3592400550842285|  0:00:00s\n",
      "epoch 15 | loss: 1.94595 | val_0_unsup_loss_numpy: 1.3377399444580078|  0:00:00s\n",
      "epoch 16 | loss: 1.70609 | val_0_unsup_loss_numpy: 1.1506600379943848|  0:00:00s\n",
      "epoch 17 | loss: 1.64312 | val_0_unsup_loss_numpy: 1.3154100179672241|  0:00:00s\n",
      "epoch 18 | loss: 1.50647 | val_0_unsup_loss_numpy: 1.1603200435638428|  0:00:01s\n",
      "epoch 19 | loss: 1.43712 | val_0_unsup_loss_numpy: 1.1561700105667114|  0:00:01s\n",
      "epoch 20 | loss: 1.35289 | val_0_unsup_loss_numpy: 1.1803300380706787|  0:00:01s\n",
      "epoch 21 | loss: 1.26701 | val_0_unsup_loss_numpy: 1.1358599662780762|  0:00:01s\n",
      "epoch 22 | loss: 1.22047 | val_0_unsup_loss_numpy: 1.1213799715042114|  0:00:01s\n",
      "epoch 23 | loss: 1.17908 | val_0_unsup_loss_numpy: 1.0866999626159668|  0:00:01s\n",
      "epoch 24 | loss: 1.1493  | val_0_unsup_loss_numpy: 1.1317600011825562|  0:00:01s\n",
      "epoch 25 | loss: 1.14488 | val_0_unsup_loss_numpy: 1.130020022392273|  0:00:01s\n",
      "epoch 26 | loss: 1.12792 | val_0_unsup_loss_numpy: 1.0836999416351318|  0:00:01s\n",
      "epoch 27 | loss: 1.1233  | val_0_unsup_loss_numpy: 1.0753099918365479|  0:00:01s\n",
      "epoch 28 | loss: 1.08747 | val_0_unsup_loss_numpy: 1.0424400568008423|  0:00:01s\n",
      "epoch 29 | loss: 1.07876 | val_0_unsup_loss_numpy: 1.0502699613571167|  0:00:01s\n",
      "epoch 30 | loss: 1.07134 | val_0_unsup_loss_numpy: 1.044800043106079|  0:00:01s\n",
      "epoch 31 | loss: 1.0588  | val_0_unsup_loss_numpy: 1.0778599977493286|  0:00:01s\n",
      "epoch 32 | loss: 1.05302 | val_0_unsup_loss_numpy: 1.0223300457000732|  0:00:01s\n",
      "epoch 33 | loss: 1.05128 | val_0_unsup_loss_numpy: 1.0270400047302246|  0:00:01s\n",
      "epoch 34 | loss: 1.05361 | val_0_unsup_loss_numpy: 1.026170015335083|  0:00:01s\n",
      "epoch 35 | loss: 1.04097 | val_0_unsup_loss_numpy: 1.037500023841858|  0:00:01s\n",
      "epoch 36 | loss: 1.04854 | val_0_unsup_loss_numpy: 1.031149983406067|  0:00:01s\n",
      "epoch 37 | loss: 1.04383 | val_0_unsup_loss_numpy: 1.0292600393295288|  0:00:01s\n",
      "epoch 38 | loss: 1.03353 | val_0_unsup_loss_numpy: 1.0211800336837769|  0:00:01s\n",
      "epoch 39 | loss: 1.02994 | val_0_unsup_loss_numpy: 1.0241600275039673|  0:00:01s\n",
      "epoch 40 | loss: 1.01944 | val_0_unsup_loss_numpy: 1.0154999494552612|  0:00:01s\n",
      "epoch 41 | loss: 1.02385 | val_0_unsup_loss_numpy: 1.0218100547790527|  0:00:01s\n",
      "epoch 42 | loss: 1.0255  | val_0_unsup_loss_numpy: 1.022379994392395|  0:00:02s\n",
      "epoch 43 | loss: 1.02503 | val_0_unsup_loss_numpy: 1.0225499868392944|  0:00:02s\n",
      "epoch 44 | loss: 1.01996 | val_0_unsup_loss_numpy: 1.0212199687957764|  0:00:02s\n",
      "epoch 45 | loss: 1.01822 | val_0_unsup_loss_numpy: 1.0211299657821655|  0:00:02s\n",
      "epoch 46 | loss: 1.01487 | val_0_unsup_loss_numpy: 1.0227400064468384|  0:00:02s\n",
      "epoch 47 | loss: 1.01113 | val_0_unsup_loss_numpy: 1.012910008430481|  0:00:02s\n",
      "epoch 48 | loss: 1.01829 | val_0_unsup_loss_numpy: 1.0169299840927124|  0:00:02s\n",
      "epoch 49 | loss: 1.01899 | val_0_unsup_loss_numpy: 1.0122699737548828|  0:00:02s\n",
      "epoch 50 | loss: 1.01053 | val_0_unsup_loss_numpy: 1.0106199979782104|  0:00:02s\n",
      "epoch 51 | loss: 1.01308 | val_0_unsup_loss_numpy: 1.0160900354385376|  0:00:02s\n",
      "epoch 52 | loss: 1.01742 | val_0_unsup_loss_numpy: 1.0157899856567383|  0:00:02s\n",
      "epoch 53 | loss: 1.01233 | val_0_unsup_loss_numpy: 1.0074900388717651|  0:00:02s\n",
      "epoch 54 | loss: 1.00877 | val_0_unsup_loss_numpy: 1.0145900249481201|  0:00:02s\n",
      "epoch 55 | loss: 1.01344 | val_0_unsup_loss_numpy: 1.0104899406433105|  0:00:02s\n",
      "epoch 56 | loss: 1.00978 | val_0_unsup_loss_numpy: 1.0064599514007568|  0:00:02s\n",
      "epoch 57 | loss: 1.01028 | val_0_unsup_loss_numpy: 1.0068999528884888|  0:00:02s\n",
      "epoch 58 | loss: 1.0074  | val_0_unsup_loss_numpy: 1.0076299905776978|  0:00:02s\n",
      "epoch 59 | loss: 1.00902 | val_0_unsup_loss_numpy: 1.0087300539016724|  0:00:02s\n",
      "epoch 60 | loss: 1.00794 | val_0_unsup_loss_numpy: 1.0072599649429321|  0:00:02s\n",
      "epoch 61 | loss: 1.00515 | val_0_unsup_loss_numpy: 1.005679965019226|  0:00:02s\n",
      "epoch 62 | loss: 1.00524 | val_0_unsup_loss_numpy: 1.0046299695968628|  0:00:02s\n",
      "epoch 63 | loss: 1.00911 | val_0_unsup_loss_numpy: 1.0078099966049194|  0:00:02s\n",
      "epoch 64 | loss: 1.00275 | val_0_unsup_loss_numpy: 1.007449984550476|  0:00:02s\n",
      "epoch 65 | loss: 1.00882 | val_0_unsup_loss_numpy: 1.0085699558258057|  0:00:02s\n",
      "epoch 66 | loss: 1.01171 | val_0_unsup_loss_numpy: 1.0100500583648682|  0:00:02s\n",
      "epoch 67 | loss: 1.00847 | val_0_unsup_loss_numpy: 1.0088399648666382|  0:00:03s\n",
      "epoch 68 | loss: 1.00925 | val_0_unsup_loss_numpy: 1.0078500509262085|  0:00:03s\n",
      "epoch 69 | loss: 1.00589 | val_0_unsup_loss_numpy: 1.0069299936294556|  0:00:03s\n",
      "epoch 70 | loss: 1.00627 | val_0_unsup_loss_numpy: 1.0060800313949585|  0:00:03s\n",
      "epoch 71 | loss: 1.00944 | val_0_unsup_loss_numpy: 1.0063899755477905|  0:00:03s\n",
      "epoch 72 | loss: 1.00613 | val_0_unsup_loss_numpy: 1.0066900253295898|  0:00:03s\n",
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 62 and best_val_0_unsup_loss_numpy = 1.0046299695968628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\pytorch_gpu\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "tabnet_params = {\n",
    "    \"n_d\": 16,\n",
    "    \"n_a\": 16,\n",
    "    \"n_steps\": 3,\n",
    "    \"n_shared\": 2,\n",
    "    \"n_independent\": 2,\n",
    "    \"gamma\": 1.3,\n",
    "    \"epsilon\": 1e-15,\n",
    "    \"momentum\": 0.98,\n",
    "    \"mask_type\": \"sparsemax\",\n",
    "    \"lambda_sparse\": 1e-3\n",
    "}\n",
    "\n",
    "\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    **tabnet_params\n",
    ")\n",
    " \n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train,\n",
    "    eval_set=[X_test],  \n",
    "    pretraining_ratio=0.8,\n",
    "    max_epochs=101,\n",
    "    patience=10,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "TabNetPretraining                                            [700, 42]                 --\n",
       "├─EmbeddingGenerator: 1-1                                    [700, 42]                 --\n",
       "├─TabNetEncoder: 1-2                                         [700, 16]                 --\n",
       "│    └─BatchNorm1d: 2-1                                      [700, 42]                 84\n",
       "│    └─FeatTransformer: 2-2                                  [700, 32]                 4,352\n",
       "│    │    └─GLU_Block: 3-1                                   [700, 32]                 4,992\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-6                                   [700, 32]                 4,352\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-7                        [700, 42]                 756\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-8                             [700, 32]                 9,344\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-13                       [700, 42]                 756\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-14                            [700, 32]                 9,344\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-19                       [700, 42]                 756\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-20                            [700, 32]                 9,344\n",
       "├─TabNetDecoder: 1-3                                         [700, 42]                 --\n",
       "│    └─ModuleList: 2-13                                      --                        --\n",
       "│    │    └─FeatTransformer: 3-21                            [700, 16]                 1,152\n",
       "│    │    └─FeatTransformer: 3-25                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-23                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-24                            [700, 16]                 1,152\n",
       "│    │    └─FeatTransformer: 3-25                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-26                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-27                            [700, 16]                 1,152\n",
       "│    └─Linear: 2-14                                          [700, 42]                 672\n",
       "==============================================================================================================\n",
       "Total params: 70,736\n",
       "Trainable params: 70,736\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 30.70\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.12\n",
       "Forward/backward pass size (MB): 15.50\n",
       "Params size (MB): 0.11\n",
       "Estimated Total Size (MB): 15.73\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truy cập vào mô hình TabNet bên trong\n",
    "from torchinfo import summary\n",
    "\n",
    "tabnet_model = unsupervised_model.network\n",
    "\n",
    "summary(tabnet_model, input_size=X_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoder Summary:\n",
      "TabNetEncoder(\n",
      "  (initial_bn): BatchNorm1d(42, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "  (initial_splitter): FeatTransformer(\n",
      "    (shared): GLU_Block(\n",
      "      (shared_layers): ModuleList(\n",
      "        (0): Linear(in_features=42, out_features=64, bias=False)\n",
      "        (1): Linear(in_features=32, out_features=64, bias=False)\n",
      "      )\n",
      "      (glu_layers): ModuleList(\n",
      "        (0): GLU_Layer(\n",
      "          (fc): Linear(in_features=42, out_features=64, bias=False)\n",
      "          (bn): GBN(\n",
      "            (bn): BatchNorm1d(64, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): GLU_Layer(\n",
      "          (fc): Linear(in_features=32, out_features=64, bias=False)\n",
      "          (bn): GBN(\n",
      "            (bn): BatchNorm1d(64, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (specifics): GLU_Block(\n",
      "      (glu_layers): ModuleList(\n",
      "        (0-1): 2 x GLU_Layer(\n",
      "          (fc): Linear(in_features=32, out_features=64, bias=False)\n",
      "          (bn): GBN(\n",
      "            (bn): BatchNorm1d(64, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feat_transformers): ModuleList(\n",
      "    (0-2): 3 x FeatTransformer(\n",
      "      (shared): GLU_Block(\n",
      "        (shared_layers): ModuleList(\n",
      "          (0): Linear(in_features=42, out_features=64, bias=False)\n",
      "          (1): Linear(in_features=32, out_features=64, bias=False)\n",
      "        )\n",
      "        (glu_layers): ModuleList(\n",
      "          (0): GLU_Layer(\n",
      "            (fc): Linear(in_features=42, out_features=64, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): GLU_Layer(\n",
      "            (fc): Linear(in_features=32, out_features=64, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (specifics): GLU_Block(\n",
      "        (glu_layers): ModuleList(\n",
      "          (0-1): 2 x GLU_Layer(\n",
      "            (fc): Linear(in_features=32, out_features=64, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (att_transformers): ModuleList(\n",
      "    (0-2): 3 x AttentiveTransformer(\n",
      "      (fc): Linear(in_features=16, out_features=42, bias=False)\n",
      "      (bn): GBN(\n",
      "        (bn): BatchNorm1d(42, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (selector): Sparsemax()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = tabnet_model.encoder\n",
    "\n",
    "print(\"\\nEncoder Summary:\")\n",
    "print(encoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoder Summary:\n",
      "TabNetDecoder(\n",
      "  (feat_transformers): ModuleList(\n",
      "    (0-2): 3 x FeatTransformer(\n",
      "      (shared): GLU_Block(\n",
      "        (shared_layers): ModuleList(\n",
      "          (0): Linear(in_features=16, out_features=32, bias=False)\n",
      "        )\n",
      "        (glu_layers): ModuleList(\n",
      "          (0): GLU_Layer(\n",
      "            (fc): Linear(in_features=16, out_features=32, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (specifics): GLU_Block(\n",
      "        (glu_layers): ModuleList(\n",
      "          (0): GLU_Layer(\n",
      "            (fc): Linear(in_features=16, out_features=32, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (reconstruction_layer): Linear(in_features=16, out_features=42, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "decoder = tabnet_model.decoder\n",
    "\n",
    "print(\"\\nDecoder Summary:\")\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã xảy ra lỗi: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA__native_batch_norm)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_9348\\992752778.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample_input = torch.tensor(X_train[:5])\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.tensor(X_train[:5])  \n",
    "\n",
    "try:\n",
    "    result = tabnet_model.encoder(sample_input)\n",
    "    if isinstance(result, tuple):\n",
    "        print(f'TabNet encoder trả về {len(result)} giá trị.')\n",
    "        for i, res in enumerate(result):\n",
    "            print(f'Giá trị {i + 1} shape: {res.shape}')\n",
    "    else:\n",
    "        print('TabNet encoder chỉ trả về một giá trị.')\n",
    "        print(f'Giá trị shape: {result.shape}')\n",
    "except Exception as e:\n",
    "    print(f'Đã xảy ra lỗi: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(nn.Module):\n",
    "    def __init__(self, seed=1337):\n",
    "        super(Sampling, self).__init__()\n",
    "        self.seed = seed\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = z_mean.size(0)\n",
    "        dim = z_mean.size(1)\n",
    "        # print(batch, dim)\n",
    "        epsilon = torch.randn(batch, dim, generator=torch.Generator().manual_seed(self.seed))\n",
    "        return z_mean + torch.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE_Encoder, self).__init__()\n",
    "        self.tabnet_encoder = tabnet_model.encoder\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(16, 128),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, latent_dim)\n",
    "        )\n",
    "        self.fc_mean = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_log_var = nn.Linear(latent_dim, latent_dim)\n",
    "        self.sampling = Sampling()\n",
    "\n",
    "    def forward(self, x):\n",
    "        steps_output, _ = self.tabnet_encoder(x)\n",
    "        encoded = steps_output[-1]\n",
    "        print(\"Shape of encoded tensor:\", encoded.shape)\n",
    "        encoded = self.mlp(encoded)\n",
    "        z_mean = self.fc_mean(encoded)\n",
    "        z_log_var = self.fc_log_var(encoded)\n",
    "        print(f'Shape of z: {z_log_var.shape} -{z_log_var.shape}')\n",
    "        try:\n",
    "            z = self.sampling((z_mean, z_log_var))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        print(f'Shape of z: {z.shape} - {z_log_var.shape} -{z_log_var.shape}')\n",
    "        return z_mean, z_log_var, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim,encoded_dim, output_dim):\n",
    "        super(VAE_Decoder, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),   \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, encoded_dim),  \n",
    "        )\n",
    "        self.tabnet_decoder = tabnet_model.decoder\n",
    "        self.reshape = nn.Unflatten(1, (encoded_dim,))\n",
    "        self.output_dim=output_dim\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = F.relu(self.mlp(z))\n",
    "\n",
    "        # print(\"Shape before reshape:\", x.shape)\n",
    "        # x = self.reshape(x)\n",
    "        x = x[None, ...]\n",
    "\n",
    "        # print(\"Shape after reshape:\", x.shape)\n",
    "        # x = x.view(x.size(0), output_dim)\n",
    "        \n",
    "        output = self.tabnet_decoder(x)\n",
    "        # print(output.shape)\n",
    "        # print(\"Shape of output from tabnet_decoder:\", output.shape)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output.view(-1, self.output_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_range(tensor, name):\n",
    "    if not torch.all((tensor >= 0) & (tensor <= 1)):\n",
    "        print(f\"{name} contains values outside the range [0, 1]\")\n",
    "        print(f\"{name} min: {tensor.min()}, max: {tensor.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_mean, z_log_var, z = self.encoder(x)\n",
    "        # print(\"Shape after encoder:\", z.shape)\n",
    "\n",
    "        reconstruction = self.decoder(z)\n",
    "        # print(\"Shape after decoder:\", reconstruction.shape)\n",
    "\n",
    "        return reconstruction, z_mean, z_log_var\n",
    "\n",
    "    def train_step(self, data, optimizer):\n",
    "        optimizer.zero_grad()\n",
    "        # z_mean, z_log_var, z = self.encoder(data)\n",
    "        # reconstruction = self.decoder(z)\n",
    "        reconstruction, z_mean, z_log_var = self.forward(data)\n",
    "        # print(check_data_range(data, 'data'))\n",
    "        # print(check_data_range(reconstruction, 'reconstruction'))\n",
    "        # reconstruction_loss = torch.mean(\n",
    "        #     torch.sum(\n",
    "        #         F.binary_cross_entropy(reconstruction, data, reduction='none'),\n",
    "        #         dim=1\n",
    "        #     )\n",
    "        # )\n",
    "        reconstruction_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                F.binary_cross_entropy_with_logits(reconstruction, data, reduction='none'),\n",
    "                dim=1\n",
    "                # dim=(1, 2)\n",
    "                )  # Tính tổng trên chiều (1, 2)\n",
    "        )\n",
    "        # print(f'Shape reconstruction_loss: {reconstruction_loss.shape}')\n",
    "\n",
    "        kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=1)\n",
    "\n",
    "        # print(f'Shape z_mean: {z_mean.shape}')\n",
    "        # print(f'Shape z_log_var: {z_log_var.shape}')\n",
    "        kl_loss = torch.mean(torch.sum(kl_loss))\n",
    "        # kl_loss = torch.mean(torch.sum(kl_loss, dim=1))\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        # print(f'Shape k1 loss: {kl_loss.shape}')\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        return total_loss.item(), reconstruction_loss.item(), kl_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "encoded_dim = 16\n",
    "output_dim = X_train.shape[1]\n",
    "input_dim = X_train.shape[1]\n",
    "print(input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Summary:\n",
      "Shape of encoded tensor: torch.Size([700, 16])\n",
      "Shape of z: torch.Size([700, 64]) -torch.Size([700, 64])\n",
      "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [TabNetEncoder: 1, BatchNorm1d: 2, FeatTransformer: 2, GLU_Block: 3, GLU_Layer: 5, Linear: 7, GBN: 6, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, GLU_Layer: 5, Linear: 7, GBN: 6, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, GLU_Block: 3, GLU_Layer: 5, Linear: 6, GBN: 6, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, GLU_Layer: 5, Linear: 6, GBN: 6, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, AttentiveTransformer: 3, Linear: 4, GBN: 4, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, Sparsemax: 4, FeatTransformer: 3, GLU_Block: 4, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Block: 4, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, AttentiveTransformer: 3, Linear: 4, GBN: 4, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, Sparsemax: 4, FeatTransformer: 3, GLU_Block: 4, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Block: 4, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, AttentiveTransformer: 3, Linear: 4, GBN: 4, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, Sparsemax: 4, FeatTransformer: 3, GLU_Block: 4, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Block: 4, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, Sequential: 1, Linear: 2, ReLU: 2, Linear: 2, ReLU: 2, Linear: 2, ReLU: 2, Linear: 2, Linear: 1, Linear: 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torchinfo\\torchinfo.py:295\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 295\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1603\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1601\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1603\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "Cell \u001b[1;32mIn[29], line 30\u001b[0m, in \u001b[0;36mVAE_Encoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShape of z: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz_log_var\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz_log_var\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z_mean, z_log_var, z\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'z' referenced before assignment",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m vae_encoder \u001b[38;5;241m=\u001b[39m VAE_Encoder(latent_dim\u001b[38;5;241m=\u001b[39mlatent_dim)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoder Summary:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvae_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m700\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torchinfo\\torchinfo.py:223\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m validate_user_params(\n\u001b[0;32m    217\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[0;32m    218\u001b[0m )\n\u001b[0;32m    220\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[0;32m    221\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[0;32m    222\u001b[0m )\n\u001b[1;32m--> 223\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[0;32m    227\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[0;32m    228\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[0;32m    229\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\miniconda3\\envs\\pytorch_gpu\\lib\\site-packages\\torchinfo\\torchinfo.py:304\u001b[0m, in \u001b[0;36mforward_pass\u001b[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    303\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [TabNetEncoder: 1, BatchNorm1d: 2, FeatTransformer: 2, GLU_Block: 3, GLU_Layer: 5, Linear: 7, GBN: 6, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, GLU_Layer: 5, Linear: 7, GBN: 6, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, GLU_Block: 3, GLU_Layer: 5, Linear: 6, GBN: 6, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, GLU_Layer: 5, Linear: 6, GBN: 6, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, BatchNorm1d: 7, AttentiveTransformer: 3, Linear: 4, GBN: 4, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, Sparsemax: 4, FeatTransformer: 3, GLU_Block: 4, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Block: 4, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, AttentiveTransformer: 3, Linear: 4, GBN: 4, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, Sparsemax: 4, FeatTransformer: 3, GLU_Block: 4, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Block: 4, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, AttentiveTransformer: 3, Linear: 4, GBN: 4, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, BatchNorm1d: 5, Sparsemax: 4, FeatTransformer: 3, GLU_Block: 4, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Block: 4, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, GLU_Layer: 6, Linear: 7, GBN: 7, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, BatchNorm1d: 8, Sequential: 1, Linear: 2, ReLU: 2, Linear: 2, ReLU: 2, Linear: 2, ReLU: 2, Linear: 2, Linear: 1, Linear: 1]"
     ]
    }
   ],
   "source": [
    "vae_encoder = VAE_Encoder(latent_dim=latent_dim)\n",
    "print(\"Encoder Summary:\")\n",
    "summary(vae_encoder, input_size=(700, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shape: torch.Size([800, 16])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(800, 42) \n",
    "steps_output, _ = tabnet_model.encoder(x)\n",
    "encoded = steps_output[-1]\n",
    "print(f\"Encoded shape: {encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoder output: [torch.Size([800, 16]), torch.Size([800, 16]), torch.Size([800, 16])]\n",
      "Decoder shape: torch.Size([800, 42])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Giả sử `tabnet_model` đã được định nghĩa và `encoder` đã được huấn luyện.\n",
    "# Thay đổi kích thước đầu vào phù hợp với yêu cầu của decoder.\n",
    "x = torch.randn(800, 42)  # Đầu vào có kích thước (batch_size, features)\n",
    "\n",
    "# Pass đầu vào qua encoder để lấy đầu ra.\n",
    "steps_output, _ = tabnet_model.encoder(x)\n",
    "print(\"Shape of encoder output:\", [output.shape for output in steps_output])\n",
    "\n",
    "# Giả sử `steps_output[-1]` có kích thước (batch_size, steps, features).\n",
    "decoder_input = steps_output[-1]  # Chọn đầu ra từ encoder.\n",
    "decoder_input = decoder_input[None, ...]\n",
    "# Pass đầu vào qua decoder.\n",
    "try:\n",
    "    decoder_output = tabnet_model.decoder(decoder_input)\n",
    "    print(f\"Decoder shape: {decoder_output.shape}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(800, 16) \n",
    "# print(x.shape)\n",
    "# steps_output, _ = tabnet_model.decoder(x)\n",
    "# decoder = steps_output[-1]\n",
    "# print(f\"Decoder shape: {decoder.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "VAE_Decoder                                                  [700, 42]                 --\n",
       "├─Sequential: 1-1                                            [700, 16]                 --\n",
       "│    └─Linear: 2-1                                           [700, 32]                 2,080\n",
       "│    └─ReLU: 2-2                                             [700, 32]                 --\n",
       "│    └─Linear: 2-3                                           [700, 96]                 3,168\n",
       "│    └─ReLU: 2-4                                             [700, 96]                 --\n",
       "│    └─Linear: 2-5                                           [700, 96]                 9,312\n",
       "│    └─ReLU: 2-6                                             [700, 96]                 --\n",
       "│    └─Linear: 2-7                                           [700, 16]                 1,552\n",
       "├─TabNetDecoder: 1-2                                         [700, 42]                 --\n",
       "│    └─ModuleList: 2-8                                       --                        --\n",
       "│    │    └─FeatTransformer: 3-1                             [700, 16]                 1,152\n",
       "│    │    └─FeatTransformer: 3-2                             --                        1,152\n",
       "│    │    └─FeatTransformer: 3-3                             --                        (recursive)\n",
       "│    └─Linear: 2-9                                           [700, 42]                 672\n",
       "==============================================================================================================\n",
       "Total params: 19,728\n",
       "Trainable params: 19,728\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 12.56\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.18\n",
       "Forward/backward pass size (MB): 2.30\n",
       "Params size (MB): 0.07\n",
       "Estimated Total Size (MB): 2.55\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_decoder = VAE_Decoder(latent_dim=latent_dim, encoded_dim=encoded_dim, output_dim=output_dim)\n",
    "print(\"Decoder Summary:\")\n",
    "summary(vae_decoder, input_size=(700, latent_dim), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                                            Output Shape              Param #\n",
       "===================================================================================================================\n",
       "VAE                                                               [700, 42]                 --\n",
       "├─VAE_Encoder: 1-1                                                [700, 64]                 --\n",
       "│    └─TabNetEncoder: 2-1                                         [700, 16]                 --\n",
       "│    │    └─BatchNorm1d: 3-1                                      [700, 42]                 84\n",
       "│    │    └─FeatTransformer: 3-2                                  [700, 32]                 9,344\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-6                                  --                        (recursive)\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-6                                  --                        (recursive)\n",
       "│    │    └─ModuleList: 3-11                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-11                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-11                                      --                        (recursive)\n",
       "│    │    └─ModuleList: 3-12                                      --                        (recursive)\n",
       "│    └─Sequential: 2-2                                            [700, 64]                 --\n",
       "│    │    └─Linear: 3-13                                          [700, 128]                2,176\n",
       "│    │    └─ReLU: 3-14                                            [700, 128]                --\n",
       "│    │    └─Linear: 3-15                                          [700, 128]                16,512\n",
       "│    │    └─ReLU: 3-16                                            [700, 128]                --\n",
       "│    │    └─Linear: 3-17                                          [700, 96]                 12,384\n",
       "│    │    └─ReLU: 3-18                                            [700, 96]                 --\n",
       "│    │    └─Linear: 3-19                                          [700, 64]                 6,208\n",
       "│    └─Linear: 2-3                                                [700, 64]                 4,160\n",
       "│    └─Linear: 2-4                                                [700, 64]                 4,160\n",
       "│    └─Sampling: 2-5                                              [700, 64]                 --\n",
       "├─VAE_Decoder: 1-2                                                [700, 42]                 --\n",
       "│    └─Sequential: 2-6                                            [700, 16]                 --\n",
       "│    │    └─Linear: 3-20                                          [700, 32]                 2,080\n",
       "│    │    └─ReLU: 3-21                                            [700, 32]                 --\n",
       "│    │    └─Linear: 3-22                                          [700, 96]                 3,168\n",
       "│    │    └─ReLU: 3-23                                            [700, 96]                 --\n",
       "│    │    └─Linear: 3-24                                          [700, 96]                 9,312\n",
       "│    │    └─ReLU: 3-25                                            [700, 96]                 --\n",
       "│    │    └─Linear: 3-26                                          [700, 16]                 1,552\n",
       "│    └─TabNetDecoder: 2-7                                         [700, 42]                 --\n",
       "│    │    └─ModuleList: 3-27                                      --                        2,432\n",
       "│    │    └─Linear: 3-28                                          [700, 42]                 672\n",
       "===================================================================================================================\n",
       "Total params: 130,144\n",
       "Trainable params: 130,144\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 72.28\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.12\n",
       "Forward/backward pass size (MB): 18.46\n",
       "Params size (MB): 0.36\n",
       "Estimated Total Size (MB): 18.93\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae = VAE(encoder=vae_encoder, decoder=vae_decoder)\n",
    "summary(vae, input_size=(700, input_dim), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 39.1144\n",
      "Epoch 2/10, Loss: 36.3957\n",
      "Epoch 3/10, Loss: 34.5533\n",
      "Epoch 4/10, Loss: 33.0103\n",
      "Epoch 5/10, Loss: 31.7651\n",
      "Epoch 6/10, Loss: 30.9912\n",
      "Epoch 7/10, Loss: 30.6230\n",
      "Epoch 8/10, Loss: 30.4859\n",
      "Epoch 9/10, Loss: 30.4281\n",
      "Epoch 10/10, Loss: 30.3930\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.0001\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_data, _ in train_loader:\n",
    "        # print(batch_data)\n",
    "        loss, rec_loss, kl_loss = vae.train_step(batch_data, optimizer)\n",
    "        train_loss += loss\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
