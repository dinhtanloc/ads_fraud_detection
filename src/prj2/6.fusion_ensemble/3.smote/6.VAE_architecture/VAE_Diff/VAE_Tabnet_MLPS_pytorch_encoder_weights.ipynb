{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  \n",
    "print(torch.cuda.current_device())  \n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Data\\ads_fraud_detection\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "__script_path=os.path.abspath(globals().get('__file__','.'))\n",
    "__script_dir = os.path.dirname(__script_path)\n",
    "root_dir = os.path.abspath(f'{__script_dir}/../../../../..')\n",
    "print(root_dir)\n",
    "for lib in [root_dir][::-1]:\n",
    "    if lib in sys.path:\n",
    "        sys.path.remove(lib)\n",
    "    sys.path.insert(0,lib)\n",
    "from config.config import *\n",
    "# from libs.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=f\"{exps_dir}/exp2/exp_smote\"\n",
    "if os.path.exists(save_dir) == False: \n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6378163041991519, 1: 2.3140088827134457}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "class_weights_dict=dict(np.load(f'{save_dir}/class_weights_dict.npz',allow_pickle=True))['class_weights_dict']\n",
    "class_weights_dict = {key: value for key, value in class_weights_dict.item().items()}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19430, 33]) torch.Size([19430, 1, 2]) torch.Size([5089, 33]) torch.Size([5089, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
    "num_classes = 2  # Assuming binary classification\n",
    "y_train = F.one_hot(y_train, num_classes=num_classes)\n",
    "y_test = F.one_hot(y_test, num_classes=num_classes)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1941.51756| val_0_unsup_loss_numpy: 21.037090301513672|  0:00:01s\n",
      "epoch 1  | loss: 22.06558| val_0_unsup_loss_numpy: 4.085599899291992|  0:00:03s\n",
      "epoch 2  | loss: 8.62228 | val_0_unsup_loss_numpy: 6.7566399574279785|  0:00:05s\n",
      "epoch 3  | loss: 8.90729 | val_0_unsup_loss_numpy: 2.1685800552368164|  0:00:07s\n",
      "epoch 4  | loss: 4.31033 | val_0_unsup_loss_numpy: 88.85392761230469|  0:00:09s\n",
      "epoch 5  | loss: 6.68755 | val_0_unsup_loss_numpy: 1.4134299755096436|  0:00:11s\n",
      "epoch 6  | loss: 4.51434 | val_0_unsup_loss_numpy: 1.9488600492477417|  0:00:13s\n",
      "epoch 7  | loss: 5.04796 | val_0_unsup_loss_numpy: 1.7437700033187866|  0:00:14s\n",
      "epoch 8  | loss: 2.8203  | val_0_unsup_loss_numpy: 6.641610145568848|  0:00:16s\n",
      "epoch 9  | loss: 2.32682 | val_0_unsup_loss_numpy: 1.6450400352478027|  0:00:18s\n",
      "epoch 10 | loss: 2.08004 | val_0_unsup_loss_numpy: 2.615489959716797|  0:00:20s\n",
      "epoch 11 | loss: 2.23871 | val_0_unsup_loss_numpy: 1.3475799560546875|  0:00:22s\n",
      "epoch 12 | loss: 1.88427 | val_0_unsup_loss_numpy: 1.262120008468628|  0:00:24s\n",
      "epoch 13 | loss: 1.56024 | val_0_unsup_loss_numpy: 1.3143600225448608|  0:00:26s\n",
      "epoch 14 | loss: 1.36775 | val_0_unsup_loss_numpy: 1.360550045967102|  0:00:28s\n",
      "epoch 15 | loss: 1.37813 | val_0_unsup_loss_numpy: 1.2533899545669556|  0:00:30s\n",
      "epoch 16 | loss: 1.25151 | val_0_unsup_loss_numpy: 1.191249966621399|  0:00:31s\n",
      "epoch 17 | loss: 1.22788 | val_0_unsup_loss_numpy: 1.1953999996185303|  0:00:33s\n",
      "epoch 18 | loss: 1.2381  | val_0_unsup_loss_numpy: 1.2280900478363037|  0:00:35s\n",
      "epoch 19 | loss: 1.13947 | val_0_unsup_loss_numpy: 1.0085899829864502|  0:00:37s\n",
      "epoch 20 | loss: 1.0784  | val_0_unsup_loss_numpy: 1.0561800003051758|  0:00:39s\n",
      "epoch 21 | loss: 1.04977 | val_0_unsup_loss_numpy: 1.0153599977493286|  0:00:41s\n",
      "epoch 22 | loss: 1.14197 | val_0_unsup_loss_numpy: 1.0738099813461304|  0:00:43s\n",
      "epoch 23 | loss: 1.08661 | val_0_unsup_loss_numpy: 1.0555000305175781|  0:00:44s\n",
      "epoch 24 | loss: 1.18632 | val_0_unsup_loss_numpy: 1.277359962463379|  0:00:46s\n",
      "epoch 25 | loss: 1.09346 | val_0_unsup_loss_numpy: 1.1215900182724|  0:00:48s\n",
      "epoch 26 | loss: 1.09819 | val_0_unsup_loss_numpy: 1.1039700508117676|  0:00:50s\n",
      "epoch 27 | loss: 1.12579 | val_0_unsup_loss_numpy: 1.1165399551391602|  0:00:51s\n",
      "epoch 28 | loss: 1.09386 | val_0_unsup_loss_numpy: 1.0944099426269531|  0:00:53s\n",
      "epoch 29 | loss: 1.04237 | val_0_unsup_loss_numpy: 0.9616699814796448|  0:00:54s\n",
      "epoch 30 | loss: 1.0422  | val_0_unsup_loss_numpy: 1.2115700244903564|  0:00:56s\n",
      "epoch 31 | loss: 1.03273 | val_0_unsup_loss_numpy: 0.9550399780273438|  0:00:58s\n",
      "epoch 32 | loss: 1.03919 | val_0_unsup_loss_numpy: 1.02128005027771|  0:00:59s\n",
      "epoch 33 | loss: 1.05916 | val_0_unsup_loss_numpy: 0.9645599722862244|  0:01:01s\n",
      "epoch 34 | loss: 1.14837 | val_0_unsup_loss_numpy: 1.2175099849700928|  0:01:02s\n",
      "epoch 35 | loss: 1.13161 | val_0_unsup_loss_numpy: 1.0161700248718262|  0:01:04s\n",
      "epoch 36 | loss: 1.04864 | val_0_unsup_loss_numpy: 0.9416400194168091|  0:01:07s\n",
      "epoch 37 | loss: 1.03796 | val_0_unsup_loss_numpy: 0.9466099739074707|  0:01:09s\n",
      "epoch 38 | loss: 1.04712 | val_0_unsup_loss_numpy: 1.1171000003814697|  0:01:12s\n",
      "epoch 39 | loss: 1.03224 | val_0_unsup_loss_numpy: 1.0069600343704224|  0:01:15s\n",
      "epoch 40 | loss: 1.01635 | val_0_unsup_loss_numpy: 0.9125400185585022|  0:01:17s\n",
      "epoch 41 | loss: 0.96449 | val_0_unsup_loss_numpy: 0.9045199751853943|  0:01:20s\n",
      "epoch 42 | loss: 0.96617 | val_0_unsup_loss_numpy: 0.90038001537323|  0:01:23s\n",
      "epoch 43 | loss: 0.98035 | val_0_unsup_loss_numpy: 0.8801800012588501|  0:01:26s\n",
      "epoch 44 | loss: 0.98193 | val_0_unsup_loss_numpy: 0.895039975643158|  0:01:28s\n",
      "epoch 45 | loss: 0.96042 | val_0_unsup_loss_numpy: 0.8669599890708923|  0:01:31s\n",
      "epoch 46 | loss: 0.95853 | val_0_unsup_loss_numpy: 0.8800399899482727|  0:01:34s\n",
      "epoch 47 | loss: 0.95059 | val_0_unsup_loss_numpy: 0.8652499914169312|  0:01:36s\n",
      "epoch 48 | loss: 0.97695 | val_0_unsup_loss_numpy: 0.8845800161361694|  0:01:39s\n",
      "epoch 49 | loss: 0.99737 | val_0_unsup_loss_numpy: 0.8735799789428711|  0:01:42s\n",
      "epoch 50 | loss: 0.94668 | val_0_unsup_loss_numpy: 0.8738600015640259|  0:01:45s\n",
      "epoch 51 | loss: 0.96331 | val_0_unsup_loss_numpy: 0.8837500214576721|  0:01:47s\n",
      "epoch 52 | loss: 0.98914 | val_0_unsup_loss_numpy: 0.8901900053024292|  0:01:50s\n",
      "epoch 53 | loss: 0.96705 | val_0_unsup_loss_numpy: 0.8846499919891357|  0:01:53s\n",
      "epoch 54 | loss: 0.95374 | val_0_unsup_loss_numpy: 0.900950014591217|  0:01:56s\n",
      "epoch 55 | loss: 0.95413 | val_0_unsup_loss_numpy: 0.8563699722290039|  0:01:58s\n",
      "epoch 56 | loss: 0.93821 | val_0_unsup_loss_numpy: 0.82819002866745|  0:02:01s\n",
      "epoch 57 | loss: 0.93614 | val_0_unsup_loss_numpy: 0.8290600180625916|  0:02:04s\n",
      "epoch 58 | loss: 0.94227 | val_0_unsup_loss_numpy: 0.8391900062561035|  0:02:07s\n",
      "epoch 59 | loss: 0.98242 | val_0_unsup_loss_numpy: 0.8648899793624878|  0:02:10s\n",
      "epoch 60 | loss: 0.94819 | val_0_unsup_loss_numpy: 0.8229299783706665|  0:02:12s\n",
      "epoch 61 | loss: 0.94446 | val_0_unsup_loss_numpy: 0.8197299838066101|  0:02:16s\n",
      "epoch 62 | loss: 0.97418 | val_0_unsup_loss_numpy: 0.9168499708175659|  0:02:19s\n",
      "epoch 63 | loss: 1.02273 | val_0_unsup_loss_numpy: 0.822160005569458|  0:02:22s\n",
      "epoch 64 | loss: 0.96167 | val_0_unsup_loss_numpy: 0.8324000239372253|  0:02:25s\n",
      "epoch 65 | loss: 0.94561 | val_0_unsup_loss_numpy: 0.8230999708175659|  0:02:27s\n",
      "epoch 66 | loss: 0.93456 | val_0_unsup_loss_numpy: 0.8163700103759766|  0:02:30s\n",
      "epoch 67 | loss: 0.9439  | val_0_unsup_loss_numpy: 0.8678100109100342|  0:02:33s\n",
      "epoch 68 | loss: 0.93858 | val_0_unsup_loss_numpy: 0.8542199730873108|  0:02:35s\n",
      "epoch 69 | loss: 0.93572 | val_0_unsup_loss_numpy: 0.8215600252151489|  0:02:38s\n",
      "epoch 70 | loss: 0.92469 | val_0_unsup_loss_numpy: 0.8466200232505798|  0:02:41s\n",
      "epoch 71 | loss: 0.94253 | val_0_unsup_loss_numpy: 0.825659990310669|  0:02:43s\n",
      "epoch 72 | loss: 0.93626 | val_0_unsup_loss_numpy: 0.7912899851799011|  0:02:46s\n",
      "epoch 73 | loss: 0.91903 | val_0_unsup_loss_numpy: 0.8102099895477295|  0:02:49s\n",
      "epoch 74 | loss: 0.92683 | val_0_unsup_loss_numpy: 0.8240500092506409|  0:02:52s\n",
      "epoch 75 | loss: 0.92591 | val_0_unsup_loss_numpy: 0.8643199801445007|  0:02:54s\n",
      "epoch 76 | loss: 0.95138 | val_0_unsup_loss_numpy: 0.8731499910354614|  0:02:57s\n",
      "epoch 77 | loss: 0.94109 | val_0_unsup_loss_numpy: 0.8157299757003784|  0:03:00s\n",
      "epoch 78 | loss: 0.92133 | val_0_unsup_loss_numpy: 0.8320900201797485|  0:03:02s\n",
      "epoch 79 | loss: 0.94743 | val_0_unsup_loss_numpy: 0.8314899802207947|  0:03:05s\n",
      "epoch 80 | loss: 0.93404 | val_0_unsup_loss_numpy: 0.8224700093269348|  0:03:08s\n",
      "epoch 81 | loss: 0.92291 | val_0_unsup_loss_numpy: 0.8184700012207031|  0:03:11s\n",
      "epoch 82 | loss: 0.92311 | val_0_unsup_loss_numpy: 0.8024200201034546|  0:03:13s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_unsup_loss_numpy = 0.7912899851799011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "tabnet_params = {\n",
    "    \"n_d\": 512,\n",
    "    \"n_a\": 512,\n",
    "    \"n_steps\": 3,\n",
    "    \"n_shared\": 2,\n",
    "    \"n_independent\": 2,\n",
    "    \"gamma\": 1.3,\n",
    "    \"epsilon\": 1e-15,\n",
    "    \"momentum\": 0.98,\n",
    "    \"mask_type\": \"sparsemax\",\n",
    "    \"lambda_sparse\": 1e-3,\n",
    "    \"device_name\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    **tabnet_params\n",
    ")\n",
    " \n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train,\n",
    "    eval_set=[X_test],  \n",
    "    pretraining_ratio=0.8,\n",
    "    max_epochs=101,\n",
    "    patience=10,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "TabNetPretraining                                            [19430, 33]               --\n",
       "├─EmbeddingGenerator: 1-1                                    [19430, 33]               --\n",
       "├─TabNetEncoder: 1-2                                         [19430, 512]              --\n",
       "│    └─BatchNorm1d: 2-1                                      [19430, 33]               66\n",
       "│    └─FeatTransformer: 2-2                                  [19430, 1024]             4,202,496\n",
       "│    │    └─GLU_Block: 3-1                                   [19430, 1024]             2,172,928\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-6                                   [19430, 1024]             4,202,496\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-7                        [19430, 33]               16,962\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-8                             [19430, 1024]             6,375,424\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-13                       [19430, 33]               16,962\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-14                            [19430, 1024]             6,375,424\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-19                       [19430, 33]               16,962\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-20                            [19430, 1024]             6,375,424\n",
       "├─TabNetDecoder: 1-3                                         [19430, 33]               --\n",
       "│    └─ModuleList: 2-13                                      --                        --\n",
       "│    │    └─FeatTransformer: 3-21                            [19430, 512]              1,052,672\n",
       "│    │    └─FeatTransformer: 3-25                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-23                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-24                            [19430, 512]              1,052,672\n",
       "│    │    └─FeatTransformer: 3-25                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-26                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-27                            [19430, 512]              1,052,672\n",
       "│    └─Linear: 2-14                                          [19430, 33]               16,896\n",
       "==============================================================================================================\n",
       "Total params: 51,409,160\n",
       "Trainable params: 51,409,160\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 558.18\n",
       "==============================================================================================================\n",
       "Input size (MB): 2.56\n",
       "Forward/backward pass size (MB): 12138.00\n",
       "Params size (MB): 84.74\n",
       "Estimated Total Size (MB): 12225.30\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truy cập vào mô hình TabNet bên trong\n",
    "from torchinfo import summary\n",
    "\n",
    "tabnet_model = unsupervised_model.network.to(device)\n",
    "\n",
    "summary(tabnet_model, input_size=X_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoder Summary:\n",
      "TabNetEncoder(\n",
      "  (initial_bn): BatchNorm1d(33, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "  (initial_splitter): FeatTransformer(\n",
      "    (shared): GLU_Block(\n",
      "      (shared_layers): ModuleList(\n",
      "        (0): Linear(in_features=33, out_features=2048, bias=False)\n",
      "        (1): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "      )\n",
      "      (glu_layers): ModuleList(\n",
      "        (0): GLU_Layer(\n",
      "          (fc): Linear(in_features=33, out_features=2048, bias=False)\n",
      "          (bn): GBN(\n",
      "            (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): GLU_Layer(\n",
      "          (fc): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "          (bn): GBN(\n",
      "            (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (specifics): GLU_Block(\n",
      "      (glu_layers): ModuleList(\n",
      "        (0-1): 2 x GLU_Layer(\n",
      "          (fc): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "          (bn): GBN(\n",
      "            (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feat_transformers): ModuleList(\n",
      "    (0-2): 3 x FeatTransformer(\n",
      "      (shared): GLU_Block(\n",
      "        (shared_layers): ModuleList(\n",
      "          (0): Linear(in_features=33, out_features=2048, bias=False)\n",
      "          (1): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "        )\n",
      "        (glu_layers): ModuleList(\n",
      "          (0): GLU_Layer(\n",
      "            (fc): Linear(in_features=33, out_features=2048, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): GLU_Layer(\n",
      "            (fc): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (specifics): GLU_Block(\n",
      "        (glu_layers): ModuleList(\n",
      "          (0-1): 2 x GLU_Layer(\n",
      "            (fc): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (att_transformers): ModuleList(\n",
      "    (0-2): 3 x AttentiveTransformer(\n",
      "      (fc): Linear(in_features=512, out_features=33, bias=False)\n",
      "      (bn): GBN(\n",
      "        (bn): BatchNorm1d(33, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (selector): Sparsemax()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = tabnet_model.encoder\n",
    "\n",
    "print(\"\\nEncoder Summary:\")\n",
    "print(encoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoder Summary:\n",
      "TabNetDecoder(\n",
      "  (feat_transformers): ModuleList(\n",
      "    (0-2): 3 x FeatTransformer(\n",
      "      (shared): GLU_Block(\n",
      "        (shared_layers): ModuleList(\n",
      "          (0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        )\n",
      "        (glu_layers): ModuleList(\n",
      "          (0): GLU_Layer(\n",
      "            (fc): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (specifics): GLU_Block(\n",
      "        (glu_layers): ModuleList(\n",
      "          (0): GLU_Layer(\n",
      "            (fc): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (reconstruction_layer): Linear(in_features=512, out_features=33, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "decoder = tabnet_model.decoder\n",
    "\n",
    "print(\"\\nDecoder Summary:\")\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNet encoder trả về 2 giá trị.\n",
      "Đã xảy ra lỗi: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14308\\3356785120.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample_input = torch.tensor(X_train[:5]).to(device)\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.tensor(X_train[:5]).to(device)  \n",
    "\n",
    "try:\n",
    "    result = tabnet_model.encoder(sample_input)\n",
    "    if isinstance(result, tuple):\n",
    "        print(f'TabNet encoder trả về {len(result)} giá trị.')\n",
    "        for i, res in enumerate(result):\n",
    "            print(f'Giá trị {i + 1} shape: {res.shape}')\n",
    "    else:\n",
    "        print('TabNet encoder chỉ trả về một giá trị.')\n",
    "        print(f'Giá trị shape: {result.shape}')\n",
    "except Exception as e:\n",
    "    print(f'Đã xảy ra lỗi: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(nn.Module):\n",
    "    def __init__(self, seed=1337):\n",
    "        super(Sampling, self).__init__()\n",
    "        self.seed = seed\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = z_mean.size(0)\n",
    "        dim = z_mean.size(1)\n",
    "        # print(batch, dim)\n",
    "        epsilon = torch.randn(batch, dim, generator=torch.Generator().manual_seed(self.seed)).to(device)\n",
    "        return z_mean + torch.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VAE_Encoder(nn.Module):\n",
    "#     def __init__(self, latent_dim):\n",
    "#         super(VAE_Encoder, self).__init__()\n",
    "#         self.tabnet_encoder = tabnet_model.encoder\n",
    "#         self.mlp = nn.Sequential(\n",
    "#             nn.Linear(512, 256),  \n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 96),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(96, 96),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(96, 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32, latent_dim)\n",
    "#         ).to(device)\n",
    "#         self.fc_mean = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "#         self.fc_log_var = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "#         self.sampling = Sampling().to(device)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.to(device)\n",
    "#         steps_output, _ = self.tabnet_encoder(x)\n",
    "#         encoded = steps_output[-1]\n",
    "#         # print(\"Shape of encoded tensor:\", encoded.shape)\n",
    "#         encoded = self.mlp(encoded)\n",
    "#         z_mean = self.fc_mean(encoded)\n",
    "#         z_log_var = self.fc_log_var(encoded)\n",
    "#         z = self.sampling((z_mean, z_log_var))\n",
    "#         # print(f'Shape of z: {z.shape} - {z_log_var.shape} -{z_log_var.shape}')\n",
    "#         return z_mean, z_log_var, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE_Encoder, self).__init__()\n",
    "        self.tabnet_encoder = tabnet_model.encoder\n",
    "\n",
    "        self.mlp_0 = nn.Sequential(\n",
    "            nn.Linear(512, 256),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        ).to(device)\n",
    "\n",
    "        self.mlp_1 = nn.Sequential(\n",
    "            nn.Linear(512, 256),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        ).to(device)\n",
    "\n",
    "        self.fc_mean_0 = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "        self.fc_log_var_0 = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "\n",
    "        self.fc_mean_1 = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "        self.fc_log_var_1 = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "\n",
    "        self.sampling = Sampling().to(device)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        steps_output, _ = self.tabnet_encoder(x)\n",
    "        encoded = steps_output[-1]\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        latent_dim = self.fc_mean_0.out_features\n",
    "\n",
    "        z_mean = torch.zeros(batch_size, latent_dim).to(device)\n",
    "        z_log_var = torch.zeros(batch_size, latent_dim).to(device)\n",
    "        z = torch.zeros(batch_size, latent_dim).to(device)\n",
    "\n",
    "        idx_0 = (labels == 0)\n",
    "        idx_1 = (labels == 1)\n",
    "\n",
    "        if idx_0.sum() > 0:\n",
    "            if encoded.size(0) >= idx_0.max().item() + 1:\n",
    "                idx_0 = idx_0.squeeze()\n",
    "                encoded_0 = encoded[idx_0]\n",
    "                out_0 = self.mlp_0(encoded_0)\n",
    "                mu_0 = self.fc_mean_0(out_0)\n",
    "                logvar_0 = self.fc_log_var_0(out_0)\n",
    "                z_0 = self.sampling((mu_0, logvar_0))\n",
    "\n",
    "                z_mean[idx_0] = mu_0\n",
    "                z_log_var[idx_0] = logvar_0\n",
    "                z[idx_0] = z_0\n",
    "            else:\n",
    "                print(\"Batch quá nhỏ hoặc idx_0 không hợp lệ\")\n",
    "            \n",
    "\n",
    "        if idx_1.sum() > 0:\n",
    "            encoded_1 = encoded[idx_1]\n",
    "            if encoded.size(0) >= idx_1.max().item() + 1:\n",
    "                idx_1 = idx_1.squeeze()\n",
    "                encoded_1 = encoded[idx_1]\n",
    "                out_1 = self.mlp_1(encoded_1)\n",
    "                mu_1 = self.fc_mean_1(out_1)\n",
    "                logvar_1 = self.fc_log_var_1(out_1)\n",
    "                z_1 = self.sampling((mu_1, logvar_1))\n",
    "\n",
    "                z_mean[idx_1] = mu_1\n",
    "                z_log_var[idx_1] = logvar_1\n",
    "                z[idx_1] = z_1\n",
    "\n",
    "            else:\n",
    "                print(\"Batch quá nhỏ hoặc idx_1 không hợp lệ\")\n",
    "           \n",
    "        return z_mean, z_log_var, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim,encoded_dim, output_dim):\n",
    "        super(VAE_Decoder, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),   \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, encoded_dim),  \n",
    "        )\n",
    "        self.tabnet_decoder = tabnet_model.decoder\n",
    "        self.reshape = nn.Unflatten(1, (encoded_dim,))\n",
    "        self.output_dim=output_dim\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = F.relu(self.mlp(z))\n",
    "\n",
    "        # print(\"Shape before reshape:\", x.shape)\n",
    "        x = self.reshape(x)\n",
    "        x = x[None, ...]\n",
    "\n",
    "        # print(\"Shape after reshape:\", x.shape)\n",
    "        # x = x.view(x.size(0), output_dim)\n",
    "        \n",
    "        output = self.tabnet_decoder(x)\n",
    "        # print(output.shape)\n",
    "        # print(\"Shape of output from tabnet_decoder:\", output.shape)\n",
    "        output = torch.softmax(output, dim=-1)  # Assuming the output is a probability distribution\n",
    "        output = output.view(-1, self.output_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_range(tensor, name):\n",
    "    if not torch.all((tensor >= 0) & (tensor <= 1)):\n",
    "        print(f\"{name} contains values outside the range [0, 1]\")\n",
    "        print(f\"{name} min: {tensor.min()}, max: {tensor.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Tabnet_MLPS(nn.Module):\n",
    "    def __init__(self, encoder, decoder, classifier):\n",
    "        super(VAE_Tabnet_MLPS, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.classifier = classifier\n",
    "        self.total_loss_tracker = []\n",
    "        self.reconstruction_loss_tracker = []\n",
    "        self.kl_loss_tracker = []\n",
    "        self.classification_loss_tracker = []\n",
    "        self.accuracy_tracker = []\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        z_mean, z_log_var, z = self.encoder(x, labels)\n",
    "        reconstruction = self.decoder(z)\n",
    "        classification_output = self.classifier(z)\n",
    "        return reconstruction, z_mean, z_log_var, classification_output\n",
    "\n",
    "    def train_step(self, data, labels, optimizer):\n",
    "        labels = labels.squeeze(1) \n",
    "        labels = torch.argmax(labels, dim=1).long()\n",
    "        labels = labels.to(device)\n",
    "        # print(f\"Shape of labels: {labels.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        # z_mean, z_log_var, z = self.encoder(data)\n",
    "        # reconstruction = self.decoder(z)\n",
    "        reconstruction, z_mean, z_log_var, classification_output = self.forward(data, labels)\n",
    "        # print('classifi',classification_output.shape)\n",
    "        # print(check_data_range(data, 'data'))\n",
    "        # print(check_data_range(reconstruction, 'reconstruction'))\n",
    "        # reconstruction_loss = torch.mean(\n",
    "        #     torch.sum(\n",
    "        #         F.binary_cross_entropy(reconstruction, data, reduction='none'),\n",
    "        #         dim=1\n",
    "        #     )\n",
    "        # )\n",
    "        reconstruction_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                F.binary_cross_entropy_with_logits(reconstruction, data, reduction='none'),\n",
    "                dim=1\n",
    "                # dim=(1, 2)\n",
    "                )  \n",
    "        )\n",
    "\n",
    "        # print(\"labels:\", labels)\n",
    "        # print(\"labels.shape:\", labels.shape)\n",
    "        # print(\"labels.dtype:\", labels.dtype)\n",
    "        # print(\"labels.min():\", labels.min().item(), \"labels.max():\", labels.max().item())\n",
    "        # print(\"classification_output.shape:\", classification_output.shape)\n",
    "\n",
    "        classification_loss = F.cross_entropy(classification_output, labels)\n",
    "                # dim=1\n",
    "                # dim=(1, 2)\n",
    "                \n",
    "        \n",
    "        kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=1)\n",
    "        kl_loss = torch.mean(torch.sum(kl_loss))\n",
    "        total_loss = reconstruction_loss + kl_loss + classification_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        self.total_loss_tracker.append(total_loss.item())\n",
    "        self.reconstruction_loss_tracker.append(reconstruction_loss.item())\n",
    "        self.kl_loss_tracker.append(kl_loss.item())\n",
    "        self.classification_loss_tracker.append(classification_loss.item())\n",
    "        # print(classification_output.shape, labels.shape)\n",
    "\n",
    "        preds = torch.softmax(classification_output, dim=1)\n",
    "        pred_labels = torch.argmax(preds, dim=1)\n",
    "        correct = (pred_labels == labels).float().sum()\n",
    "        accuracy = correct / labels.size(0)\n",
    "        self.accuracy_tracker.append(accuracy.item())\n",
    "\n",
    "        return {\n",
    "            \"loss\": total_loss.item(),\n",
    "            \"reconstruction_loss\": reconstruction_loss.item(),\n",
    "            \"kl_loss\": kl_loss.item(),\n",
    "            \"classification_loss\": classification_loss.item(),\n",
    "            \"accuracy\": accuracy.item()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "encoded_dim = 512\n",
    "output_dim = X_train.shape[1]\n",
    "input_dim = X_train.shape[1]\n",
    "print(input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(32, output_dim),\n",
    "            # nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('input: ',x.shape)\n",
    "        output = self.fc_layers(x)\n",
    "        # output = output.view(-1)\n",
    "        # print('output',output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SimpleClassifier(latent_dim, output_dim=2).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([32, 64])\n",
      "Output size: torch.Size([32, 1])\n",
      "Output: tensor([[ 0.3256],\n",
      "        [ 1.0663],\n",
      "        [-0.0336],\n",
      "        [-0.2313],\n",
      "        [ 0.0378],\n",
      "        [ 0.1005],\n",
      "        [-0.3622],\n",
      "        [-0.0750],\n",
      "        [ 0.7117],\n",
      "        [ 0.0388],\n",
      "        [-0.6199],\n",
      "        [ 0.4649],\n",
      "        [-0.3589],\n",
      "        [-0.0025],\n",
      "        [-0.6826],\n",
      "        [-0.1581],\n",
      "        [-0.6116],\n",
      "        [ 0.1627],\n",
      "        [ 0.2698],\n",
      "        [-0.1503],\n",
      "        [ 0.1860],\n",
      "        [-0.0651],\n",
      "        [-0.2239],\n",
      "        [-0.4741],\n",
      "        [ 0.1823],\n",
      "        [ 0.6643],\n",
      "        [-0.0823],\n",
      "        [ 0.2351],\n",
      "        [ 0.0924],\n",
      "        [-0.1615],\n",
      "        [-0.1163],\n",
      "        [-0.6726]])\n"
     ]
    }
   ],
   "source": [
    "def check_output(model, input_tensor):\n",
    "    with torch.no_grad():  \n",
    "        output = model(input_tensor)\n",
    "        print(f\"Input size: {input_tensor.size()}\")\n",
    "        print(f\"Output size: {output.size()}\")\n",
    "        print(f\"Output: {output}\")\n",
    "\n",
    "model = SimpleClassifier(latent_dim, output_dim=1)\n",
    "\n",
    "input_tensor = torch.randn(32,latent_dim)  \n",
    "\n",
    "check_output(model, input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_encoder = VAE_Encoder(latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae_encoder = VAE_Encoder(latent_dim=latent_dim)\n",
    "# print(\"Encoder Summary:\")\n",
    "# # vae_encoder.to(device)\n",
    "\n",
    "# summary(vae_encoder, input_size=(32, input_dim), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shape: torch.Size([800, 512])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(800, X_train.shape[1]).to(device)\n",
    "steps_output, _ = tabnet_model.encoder(x)\n",
    "encoded = steps_output[-1]\n",
    "print(f\"Encoded shape: {encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoder output: [torch.Size([800, 512]), torch.Size([800, 512]), torch.Size([800, 512])]\n",
      "Decoder shape: torch.Size([800, 33])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(800, X_train.shape[1]).to(device)  # Đầu vào có kích thước (batch_size, features)\n",
    "\n",
    "steps_output, _ = tabnet_model.encoder(x)\n",
    "print(\"Shape of encoder output:\", [output.shape for output in steps_output])\n",
    "\n",
    "decoder_input = steps_output[-1]  \n",
    "decoder_input = decoder_input[None, ...]\n",
    "try:\n",
    "    decoder_output = tabnet_model.decoder(decoder_input)\n",
    "    print(f\"Decoder shape: {decoder_output.shape}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 33)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "VAE_Decoder                                                  [32, 33]                  --\n",
       "├─Sequential: 1-1                                            [32, 512]                 --\n",
       "│    └─Linear: 2-1                                           [32, 32]                  2,080\n",
       "│    └─ReLU: 2-2                                             [32, 32]                  --\n",
       "│    └─Linear: 2-3                                           [32, 96]                  3,168\n",
       "│    └─ReLU: 2-4                                             [32, 96]                  --\n",
       "│    └─Linear: 2-5                                           [32, 96]                  9,312\n",
       "│    └─ReLU: 2-6                                             [32, 96]                  --\n",
       "│    └─Linear: 2-7                                           [32, 128]                 12,416\n",
       "│    └─ReLU: 2-8                                             [32, 128]                 --\n",
       "│    └─Linear: 2-9                                           [32, 256]                 33,024\n",
       "│    └─ReLU: 2-10                                            [32, 256]                 --\n",
       "│    └─Linear: 2-11                                          [32, 512]                 131,584\n",
       "├─Unflatten: 1-2                                             [32, 512]                 --\n",
       "├─TabNetDecoder: 1-3                                         [32, 33]                  --\n",
       "│    └─ModuleList: 2-12                                      --                        --\n",
       "│    │    └─FeatTransformer: 3-1                             [32, 512]                 1,052,672\n",
       "│    │    └─FeatTransformer: 3-2                             --                        1,052,672\n",
       "│    │    └─FeatTransformer: 3-3                             --                        (recursive)\n",
       "│    └─Linear: 2-13                                          [32, 33]                  16,896\n",
       "==============================================================================================================\n",
       "Total params: 2,842,208\n",
       "Trainable params: 2,842,208\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 40.36\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.34\n",
       "Params size (MB): 5.04\n",
       "Estimated Total Size (MB): 6.40\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_decoder = VAE_Decoder(latent_dim=latent_dim, encoded_dim=encoded_dim, output_dim=output_dim).to(device)\n",
    "print(\"Decoder Summary:\")\n",
    "summary(vae_decoder, input_size=(32, latent_dim), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE_Tabnet_MLPS(encoder=vae_encoder, decoder=vae_decoder,classifier=classifier).to(device)\n",
    "# summary(vae, input_size=(32, input_dim), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 0.0001\n",
    "# optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "# num_epochs = 10\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     vae.train()\n",
    "#     train_loss = 0\n",
    "#     rec_loss = 0\n",
    "#     kl_loss = 0\n",
    "#     classification_loss = 0\n",
    "#     accuracy = 0\n",
    "\n",
    "#     for batch_data, batch_labels in train_loader:\n",
    "#         batch_data = batch_data.to(device)\n",
    "#         batch_labels = batch_labels.to(device)\n",
    "#         # print(f\"Batch data shape: {batch_data.shape}, Batch labels shape: {batch_labels.shape}\")\n",
    "#         results = vae.train_step(batch_data, batch_labels, optimizer)\n",
    "        \n",
    "#         train_loss += results[\"loss\"]\n",
    "#         rec_loss += results[\"reconstruction_loss\"]\n",
    "#         kl_loss += results[\"kl_loss\"]\n",
    "#         classification_loss += results[\"classification_loss\"]\n",
    "#         accuracy += results[\"accuracy\"]\n",
    "\n",
    "#     train_loss /= len(train_loader)\n",
    "#     rec_loss /= len(train_loader)\n",
    "#     kl_loss /= len(train_loader)\n",
    "#     classification_loss /= len(train_loader)\n",
    "#     accuracy /= len(train_loader)\n",
    "\n",
    "#     print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Reconstruction Loss: {rec_loss:.4f}, KL Loss: {kl_loss:.4f}, Classification Loss: {classification_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vae.encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: -402.6622, Reconstruction Loss: -434.8605, KL Loss: 31.5445, Classification Loss: 0.6538, Accuracy: 0.6138\n",
      "Epoch 2/50, Loss: -408.1541, Reconstruction Loss: -440.0485, KL Loss: 31.5452, Classification Loss: 0.3493, Accuracy: 0.8981\n",
      "Epoch 3/50, Loss: -407.1337, Reconstruction Loss: -438.8141, KL Loss: 31.5459, Classification Loss: 0.1345, Accuracy: 0.9818\n",
      "Epoch 4/50, Loss: -408.5418, Reconstruction Loss: -440.1528, KL Loss: 31.5452, Classification Loss: 0.0659, Accuracy: 0.9942\n",
      "Epoch 5/50, Loss: -406.6109, Reconstruction Loss: -438.1958, KL Loss: 31.5440, Classification Loss: 0.0409, Accuracy: 0.9955\n",
      "Epoch 6/50, Loss: -407.6235, Reconstruction Loss: -439.1914, KL Loss: 31.5441, Classification Loss: 0.0237, Accuracy: 0.9984\n",
      "Epoch 7/50, Loss: -437.6828, Reconstruction Loss: -469.2460, KL Loss: 31.5452, Classification Loss: 0.0180, Accuracy: 0.9978\n",
      "Epoch 8/50, Loss: -466.4237, Reconstruction Loss: -497.9810, KL Loss: 31.5447, Classification Loss: 0.0126, Accuracy: 0.9989\n",
      "Epoch 9/50, Loss: -466.4022, Reconstruction Loss: -497.9551, KL Loss: 31.5443, Classification Loss: 0.0086, Accuracy: 0.9994\n",
      "Epoch 10/50, Loss: -466.5154, Reconstruction Loss: -498.0684, KL Loss: 31.5446, Classification Loss: 0.0084, Accuracy: 0.9988\n",
      "Epoch 11/50, Loss: -466.3865, Reconstruction Loss: -497.9366, KL Loss: 31.5452, Classification Loss: 0.0049, Accuracy: 0.9999\n",
      "Epoch 12/50, Loss: -466.4991, Reconstruction Loss: -498.0481, KL Loss: 31.5452, Classification Loss: 0.0038, Accuracy: 0.9998\n",
      "Epoch 13/50, Loss: -466.5331, Reconstruction Loss: -498.0812, KL Loss: 31.5435, Classification Loss: 0.0045, Accuracy: 0.9993\n",
      "Epoch 14/50, Loss: -466.6780, Reconstruction Loss: -498.2249, KL Loss: 31.5441, Classification Loss: 0.0028, Accuracy: 0.9997\n",
      "Epoch 15/50, Loss: -466.4920, Reconstruction Loss: -498.0383, KL Loss: 31.5440, Classification Loss: 0.0023, Accuracy: 0.9998\n",
      "Epoch 16/50, Loss: -466.3507, Reconstruction Loss: -497.8976, KL Loss: 31.5447, Classification Loss: 0.0022, Accuracy: 0.9997\n",
      "Epoch 17/50, Loss: -466.5354, Reconstruction Loss: -498.0822, KL Loss: 31.5446, Classification Loss: 0.0022, Accuracy: 0.9996\n",
      "Epoch 18/50, Loss: -466.5270, Reconstruction Loss: -498.0739, KL Loss: 31.5442, Classification Loss: 0.0027, Accuracy: 0.9995\n",
      "Epoch 19/50, Loss: -466.4337, Reconstruction Loss: -497.9794, KL Loss: 31.5432, Classification Loss: 0.0025, Accuracy: 0.9994\n",
      "Epoch 20/50, Loss: -466.5410, Reconstruction Loss: -498.0873, KL Loss: 31.5449, Classification Loss: 0.0014, Accuracy: 0.9998\n",
      "Epoch 21/50, Loss: -466.3905, Reconstruction Loss: -497.9353, KL Loss: 31.5437, Classification Loss: 0.0012, Accuracy: 0.9998\n",
      "Epoch 22/50, Loss: -466.4740, Reconstruction Loss: -498.0186, KL Loss: 31.5430, Classification Loss: 0.0016, Accuracy: 0.9996\n",
      "Epoch 23/50, Loss: -466.4016, Reconstruction Loss: -497.9463, KL Loss: 31.5438, Classification Loss: 0.0010, Accuracy: 0.9999\n",
      "Epoch 24/50, Loss: -466.4754, Reconstruction Loss: -498.0213, KL Loss: 31.5448, Classification Loss: 0.0011, Accuracy: 0.9997\n",
      "Epoch 25/50, Loss: -466.5233, Reconstruction Loss: -498.0694, KL Loss: 31.5447, Classification Loss: 0.0014, Accuracy: 0.9996\n",
      "Epoch 26/50, Loss: -466.5974, Reconstruction Loss: -498.1424, KL Loss: 31.5445, Classification Loss: 0.0006, Accuracy: 0.9999\n",
      "Epoch 27/50, Loss: -466.5814, Reconstruction Loss: -498.1260, KL Loss: 31.5439, Classification Loss: 0.0007, Accuracy: 0.9998\n",
      "Epoch 28/50, Loss: -466.5510, Reconstruction Loss: -498.0957, KL Loss: 31.5439, Classification Loss: 0.0007, Accuracy: 0.9999\n",
      "Epoch 29/50, Loss: -466.4141, Reconstruction Loss: -497.9606, KL Loss: 31.5447, Classification Loss: 0.0018, Accuracy: 0.9997\n",
      "Epoch 30/50, Loss: -466.4687, Reconstruction Loss: -498.0132, KL Loss: 31.5440, Classification Loss: 0.0005, Accuracy: 0.9999\n",
      "Epoch 31/50, Loss: -466.5590, Reconstruction Loss: -498.1038, KL Loss: 31.5445, Classification Loss: 0.0003, Accuracy: 1.0000\n",
      "Epoch 32/50, Loss: -466.4895, Reconstruction Loss: -498.0350, KL Loss: 31.5452, Classification Loss: 0.0004, Accuracy: 0.9999\n",
      "Epoch 33/50, Loss: -466.6065, Reconstruction Loss: -498.1509, KL Loss: 31.5437, Classification Loss: 0.0007, Accuracy: 0.9998\n",
      "Epoch 34/50, Loss: -466.5113, Reconstruction Loss: -498.0557, KL Loss: 31.5442, Classification Loss: 0.0003, Accuracy: 0.9999\n",
      "Epoch 35/50, Loss: -466.4397, Reconstruction Loss: -497.9851, KL Loss: 31.5442, Classification Loss: 0.0013, Accuracy: 0.9998\n",
      "Epoch 36/50, Loss: -466.3836, Reconstruction Loss: -497.9280, KL Loss: 31.5442, Classification Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch 37/50, Loss: -466.4700, Reconstruction Loss: -498.0152, KL Loss: 31.5444, Classification Loss: 0.0007, Accuracy: 0.9998\n",
      "Epoch 38/50, Loss: -466.4711, Reconstruction Loss: -498.0160, KL Loss: 31.5446, Classification Loss: 0.0003, Accuracy: 0.9999\n",
      "Epoch 39/50, Loss: -466.6108, Reconstruction Loss: -498.1562, KL Loss: 31.5445, Classification Loss: 0.0009, Accuracy: 0.9998\n",
      "Epoch 40/50, Loss: -466.5439, Reconstruction Loss: -498.0900, KL Loss: 31.5446, Classification Loss: 0.0015, Accuracy: 0.9996\n",
      "Epoch 41/50, Loss: -466.4825, Reconstruction Loss: -498.0272, KL Loss: 31.5440, Classification Loss: 0.0007, Accuracy: 0.9999\n",
      "Epoch 42/50, Loss: -466.6626, Reconstruction Loss: -498.2077, KL Loss: 31.5443, Classification Loss: 0.0008, Accuracy: 0.9997\n",
      "Epoch 43/50, Loss: -466.4407, Reconstruction Loss: -497.9856, KL Loss: 31.5447, Classification Loss: 0.0002, Accuracy: 0.9999\n",
      "Epoch 44/50, Loss: -466.4765, Reconstruction Loss: -498.0214, KL Loss: 31.5445, Classification Loss: 0.0004, Accuracy: 0.9998\n",
      "Epoch 45/50, Loss: -466.4139, Reconstruction Loss: -497.9574, KL Loss: 31.5434, Classification Loss: 0.0002, Accuracy: 1.0000\n",
      "Epoch 46/50, Loss: -466.5875, Reconstruction Loss: -498.1314, KL Loss: 31.5438, Classification Loss: 0.0001, Accuracy: 1.0000\n",
      "Epoch 47/50, Loss: -466.3591, Reconstruction Loss: -497.9043, KL Loss: 31.5443, Classification Loss: 0.0009, Accuracy: 0.9997\n",
      "Epoch 48/50, Loss: -466.5856, Reconstruction Loss: -498.1307, KL Loss: 31.5442, Classification Loss: 0.0009, Accuracy: 0.9998\n",
      "Epoch 49/50, Loss: -466.4670, Reconstruction Loss: -498.0106, KL Loss: 31.5432, Classification Loss: 0.0004, Accuracy: 0.9999\n",
      "Epoch 50/50, Loss: -466.6422, Reconstruction Loss: -498.1874, KL Loss: 31.5448, Classification Loss: 0.0003, Accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "num_epochs = 50\n",
    "vae_new = VAE_Tabnet_MLPS(vae.encoder, vae.decoder, vae.classifier).to(device)\n",
    "for param in vae_new.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, vae_new.parameters()), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    vae_new.train()\n",
    "    train_loss = 0\n",
    "    rec_loss = 0\n",
    "    kl_loss = 0\n",
    "    classification_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        results = vae.train_step(batch_data, batch_labels, optimizer)\n",
    "        \n",
    "        train_loss += results[\"loss\"]\n",
    "        rec_loss += results[\"reconstruction_loss\"]\n",
    "        kl_loss += results[\"kl_loss\"]\n",
    "        classification_loss += results[\"classification_loss\"]\n",
    "        accuracy += results[\"accuracy\"]\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    rec_loss /= len(train_loader)\n",
    "    kl_loss /= len(train_loader)\n",
    "    classification_loss /= len(train_loader)\n",
    "    accuracy /= len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Reconstruction Loss: {rec_loss:.4f}, KL Loss: {kl_loss:.4f}, Classification Loss: {classification_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleDiffusionModel(nn.Module):\n",
    "    def __init__(self, latent_dim, time_steps=1000):\n",
    "        super().__init__()\n",
    "        self.time_steps = time_steps\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Tạo các beta_schedule tuyến tính\n",
    "        beta = torch.linspace(0.0001, 0.02, time_steps)\n",
    "        alpha = 1. - beta\n",
    "        alpha_bar = torch.cumprod(alpha, dim=0)\n",
    "\n",
    "        self.register_buffer('beta', beta)\n",
    "        self.register_buffer('alpha', alpha)\n",
    "        self.register_buffer('alpha_bar', alpha_bar)\n",
    "\n",
    "        # Mạng neural đơn giản để dự đoán nhiễu\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim + 1, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z, t):\n",
    "        noise = torch.randn_like(z)\n",
    "        \n",
    "        # Đảm bảo t là long type và shape phù hợp\n",
    "        if isinstance(t, torch.Tensor):\n",
    "            t = t.to(dtype=torch.long)\n",
    "        else:\n",
    "            t = torch.tensor([t], device=z.device, dtype=torch.long).expand(z.shape[0])\n",
    "\n",
    "        sqrt_alpha_bar = torch.sqrt(self.alpha_bar[t])[:, None]\n",
    "        sqrt_one_minus_alpha_bar = torch.sqrt(1 - self.alpha_bar[t])[:, None]\n",
    "        noisy_z = sqrt_alpha_bar * z + sqrt_one_minus_alpha_bar * noise\n",
    "\n",
    "        predicted_noise = self.model(torch.cat([noisy_z, t.unsqueeze(1)], dim=1))\n",
    "        loss = F.mse_loss(predicted_noise, noise)\n",
    "        return loss\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        z = torch.randn(num_samples, self.latent_dim).to(next(self.parameters()).device)\n",
    "        for i in reversed(range(self.time_steps)):\n",
    "            t = torch.full((num_samples,), i, device=z.device, dtype=torch.long)\n",
    "            z = self.denoise_step(z, t)\n",
    "        return z\n",
    "    \n",
    "    def denoise_step(self, z, t):\n",
    "        timestep = t.item() if isinstance(t, torch.Tensor) else t\n",
    "        t_batch = torch.full((z.shape[0],), timestep, device=z.device, dtype=torch.long)\n",
    "\n",
    "        predicted_noise = self.model(torch.cat([z, t_batch.unsqueeze(1)], dim=1))\n",
    "\n",
    "        alpha = self.alpha[timestep]\n",
    "        alpha_bar = self.alpha_bar[timestep]\n",
    "        beta = self.beta[timestep]\n",
    "\n",
    "        z = (1 / torch.sqrt(alpha)) * (z - ((1 - alpha) / torch.sqrt(1 - alpha_bar)) * predicted_noise)\n",
    "        if timestep > 0:\n",
    "            noise = torch.randn_like(z)\n",
    "            z += torch.sqrt(beta) * noise\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch quá nhỏ hoặc idx_0 không hợp lệ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    vae_new.encoder.eval()\n",
    "    dummy_input = torch.randn(1, input_dim).to(device)  # Thay input_dim theo đúng dữ liệu của bạn\n",
    "    dummy_labels = torch.zeros(1, dtype=torch.long).to(device)\n",
    "    z_mean, z_log_var, _ = vae_new.encoder(dummy_input, dummy_labels)\n",
    "    latent_dim = z_mean.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_dim = vae.encoder[-1].out_features  # Kích thước latent z\n",
    "diffusion_model = SimpleDiffusionModel(latent_dim=latent_dim).to(device)\n",
    "diffusion_optimizer = torch.optim.Adam(diffusion_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_diffusion(vae, diffusion_model, dataloader, optimizer, device, time_steps=1000, epochs=150):\n",
    "    diffusion_model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_data, batch_labels in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.squeeze().to(device)\n",
    "            if batch_labels.dim() > 1:  # nếu là one-hot hoặc có chiều phụ\n",
    "                batch_labels = batch_labels.argmax(dim=1)\n",
    "            with torch.no_grad():\n",
    "                z_mean, z_log_var, z = vae.encoder(batch_data, batch_labels)\n",
    "\n",
    "            t = torch.randint(0, time_steps, (z.shape[0],), device=device).long()\n",
    "            loss = diffusion_model(z, t)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Diffusion Loss: {total_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "def evaluate_diffusion_with_classifier(vae, diffusion_model, classifier, test_loader, device, time_steps=1000):\n",
    "    vae.eval()\n",
    "    diffusion_model.eval()\n",
    "    classifier.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in test_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.squeeze().to(device)\n",
    "            if batch_labels.ndim == 3 and batch_labels.shape[1] == 1:\n",
    "                batch_labels = batch_labels.squeeze(1)  # bỏ chiều 1\n",
    "\n",
    "            if batch_labels.ndim == 2 and batch_labels.shape[1] == 2:\n",
    "                batch_labels = torch.argmax(batch_labels, dim=1)\n",
    "            elif batch_labels.ndim == 2 and batch_labels.shape[1] == 1:\n",
    "                batch_labels = batch_labels.squeeze(1)\n",
    "\n",
    "            z_mean, z_log_var, z = vae.encoder(batch_data, batch_labels)\n",
    "\n",
    "            t_forward = time_steps - 1\n",
    "            sqrt_alpha_bar = torch.sqrt(diffusion_model.alpha_bar[t_forward])\n",
    "            sqrt_one_minus_alpha_bar = torch.sqrt(1 - diffusion_model.alpha_bar[t_forward])\n",
    "            noisy_z = sqrt_alpha_bar * z + sqrt_one_minus_alpha_bar * torch.randn_like(z)\n",
    "\n",
    "            z_recovered = noisy_z\n",
    "            for t in reversed(range(time_steps)):\n",
    "                z_recovered = diffusion_model.denoise_step(z_recovered, t)\n",
    "            logits = classifier(z_recovered)\n",
    "\n",
    "            # print(\"Logits shape:\", logits.shape)  # Debug\n",
    "\n",
    "            if len(logits.shape) == 1:\n",
    "                preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            elif len(logits.shape) == 2:\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected logits shape: {logits.shape}\")\n",
    "\n",
    "            # print(f\"preds shape: {preds.shape}, batch_labels shape: {batch_labels.shape}\")  # Debug\n",
    "            preds = preds.cpu().numpy().flatten()\n",
    "            labels = batch_labels.squeeze().cpu().numpy().flatten()\n",
    "\n",
    "            # Lưu lại cho metrics\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "            correct += (preds == labels).sum()\n",
    "            total += len(labels)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "    # Nếu bạn muốn trả về thêm các chỉ số cụ thể:\n",
    "    accuracy = sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary' if len(np.unique(all_labels)) == 2 else 'macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='binary' if len(np.unique(all_labels)) == 2 else 'macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary' if len(np.unique(all_labels)) == 2 else 'macro')\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }\n",
    "    print(f\"Accuracy on recovered z: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 304/304 [00:03<00:00, 81.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Diffusion Loss: 4.4964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 304/304 [00:03<00:00, 79.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Diffusion Loss: 0.3688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 304/304 [00:03<00:00, 79.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Diffusion Loss: 0.2212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 304/304 [00:04<00:00, 71.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Diffusion Loss: 0.1765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 304/304 [00:04<00:00, 70.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Diffusion Loss: 0.1749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 304/304 [00:04<00:00, 68.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Diffusion Loss: 0.1785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 304/304 [00:04<00:00, 68.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Diffusion Loss: 0.1944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 304/304 [00:04<00:00, 66.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Diffusion Loss: 0.1802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 304/304 [00:04<00:00, 66.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Diffusion Loss: 0.1865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 304/304 [00:04<00:00, 67.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Diffusion Loss: 0.1884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 304/304 [00:04<00:00, 68.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Diffusion Loss: 0.1772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 304/304 [00:03<00:00, 82.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Diffusion Loss: 0.1798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 304/304 [00:04<00:00, 69.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Diffusion Loss: 0.1825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 304/304 [00:04<00:00, 70.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Diffusion Loss: 0.1688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 304/304 [00:04<00:00, 71.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Diffusion Loss: 0.1663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 304/304 [00:04<00:00, 71.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Diffusion Loss: 0.1621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 304/304 [00:04<00:00, 69.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Diffusion Loss: 0.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 304/304 [00:03<00:00, 76.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Diffusion Loss: 0.1656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 304/304 [00:03<00:00, 76.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Diffusion Loss: 0.1587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 304/304 [00:03<00:00, 80.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Diffusion Loss: 0.1544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 304/304 [00:03<00:00, 78.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Diffusion Loss: 0.1521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 304/304 [00:03<00:00, 77.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Diffusion Loss: 0.1513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 304/304 [00:03<00:00, 78.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Diffusion Loss: 0.1523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 304/304 [00:03<00:00, 77.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Diffusion Loss: 0.1456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 304/304 [00:03<00:00, 80.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Diffusion Loss: 0.1437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 304/304 [00:03<00:00, 82.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Diffusion Loss: 0.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 304/304 [00:03<00:00, 79.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Diffusion Loss: 0.1414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 304/304 [00:03<00:00, 79.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Diffusion Loss: 0.1360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 304/304 [00:03<00:00, 77.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Diffusion Loss: 0.1352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 304/304 [00:03<00:00, 77.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Diffusion Loss: 0.1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 304/304 [00:03<00:00, 77.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Diffusion Loss: 0.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 304/304 [00:03<00:00, 82.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Diffusion Loss: 0.1311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 304/304 [00:03<00:00, 77.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Diffusion Loss: 0.1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 304/304 [00:04<00:00, 74.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Diffusion Loss: 0.1267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 304/304 [00:03<00:00, 80.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Diffusion Loss: 0.1266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 304/304 [00:03<00:00, 76.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Diffusion Loss: 0.1252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 304/304 [00:03<00:00, 79.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Diffusion Loss: 0.1241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 304/304 [00:03<00:00, 78.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Diffusion Loss: 0.1232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 304/304 [00:04<00:00, 72.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Diffusion Loss: 0.1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 304/304 [00:04<00:00, 73.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Diffusion Loss: 0.1225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 304/304 [00:03<00:00, 76.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Diffusion Loss: 0.1213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 304/304 [00:03<00:00, 77.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Diffusion Loss: 0.1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 304/304 [00:03<00:00, 77.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Diffusion Loss: 0.1192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 304/304 [00:03<00:00, 77.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Diffusion Loss: 0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 304/304 [00:03<00:00, 79.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Diffusion Loss: 0.1165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 304/304 [00:03<00:00, 76.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Diffusion Loss: 0.1188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 304/304 [00:04<00:00, 73.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Diffusion Loss: 0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 304/304 [00:03<00:00, 80.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Diffusion Loss: 0.1154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 304/304 [00:03<00:00, 76.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Diffusion Loss: 0.1160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 304/304 [00:03<00:00, 78.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Diffusion Loss: 0.1134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 304/304 [00:03<00:00, 79.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Diffusion Loss: 0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 304/304 [00:03<00:00, 81.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Diffusion Loss: 0.1128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 304/304 [00:03<00:00, 78.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Diffusion Loss: 0.1118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 304/304 [00:03<00:00, 78.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Diffusion Loss: 0.1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 304/304 [00:03<00:00, 79.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Diffusion Loss: 0.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 304/304 [00:03<00:00, 77.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Diffusion Loss: 0.1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 304/304 [00:03<00:00, 77.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Diffusion Loss: 0.1110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 304/304 [00:03<00:00, 80.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Diffusion Loss: 0.1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 304/304 [00:03<00:00, 76.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Diffusion Loss: 0.1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 304/304 [00:04<00:00, 73.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Diffusion Loss: 0.1074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 304/304 [00:03<00:00, 78.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Diffusion Loss: 0.1079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 304/304 [00:03<00:00, 76.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Diffusion Loss: 0.1074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 304/304 [00:03<00:00, 77.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Diffusion Loss: 0.1068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|██████████| 304/304 [00:03<00:00, 79.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, Diffusion Loss: 0.1052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|██████████| 304/304 [00:03<00:00, 79.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, Diffusion Loss: 0.1051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|██████████| 304/304 [00:03<00:00, 78.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, Diffusion Loss: 0.1048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|██████████| 304/304 [00:04<00:00, 75.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Diffusion Loss: 0.1043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|██████████| 304/304 [00:03<00:00, 76.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Diffusion Loss: 0.1017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|██████████| 304/304 [00:03<00:00, 76.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, Diffusion Loss: 0.1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|██████████| 304/304 [00:04<00:00, 72.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Diffusion Loss: 0.1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 304/304 [00:03<00:00, 77.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, Diffusion Loss: 0.1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|██████████| 304/304 [00:03<00:00, 78.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, Diffusion Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|██████████| 304/304 [00:04<00:00, 75.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73, Diffusion Loss: 0.1039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|██████████| 304/304 [00:04<00:00, 75.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74, Diffusion Loss: 0.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|██████████| 304/304 [00:03<00:00, 78.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Diffusion Loss: 0.1013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|██████████| 304/304 [00:04<00:00, 75.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, Diffusion Loss: 0.0996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|██████████| 304/304 [00:04<00:00, 73.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, Diffusion Loss: 0.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|██████████| 304/304 [00:04<00:00, 70.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, Diffusion Loss: 0.1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|██████████| 304/304 [00:04<00:00, 73.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, Diffusion Loss: 0.1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|██████████| 304/304 [00:04<00:00, 70.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Diffusion Loss: 0.0974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 304/304 [00:04<00:00, 72.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, Diffusion Loss: 0.0983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|██████████| 304/304 [00:04<00:00, 70.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, Diffusion Loss: 0.0984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|██████████| 304/304 [00:04<00:00, 71.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, Diffusion Loss: 0.0970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|██████████| 304/304 [00:04<00:00, 65.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84, Diffusion Loss: 0.0984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|██████████| 304/304 [00:04<00:00, 70.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, Diffusion Loss: 0.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|██████████| 304/304 [00:04<00:00, 75.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, Diffusion Loss: 0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|██████████| 304/304 [00:03<00:00, 79.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, Diffusion Loss: 0.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|██████████| 304/304 [00:04<00:00, 75.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88, Diffusion Loss: 0.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|██████████| 304/304 [00:04<00:00, 74.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, Diffusion Loss: 0.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|██████████| 304/304 [00:03<00:00, 77.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Diffusion Loss: 0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 304/304 [00:03<00:00, 76.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91, Diffusion Loss: 0.0957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|██████████| 304/304 [00:04<00:00, 74.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92, Diffusion Loss: 0.0965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|██████████| 304/304 [00:04<00:00, 66.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93, Diffusion Loss: 0.0967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|██████████| 304/304 [00:03<00:00, 77.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94, Diffusion Loss: 0.0924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|██████████| 304/304 [00:03<00:00, 78.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, Diffusion Loss: 0.0951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|██████████| 304/304 [00:03<00:00, 78.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96, Diffusion Loss: 0.0940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|██████████| 304/304 [00:03<00:00, 76.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97, Diffusion Loss: 0.0928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|██████████| 304/304 [00:03<00:00, 76.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98, Diffusion Loss: 0.0922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|██████████| 304/304 [00:04<00:00, 73.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, Diffusion Loss: 0.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 304/304 [00:04<00:00, 63.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Diffusion Loss: 0.0932\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.62      0.74      4782\n",
      "           1       0.06      0.39      0.11       307\n",
      "\n",
      "    accuracy                           0.60      5089\n",
      "   macro avg       0.50      0.50      0.42      5089\n",
      "weighted avg       0.89      0.60      0.71      5089\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2944 1838]\n",
      " [ 188  119]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6018864216938494,\n",
       " 'f1_score': 0.10512367491166077,\n",
       " 'precision': 0.060807358201328564,\n",
       " 'recall': 0.38762214983713356}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# latent_dim = vae.encoder[-1].out_features\n",
    "diffusion_model = SimpleDiffusionModel(latent_dim=latent_dim).to(device)\n",
    "diffusion_optimizer = optim.Adam(diffusion_model.parameters(), lr=1e-3)\n",
    "\n",
    "train_diffusion(vae_new, diffusion_model, train_loader, diffusion_optimizer, device, epochs=100)\n",
    "\n",
    "evaluate_diffusion_with_classifier(vae_new, diffusion_model, vae.classifier, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
