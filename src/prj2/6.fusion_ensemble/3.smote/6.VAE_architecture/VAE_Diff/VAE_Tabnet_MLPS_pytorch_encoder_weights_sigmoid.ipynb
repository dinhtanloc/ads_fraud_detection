{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  \n",
    "print(torch.cuda.current_device())  \n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Data\\ads_fraud_detection\n",
      "c:/Users/Admin/Data/ads_fraud_detection\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "__script_path=os.path.abspath(globals().get('__file__','.'))\n",
    "__script_dir = os.path.dirname(__script_path)\n",
    "root_dir = os.path.abspath(f'{__script_dir}/../../../../..')\n",
    "print(root_dir)\n",
    "for lib in [root_dir][::-1]:\n",
    "    if lib in sys.path:\n",
    "        sys.path.remove(lib)\n",
    "    sys.path.insert(0,lib)\n",
    "from config.config import *\n",
    "# from libs.common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=f\"{exps_dir}/exp2/exp_smote\"\n",
    "if os.path.exists(save_dir) == False: \n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6378163041991519, 1: 2.3140088827134457}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "class_weights_dict=dict(np.load(f'{save_dir}/class_weights_dict.npz',allow_pickle=True))['class_weights_dict']\n",
    "class_weights_dict = {key: value for key, value in class_weights_dict.item().items()}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19430, 33]) torch.Size([19430, 1]) torch.Size([5089, 33]) torch.Size([5089, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# y_train = y_train.values.astype(np.float32)\n",
    "# y_test = y_test.values.astype(np.float32)\n",
    "X_train = torch.tensor(x_train.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test = torch.tensor(x_test.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1941.51756| val_0_unsup_loss_numpy: 21.037090301513672|  0:00:02s\n",
      "epoch 1  | loss: 22.06558| val_0_unsup_loss_numpy: 4.085599899291992|  0:00:05s\n",
      "epoch 2  | loss: 8.62228 | val_0_unsup_loss_numpy: 6.7566399574279785|  0:00:08s\n",
      "epoch 3  | loss: 8.90729 | val_0_unsup_loss_numpy: 2.1685800552368164|  0:00:11s\n",
      "epoch 4  | loss: 4.31033 | val_0_unsup_loss_numpy: 88.85392761230469|  0:00:13s\n",
      "epoch 5  | loss: 6.68755 | val_0_unsup_loss_numpy: 1.4134299755096436|  0:00:16s\n",
      "epoch 6  | loss: 4.51434 | val_0_unsup_loss_numpy: 1.9488600492477417|  0:00:19s\n",
      "epoch 7  | loss: 5.04796 | val_0_unsup_loss_numpy: 1.7437700033187866|  0:00:22s\n",
      "epoch 8  | loss: 2.8203  | val_0_unsup_loss_numpy: 6.641610145568848|  0:00:24s\n",
      "epoch 9  | loss: 2.32682 | val_0_unsup_loss_numpy: 1.6450400352478027|  0:00:27s\n",
      "epoch 10 | loss: 2.08004 | val_0_unsup_loss_numpy: 2.615489959716797|  0:00:30s\n",
      "epoch 11 | loss: 2.23871 | val_0_unsup_loss_numpy: 1.3475799560546875|  0:00:33s\n",
      "epoch 12 | loss: 1.88427 | val_0_unsup_loss_numpy: 1.262120008468628|  0:00:35s\n",
      "epoch 13 | loss: 1.56024 | val_0_unsup_loss_numpy: 1.3143600225448608|  0:00:38s\n",
      "epoch 14 | loss: 1.36775 | val_0_unsup_loss_numpy: 1.360550045967102|  0:00:41s\n",
      "epoch 15 | loss: 1.37813 | val_0_unsup_loss_numpy: 1.2533899545669556|  0:00:44s\n",
      "epoch 16 | loss: 1.25151 | val_0_unsup_loss_numpy: 1.191249966621399|  0:00:46s\n",
      "epoch 17 | loss: 1.22788 | val_0_unsup_loss_numpy: 1.1953999996185303|  0:00:49s\n",
      "epoch 18 | loss: 1.2381  | val_0_unsup_loss_numpy: 1.2280900478363037|  0:00:52s\n",
      "epoch 19 | loss: 1.13947 | val_0_unsup_loss_numpy: 1.0085899829864502|  0:00:55s\n",
      "epoch 20 | loss: 1.0784  | val_0_unsup_loss_numpy: 1.0561800003051758|  0:00:58s\n",
      "epoch 21 | loss: 1.04977 | val_0_unsup_loss_numpy: 1.0153599977493286|  0:01:01s\n",
      "epoch 22 | loss: 1.14197 | val_0_unsup_loss_numpy: 1.0738099813461304|  0:01:04s\n",
      "epoch 23 | loss: 1.08661 | val_0_unsup_loss_numpy: 1.0555000305175781|  0:01:07s\n",
      "epoch 24 | loss: 1.18632 | val_0_unsup_loss_numpy: 1.277359962463379|  0:01:10s\n",
      "epoch 25 | loss: 1.09346 | val_0_unsup_loss_numpy: 1.1215900182724|  0:01:13s\n",
      "epoch 26 | loss: 1.09819 | val_0_unsup_loss_numpy: 1.1039700508117676|  0:01:16s\n",
      "epoch 27 | loss: 1.12579 | val_0_unsup_loss_numpy: 1.1165399551391602|  0:01:19s\n",
      "epoch 28 | loss: 1.09386 | val_0_unsup_loss_numpy: 1.0944099426269531|  0:01:22s\n",
      "epoch 29 | loss: 1.04237 | val_0_unsup_loss_numpy: 0.9616699814796448|  0:01:25s\n",
      "epoch 30 | loss: 1.0422  | val_0_unsup_loss_numpy: 1.2115700244903564|  0:01:27s\n",
      "epoch 31 | loss: 1.03273 | val_0_unsup_loss_numpy: 0.9550399780273438|  0:01:30s\n",
      "epoch 32 | loss: 1.03919 | val_0_unsup_loss_numpy: 1.02128005027771|  0:01:33s\n",
      "epoch 33 | loss: 1.05916 | val_0_unsup_loss_numpy: 0.9645599722862244|  0:01:35s\n",
      "epoch 34 | loss: 1.14837 | val_0_unsup_loss_numpy: 1.2175099849700928|  0:01:38s\n",
      "epoch 35 | loss: 1.13161 | val_0_unsup_loss_numpy: 1.0161700248718262|  0:01:41s\n",
      "epoch 36 | loss: 1.04864 | val_0_unsup_loss_numpy: 0.9416400194168091|  0:01:44s\n",
      "epoch 37 | loss: 1.03796 | val_0_unsup_loss_numpy: 0.9466099739074707|  0:01:46s\n",
      "epoch 38 | loss: 1.04712 | val_0_unsup_loss_numpy: 1.1171000003814697|  0:01:49s\n",
      "epoch 39 | loss: 1.03224 | val_0_unsup_loss_numpy: 1.0069600343704224|  0:01:52s\n",
      "epoch 40 | loss: 1.01635 | val_0_unsup_loss_numpy: 0.9125400185585022|  0:01:55s\n",
      "epoch 41 | loss: 0.96449 | val_0_unsup_loss_numpy: 0.9045199751853943|  0:01:57s\n",
      "epoch 42 | loss: 0.96617 | val_0_unsup_loss_numpy: 0.90038001537323|  0:02:00s\n",
      "epoch 43 | loss: 0.98035 | val_0_unsup_loss_numpy: 0.8801800012588501|  0:02:03s\n",
      "epoch 44 | loss: 0.98193 | val_0_unsup_loss_numpy: 0.895039975643158|  0:02:06s\n",
      "epoch 45 | loss: 0.96042 | val_0_unsup_loss_numpy: 0.8669599890708923|  0:02:08s\n",
      "epoch 46 | loss: 0.95853 | val_0_unsup_loss_numpy: 0.8800399899482727|  0:02:11s\n",
      "epoch 47 | loss: 0.95059 | val_0_unsup_loss_numpy: 0.8652499914169312|  0:02:13s\n",
      "epoch 48 | loss: 0.97695 | val_0_unsup_loss_numpy: 0.8845800161361694|  0:02:15s\n",
      "epoch 49 | loss: 0.99737 | val_0_unsup_loss_numpy: 0.8735799789428711|  0:02:17s\n",
      "epoch 50 | loss: 0.94668 | val_0_unsup_loss_numpy: 0.8738600015640259|  0:02:19s\n",
      "epoch 51 | loss: 0.96331 | val_0_unsup_loss_numpy: 0.8837500214576721|  0:02:21s\n",
      "epoch 52 | loss: 0.98914 | val_0_unsup_loss_numpy: 0.8901900053024292|  0:02:23s\n",
      "epoch 53 | loss: 0.96705 | val_0_unsup_loss_numpy: 0.8846499919891357|  0:02:25s\n",
      "epoch 54 | loss: 0.95374 | val_0_unsup_loss_numpy: 0.900950014591217|  0:02:27s\n",
      "epoch 55 | loss: 0.95413 | val_0_unsup_loss_numpy: 0.8563699722290039|  0:02:29s\n",
      "epoch 56 | loss: 0.93821 | val_0_unsup_loss_numpy: 0.82819002866745|  0:02:31s\n",
      "epoch 57 | loss: 0.93614 | val_0_unsup_loss_numpy: 0.8290600180625916|  0:02:33s\n",
      "epoch 58 | loss: 0.94227 | val_0_unsup_loss_numpy: 0.8391900062561035|  0:02:35s\n",
      "epoch 59 | loss: 0.98242 | val_0_unsup_loss_numpy: 0.8648899793624878|  0:02:37s\n",
      "epoch 60 | loss: 0.94819 | val_0_unsup_loss_numpy: 0.8229299783706665|  0:02:38s\n",
      "epoch 61 | loss: 0.94446 | val_0_unsup_loss_numpy: 0.8197299838066101|  0:02:40s\n",
      "epoch 62 | loss: 0.97418 | val_0_unsup_loss_numpy: 0.9168499708175659|  0:02:42s\n",
      "epoch 63 | loss: 1.02273 | val_0_unsup_loss_numpy: 0.822160005569458|  0:02:44s\n",
      "epoch 64 | loss: 0.96167 | val_0_unsup_loss_numpy: 0.8324000239372253|  0:02:46s\n",
      "epoch 65 | loss: 0.94561 | val_0_unsup_loss_numpy: 0.8230999708175659|  0:02:48s\n",
      "epoch 66 | loss: 0.93456 | val_0_unsup_loss_numpy: 0.8163700103759766|  0:02:50s\n",
      "epoch 67 | loss: 0.9439  | val_0_unsup_loss_numpy: 0.8678100109100342|  0:02:52s\n",
      "epoch 68 | loss: 0.93858 | val_0_unsup_loss_numpy: 0.8542199730873108|  0:02:54s\n",
      "epoch 69 | loss: 0.93572 | val_0_unsup_loss_numpy: 0.8215600252151489|  0:02:56s\n",
      "epoch 70 | loss: 0.92469 | val_0_unsup_loss_numpy: 0.8466200232505798|  0:02:58s\n",
      "epoch 71 | loss: 0.94253 | val_0_unsup_loss_numpy: 0.825659990310669|  0:03:00s\n",
      "epoch 72 | loss: 0.93626 | val_0_unsup_loss_numpy: 0.7912899851799011|  0:03:02s\n",
      "epoch 73 | loss: 0.91903 | val_0_unsup_loss_numpy: 0.8102099895477295|  0:03:04s\n",
      "epoch 74 | loss: 0.92683 | val_0_unsup_loss_numpy: 0.8240500092506409|  0:03:06s\n",
      "epoch 75 | loss: 0.92591 | val_0_unsup_loss_numpy: 0.8643199801445007|  0:03:08s\n",
      "epoch 76 | loss: 0.95138 | val_0_unsup_loss_numpy: 0.8731499910354614|  0:03:10s\n",
      "epoch 77 | loss: 0.94109 | val_0_unsup_loss_numpy: 0.8157299757003784|  0:03:12s\n",
      "epoch 78 | loss: 0.92133 | val_0_unsup_loss_numpy: 0.8320900201797485|  0:03:14s\n",
      "epoch 79 | loss: 0.94743 | val_0_unsup_loss_numpy: 0.8314899802207947|  0:03:16s\n",
      "epoch 80 | loss: 0.93404 | val_0_unsup_loss_numpy: 0.8224700093269348|  0:03:18s\n",
      "epoch 81 | loss: 0.92291 | val_0_unsup_loss_numpy: 0.8184700012207031|  0:03:20s\n",
      "epoch 82 | loss: 0.92311 | val_0_unsup_loss_numpy: 0.8024200201034546|  0:03:22s\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 72 and best_val_0_unsup_loss_numpy = 0.7912899851799011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "tabnet_params = {\n",
    "    \"n_d\": 512,\n",
    "    \"n_a\": 512,\n",
    "    \"n_steps\": 3,\n",
    "    \"n_shared\": 2,\n",
    "    \"n_independent\": 2,\n",
    "    \"gamma\": 1.3,\n",
    "    \"epsilon\": 1e-15,\n",
    "    \"momentum\": 0.98,\n",
    "    \"mask_type\": \"sparsemax\",\n",
    "    \"lambda_sparse\": 1e-3,\n",
    "    \"device_name\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "\n",
    "unsupervised_model = TabNetPretrainer(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    **tabnet_params\n",
    ")\n",
    " \n",
    "\n",
    "unsupervised_model.fit(\n",
    "    X_train,\n",
    "    eval_set=[X_test],  \n",
    "    pretraining_ratio=0.8,\n",
    "    max_epochs=101,\n",
    "    patience=10,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "TabNetPretraining                                            [19430, 33]               --\n",
       "├─EmbeddingGenerator: 1-1                                    [19430, 33]               --\n",
       "├─TabNetEncoder: 1-2                                         [19430, 512]              --\n",
       "│    └─BatchNorm1d: 2-1                                      [19430, 33]               66\n",
       "│    └─FeatTransformer: 2-2                                  [19430, 1024]             4,202,496\n",
       "│    │    └─GLU_Block: 3-1                                   [19430, 1024]             2,172,928\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    └─FeatTransformer: 2-6                                  --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-5                                   --                        (recursive)\n",
       "│    │    └─GLU_Block: 3-6                                   [19430, 1024]             4,202,496\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-7                        [19430, 33]               16,962\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-8                             [19430, 1024]             6,375,424\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-12                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-13                       [19430, 33]               16,962\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-14                            [19430, 1024]             6,375,424\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-17                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-18                            --                        (recursive)\n",
       "│    └─ModuleList: 2-11                                      --                        (recursive)\n",
       "│    │    └─AttentiveTransformer: 3-19                       [19430, 33]               16,962\n",
       "│    └─ModuleList: 2-12                                      --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-20                            [19430, 1024]             6,375,424\n",
       "├─TabNetDecoder: 1-3                                         [19430, 33]               --\n",
       "│    └─ModuleList: 2-13                                      --                        --\n",
       "│    │    └─FeatTransformer: 3-21                            [19430, 512]              1,052,672\n",
       "│    │    └─FeatTransformer: 3-25                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-23                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-24                            [19430, 512]              1,052,672\n",
       "│    │    └─FeatTransformer: 3-25                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-26                            --                        (recursive)\n",
       "│    │    └─FeatTransformer: 3-27                            [19430, 512]              1,052,672\n",
       "│    └─Linear: 2-14                                          [19430, 33]               16,896\n",
       "==============================================================================================================\n",
       "Total params: 51,409,160\n",
       "Trainable params: 51,409,160\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 558.18\n",
       "==============================================================================================================\n",
       "Input size (MB): 2.56\n",
       "Forward/backward pass size (MB): 12138.00\n",
       "Params size (MB): 84.74\n",
       "Estimated Total Size (MB): 12225.30\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truy cập vào mô hình TabNet bên trong\n",
    "from torchinfo import summary\n",
    "\n",
    "tabnet_model = unsupervised_model.network.to(device)\n",
    "\n",
    "summary(tabnet_model, input_size=X_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoder Summary:\n",
      "TabNetEncoder(\n",
      "  (initial_bn): BatchNorm1d(33, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "  (initial_splitter): FeatTransformer(\n",
      "    (shared): GLU_Block(\n",
      "      (shared_layers): ModuleList(\n",
      "        (0): Linear(in_features=33, out_features=2048, bias=False)\n",
      "        (1): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "      )\n",
      "      (glu_layers): ModuleList(\n",
      "        (0): GLU_Layer(\n",
      "          (fc): Linear(in_features=33, out_features=2048, bias=False)\n",
      "          (bn): GBN(\n",
      "            (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): GLU_Layer(\n",
      "          (fc): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "          (bn): GBN(\n",
      "            (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (specifics): GLU_Block(\n",
      "      (glu_layers): ModuleList(\n",
      "        (0-1): 2 x GLU_Layer(\n",
      "          (fc): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "          (bn): GBN(\n",
      "            (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feat_transformers): ModuleList(\n",
      "    (0-2): 3 x FeatTransformer(\n",
      "      (shared): GLU_Block(\n",
      "        (shared_layers): ModuleList(\n",
      "          (0): Linear(in_features=33, out_features=2048, bias=False)\n",
      "          (1): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "        )\n",
      "        (glu_layers): ModuleList(\n",
      "          (0): GLU_Layer(\n",
      "            (fc): Linear(in_features=33, out_features=2048, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): GLU_Layer(\n",
      "            (fc): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (specifics): GLU_Block(\n",
      "        (glu_layers): ModuleList(\n",
      "          (0-1): 2 x GLU_Layer(\n",
      "            (fc): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(2048, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (att_transformers): ModuleList(\n",
      "    (0-2): 3 x AttentiveTransformer(\n",
      "      (fc): Linear(in_features=512, out_features=33, bias=False)\n",
      "      (bn): GBN(\n",
      "        (bn): BatchNorm1d(33, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (selector): Sparsemax()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = tabnet_model.encoder\n",
    "\n",
    "print(\"\\nEncoder Summary:\")\n",
    "print(encoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoder Summary:\n",
      "TabNetDecoder(\n",
      "  (feat_transformers): ModuleList(\n",
      "    (0-2): 3 x FeatTransformer(\n",
      "      (shared): GLU_Block(\n",
      "        (shared_layers): ModuleList(\n",
      "          (0): Linear(in_features=512, out_features=1024, bias=False)\n",
      "        )\n",
      "        (glu_layers): ModuleList(\n",
      "          (0): GLU_Layer(\n",
      "            (fc): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (specifics): GLU_Block(\n",
      "        (glu_layers): ModuleList(\n",
      "          (0): GLU_Layer(\n",
      "            (fc): Linear(in_features=512, out_features=1024, bias=False)\n",
      "            (bn): GBN(\n",
      "              (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.98, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (reconstruction_layer): Linear(in_features=512, out_features=33, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "decoder = tabnet_model.decoder\n",
    "\n",
    "print(\"\\nDecoder Summary:\")\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabNet encoder trả về 2 giá trị.\n",
      "Đã xảy ra lỗi: 'list' object has no attribute 'shape'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13884\\3356785120.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sample_input = torch.tensor(X_train[:5]).to(device)\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.tensor(X_train[:5]).to(device)  \n",
    "\n",
    "try:\n",
    "    result = tabnet_model.encoder(sample_input)\n",
    "    if isinstance(result, tuple):\n",
    "        print(f'TabNet encoder trả về {len(result)} giá trị.')\n",
    "        for i, res in enumerate(result):\n",
    "            print(f'Giá trị {i + 1} shape: {res.shape}')\n",
    "    else:\n",
    "        print('TabNet encoder chỉ trả về một giá trị.')\n",
    "        print(f'Giá trị shape: {result.shape}')\n",
    "except Exception as e:\n",
    "    print(f'Đã xảy ra lỗi: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(nn.Module):\n",
    "    def __init__(self, seed=1337):\n",
    "        super(Sampling, self).__init__()\n",
    "        self.seed = seed\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = z_mean.size(0)\n",
    "        dim = z_mean.size(1)\n",
    "        # print(batch, dim)\n",
    "        epsilon = torch.randn(batch, dim, generator=torch.Generator().manual_seed(self.seed)).to(device)\n",
    "        return z_mean + torch.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE_Encoder, self).__init__()\n",
    "        self.tabnet_encoder = tabnet_model.encoder\n",
    "\n",
    "        self.mlp_0 = nn.Sequential(\n",
    "            nn.Linear(512, 256),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        ).to(device)\n",
    "\n",
    "        self.mlp_1 = nn.Sequential(\n",
    "            nn.Linear(512, 256),  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        ).to(device)\n",
    "\n",
    "        self.fc_mean_0 = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "        self.fc_log_var_0 = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "\n",
    "        self.fc_mean_1 = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "        self.fc_log_var_1 = nn.Linear(latent_dim, latent_dim).to(device)\n",
    "\n",
    "        self.sampling = Sampling().to(device)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        steps_output, _ = self.tabnet_encoder(x)\n",
    "        encoded = steps_output[-1]\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        latent_dim = self.fc_mean_0.out_features\n",
    "\n",
    "        z_mean = torch.zeros(batch_size, latent_dim).to(device)\n",
    "        z_log_var = torch.zeros(batch_size, latent_dim).to(device)\n",
    "        z = torch.zeros(batch_size, latent_dim).to(device)\n",
    "\n",
    "        idx_0 = (labels.squeeze() == 0)  # hoặc labels[:, 0] == 0\n",
    "        idx_1 = (labels.squeeze() == 1)\n",
    "\n",
    "        if idx_0.sum() > 0:\n",
    "            if encoded.size(0) >= idx_0.max().item() + 1:\n",
    "                # idx_1 = idx_1.squeeze(1)\n",
    "\n",
    "                encoded_0 = encoded[idx_0]\n",
    "                out_0 = self.mlp_0(encoded_0)\n",
    "                mu_0 = self.fc_mean_0(out_0)\n",
    "                logvar_0 = self.fc_log_var_0(out_0)\n",
    "                z_0 = self.sampling((mu_0, logvar_0))\n",
    "\n",
    "                z_mean[idx_0] = mu_0\n",
    "                z_log_var[idx_0] = logvar_0\n",
    "                z[idx_0] = z_0\n",
    "            # else:\n",
    "            #     print(\"Batch quá nhỏ hoặc idx_0 không hợp lệ\")\n",
    "            \n",
    "\n",
    "        if idx_1.sum() > 0:\n",
    "            encoded_1 = encoded[idx_1]\n",
    "            if encoded.size(0) >= idx_1.max().item() + 1:\n",
    "                # idx_1 = idx_1.squeeze(1)\n",
    "                encoded_1 = encoded[idx_1]\n",
    "                out_1 = self.mlp_1(encoded_1)\n",
    "                mu_1 = self.fc_mean_1(out_1)\n",
    "                logvar_1 = self.fc_log_var_1(out_1)\n",
    "                z_1 = self.sampling((mu_1, logvar_1))\n",
    "\n",
    "                z_mean[idx_1] = mu_1\n",
    "                z_log_var[idx_1] = logvar_1\n",
    "                z[idx_1] = z_1\n",
    "\n",
    "            # else:\n",
    "            #     print(\"Batch quá nhỏ hoặc idx_1 không hợp lệ\")\n",
    "\n",
    "        return z_mean, z_log_var, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim,encoded_dim, output_dim):\n",
    "        super(VAE_Decoder, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),   \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, encoded_dim),  \n",
    "        )\n",
    "        self.tabnet_decoder = tabnet_model.decoder\n",
    "        self.reshape = nn.Unflatten(1, (encoded_dim,))\n",
    "        self.output_dim=output_dim\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = F.relu(self.mlp(z))\n",
    "\n",
    "        # print(\"Shape before reshape:\", x.shape)\n",
    "        # x = self.reshape(x)\n",
    "        x = x[None, ...]\n",
    "\n",
    "        # print(\"Shape after reshape:\", x.shape)\n",
    "        # x = x.view(x.size(0), output_dim)\n",
    "        \n",
    "        output = self.tabnet_decoder(x)\n",
    "        # print(output.shape)\n",
    "        # print(\"Shape of output from tabnet_decoder:\", output.shape)\n",
    "        output = torch.sigmoid(output)\n",
    "        output = output.view(-1, self.output_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_range(tensor, name):\n",
    "    if not torch.all((tensor >= 0) & (tensor <= 1)):\n",
    "        print(f\"{name} contains values outside the range [0, 1]\")\n",
    "        print(f\"{name} min: {tensor.min()}, max: {tensor.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Tabnet_MLPS(nn.Module):\n",
    "    def __init__(self, encoder, decoder, classifier):\n",
    "        super(VAE_Tabnet_MLPS, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.classifier = classifier\n",
    "        self.total_loss_tracker = []\n",
    "        self.reconstruction_loss_tracker = []\n",
    "        self.kl_loss_tracker = []\n",
    "        self.classification_loss_tracker = []\n",
    "        self.accuracy_tracker = []\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        z_mean, z_log_var, z = self.encoder(x, labels)\n",
    "        reconstruction = self.decoder(z)\n",
    "        classification_output = self.classifier(z)\n",
    "        return reconstruction, z_mean, z_log_var, classification_output\n",
    "\n",
    "    def train_step(self, data, labels, optimizer):\n",
    "        labels = labels.float()\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # z_mean, z_log_var, z = self.encoder(data)\n",
    "        # reconstruction = self.decoder(z)\n",
    "        reconstruction, z_mean, z_log_var, classification_output = self.forward(data, labels)\n",
    "        # print('classifi',classification_output.shape)\n",
    "        # print(check_data_range(data, 'data'))\n",
    "        # print(check_data_range(reconstruction, 'reconstruction'))\n",
    "        # reconstruction_loss = torch.mean(\n",
    "        #     torch.sum(\n",
    "        #         F.binary_cross_entropy(reconstruction, data, reduction='none'),\n",
    "        #         dim=1\n",
    "        #     )\n",
    "        # )\n",
    "        reconstruction_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                F.binary_cross_entropy_with_logits(reconstruction, data, reduction='none'),\n",
    "                dim=1\n",
    "                # dim=(1, 2)\n",
    "                )  \n",
    "        )\n",
    "        classification_loss = torch.mean(\n",
    "            torch.sum(\n",
    "                F.binary_cross_entropy_with_logits(classification_output, labels, reduction='none'),\n",
    "                # dim=1\n",
    "                # dim=(1, 2)\n",
    "                )  \n",
    "        )\n",
    "        kl_loss = -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp(), dim=1)\n",
    "        kl_loss = torch.mean(torch.sum(kl_loss))\n",
    "        total_loss = reconstruction_loss + kl_loss + classification_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        self.total_loss_tracker.append(total_loss.item())\n",
    "        self.reconstruction_loss_tracker.append(reconstruction_loss.item())\n",
    "        self.kl_loss_tracker.append(kl_loss.item())\n",
    "        self.classification_loss_tracker.append(classification_loss.item())\n",
    "\n",
    "        preds = torch.sigmoid(classification_output)\n",
    "        correct = ((preds > 0.5) == labels).float().sum()\n",
    "        accuracy = correct / labels.size(0)\n",
    "        self.accuracy_tracker.append(accuracy.item())\n",
    "\n",
    "        return {\n",
    "            \"loss\": total_loss.item(),\n",
    "            \"reconstruction_loss\": reconstruction_loss.item(),\n",
    "            \"kl_loss\": kl_loss.item(),\n",
    "            \"classification_loss\": classification_loss.item(),\n",
    "            \"accuracy\": accuracy.item()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 64\n",
    "encoded_dim = 512\n",
    "output_dim = X_train.shape[1]\n",
    "input_dim = X_train.shape[1]\n",
    "print(input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(32, output_dim),\n",
    "            # nn.Softmax()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('input: ',x.shape)\n",
    "        output = self.fc_layers(x)\n",
    "        # output = output.view(-1)\n",
    "        # print('output',output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SimpleClassifier(latent_dim, output_dim=1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: torch.Size([32, 64])\n",
      "Output size: torch.Size([32, 1])\n",
      "Output: tensor([[-1.0297],\n",
      "        [ 0.2214],\n",
      "        [-0.3959],\n",
      "        [-0.3669],\n",
      "        [-0.4729],\n",
      "        [-0.3672],\n",
      "        [ 0.0294],\n",
      "        [-0.7407],\n",
      "        [-0.2764],\n",
      "        [ 0.3790],\n",
      "        [-0.5971],\n",
      "        [-0.0585],\n",
      "        [ 0.1162],\n",
      "        [-0.4371],\n",
      "        [-0.0668],\n",
      "        [-0.9475],\n",
      "        [-0.5368],\n",
      "        [-0.1033],\n",
      "        [-0.2090],\n",
      "        [-0.1462],\n",
      "        [-0.1314],\n",
      "        [-0.0668],\n",
      "        [-0.5518],\n",
      "        [-0.1595],\n",
      "        [-0.2493],\n",
      "        [-0.2016],\n",
      "        [ 0.0475],\n",
      "        [-0.5231],\n",
      "        [-0.0213],\n",
      "        [ 0.6597],\n",
      "        [-0.5779],\n",
      "        [-0.4592]])\n"
     ]
    }
   ],
   "source": [
    "def check_output(model, input_tensor):\n",
    "    with torch.no_grad():  \n",
    "        output = model(input_tensor)\n",
    "        print(f\"Input size: {input_tensor.size()}\")\n",
    "        print(f\"Output size: {output.size()}\")\n",
    "        print(f\"Output: {output}\")\n",
    "\n",
    "model = SimpleClassifier(latent_dim, output_dim=1)\n",
    "\n",
    "input_tensor = torch.randn(32,latent_dim)  \n",
    "\n",
    "check_output(model, input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Summary:\n"
     ]
    }
   ],
   "source": [
    "vae_encoder = VAE_Encoder(latent_dim=latent_dim)\n",
    "print(\"Encoder Summary:\")\n",
    "# vae_encoder.to(device)\n",
    "\n",
    "# summary(vae_encoder, input_size=(32, input_dim), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shape: torch.Size([800, 512])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(800, X_train.shape[1]).to(device)\n",
    "steps_output, _ = tabnet_model.encoder(x)\n",
    "encoded = steps_output[-1]\n",
    "print(f\"Encoded shape: {encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoder output: [torch.Size([800, 512]), torch.Size([800, 512]), torch.Size([800, 512])]\n",
      "Decoder shape: torch.Size([800, 33])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(800, X_train.shape[1]).to(device)  # Đầu vào có kích thước (batch_size, features)\n",
    "\n",
    "steps_output, _ = tabnet_model.encoder(x)\n",
    "print(\"Shape of encoder output:\", [output.shape for output in steps_output])\n",
    "\n",
    "decoder_input = steps_output[-1]  \n",
    "decoder_input = decoder_input[None, ...]\n",
    "try:\n",
    "    decoder_output = tabnet_model.decoder(decoder_input)\n",
    "    print(f\"Decoder shape: {decoder_output.shape}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Summary:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "VAE_Decoder                                                  [32, 33]                  --\n",
       "├─Sequential: 1-1                                            [32, 512]                 --\n",
       "│    └─Linear: 2-1                                           [32, 32]                  2,080\n",
       "│    └─ReLU: 2-2                                             [32, 32]                  --\n",
       "│    └─Linear: 2-3                                           [32, 96]                  3,168\n",
       "│    └─ReLU: 2-4                                             [32, 96]                  --\n",
       "│    └─Linear: 2-5                                           [32, 96]                  9,312\n",
       "│    └─ReLU: 2-6                                             [32, 96]                  --\n",
       "│    └─Linear: 2-7                                           [32, 128]                 12,416\n",
       "│    └─ReLU: 2-8                                             [32, 128]                 --\n",
       "│    └─Linear: 2-9                                           [32, 256]                 33,024\n",
       "│    └─ReLU: 2-10                                            [32, 256]                 --\n",
       "│    └─Linear: 2-11                                          [32, 512]                 131,584\n",
       "├─TabNetDecoder: 1-2                                         [32, 33]                  --\n",
       "│    └─ModuleList: 2-12                                      --                        --\n",
       "│    │    └─FeatTransformer: 3-1                             [32, 512]                 1,052,672\n",
       "│    │    └─FeatTransformer: 3-2                             --                        1,052,672\n",
       "│    │    └─FeatTransformer: 3-3                             --                        (recursive)\n",
       "│    └─Linear: 2-13                                          [32, 33]                  16,896\n",
       "==============================================================================================================\n",
       "Total params: 2,842,208\n",
       "Trainable params: 2,842,208\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 40.36\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.34\n",
       "Params size (MB): 5.04\n",
       "Estimated Total Size (MB): 6.40\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_decoder = VAE_Decoder(latent_dim=latent_dim, encoded_dim=encoded_dim, output_dim=output_dim).to(device)\n",
    "print(\"Decoder Summary:\")\n",
    "summary(vae_decoder, input_size=(32, latent_dim), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE_Tabnet_MLPS(encoder=vae_encoder, decoder=vae_decoder,classifier=classifier).to(device)\n",
    "# summary(vae, input_size=(32, input_dim), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 0.0001\n",
    "# optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "# num_epochs = 10\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     vae.train()\n",
    "#     train_loss = 0\n",
    "#     rec_loss = 0\n",
    "#     kl_loss = 0\n",
    "#     classification_loss = 0\n",
    "#     accuracy = 0\n",
    "\n",
    "#     for batch_data, batch_labels in train_loader:\n",
    "#         batch_data = batch_data.to(device)\n",
    "#         batch_labels = batch_labels.to(device)\n",
    "#         results = vae.train_step(batch_data, batch_labels, optimizer)\n",
    "        \n",
    "#         train_loss += results[\"loss\"]\n",
    "#         rec_loss += results[\"reconstruction_loss\"]\n",
    "#         kl_loss += results[\"kl_loss\"]\n",
    "#         classification_loss += results[\"classification_loss\"]\n",
    "#         accuracy += results[\"accuracy\"]\n",
    "\n",
    "#     train_loss /= len(train_loader)\n",
    "#     rec_loss /= len(train_loader)\n",
    "#     kl_loss /= len(train_loader)\n",
    "#     classification_loss /= len(train_loader)\n",
    "#     accuracy /= len(train_loader)\n",
    "\n",
    "#     print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Reconstruction Loss: {rec_loss:.4f}, KL Loss: {kl_loss:.4f}, Classification Loss: {classification_loss:.4f}, Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vae.encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: -761.5660, Reconstruction Loss: -793.2894, KL Loss: 11.8450, Classification Loss: 19.8784, Accuracy: 0.6607\n",
      "Epoch 2/20, Loss: -881.3574, Reconstruction Loss: -900.8885, KL Loss: 11.8449, Classification Loss: 7.6863, Accuracy: 0.9647\n",
      "Epoch 3/20, Loss: -886.9457, Reconstruction Loss: -901.7296, KL Loss: 11.8457, Classification Loss: 2.9383, Accuracy: 0.9937\n",
      "Epoch 4/20, Loss: -890.6945, Reconstruction Loss: -903.9433, KL Loss: 11.8450, Classification Loss: 1.4038, Accuracy: 0.9972\n",
      "Epoch 5/20, Loss: -892.9047, Reconstruction Loss: -905.6719, KL Loss: 11.8457, Classification Loss: 0.9215, Accuracy: 0.9966\n",
      "Epoch 6/20, Loss: -892.1259, Reconstruction Loss: -904.5294, KL Loss: 11.8451, Classification Loss: 0.5584, Accuracy: 0.9982\n",
      "Epoch 7/20, Loss: -920.7406, Reconstruction Loss: -932.9480, KL Loss: 11.8455, Classification Loss: 0.3619, Accuracy: 0.9991\n",
      "Epoch 8/20, Loss: -949.6988, Reconstruction Loss: -961.8402, KL Loss: 11.8451, Classification Loss: 0.2962, Accuracy: 0.9989\n",
      "Epoch 9/20, Loss: -949.3312, Reconstruction Loss: -961.4129, KL Loss: 11.8454, Classification Loss: 0.2363, Accuracy: 0.9989\n",
      "Epoch 10/20, Loss: -949.5869, Reconstruction Loss: -961.6069, KL Loss: 11.8455, Classification Loss: 0.1745, Accuracy: 0.9991\n",
      "Epoch 11/20, Loss: -949.9974, Reconstruction Loss: -961.9511, KL Loss: 11.8452, Classification Loss: 0.1086, Accuracy: 0.9996\n",
      "Epoch 12/20, Loss: -949.4388, Reconstruction Loss: -961.4040, KL Loss: 11.8451, Classification Loss: 0.1201, Accuracy: 0.9991\n",
      "Epoch 13/20, Loss: -949.8620, Reconstruction Loss: -961.7876, KL Loss: 11.8452, Classification Loss: 0.0805, Accuracy: 0.9997\n",
      "Epoch 14/20, Loss: -949.8754, Reconstruction Loss: -961.7989, KL Loss: 11.8450, Classification Loss: 0.0784, Accuracy: 0.9995\n",
      "Epoch 15/20, Loss: -949.2684, Reconstruction Loss: -961.2309, KL Loss: 11.8452, Classification Loss: 0.1173, Accuracy: 0.9989\n",
      "Epoch 16/20, Loss: -950.2471, Reconstruction Loss: -962.1476, KL Loss: 11.8452, Classification Loss: 0.0553, Accuracy: 0.9996\n",
      "Epoch 17/20, Loss: -950.2190, Reconstruction Loss: -962.1526, KL Loss: 11.8453, Classification Loss: 0.0883, Accuracy: 0.9993\n",
      "Epoch 18/20, Loss: -950.4585, Reconstruction Loss: -962.3578, KL Loss: 11.8453, Classification Loss: 0.0540, Accuracy: 0.9995\n",
      "Epoch 19/20, Loss: -950.3349, Reconstruction Loss: -962.2268, KL Loss: 11.8455, Classification Loss: 0.0464, Accuracy: 0.9996\n",
      "Epoch 20/20, Loss: -949.7647, Reconstruction Loss: -961.6430, KL Loss: 11.8453, Classification Loss: 0.0330, Accuracy: 0.9998\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "num_epochs = 20\n",
    "vae_new = VAE_Tabnet_MLPS(vae.encoder, vae.decoder, vae.classifier).to(device)\n",
    "for param in vae_new.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, vae_new.parameters()), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    vae_new.train()\n",
    "    train_loss = 0\n",
    "    rec_loss = 0\n",
    "    kl_loss = 0\n",
    "    classification_loss = 0\n",
    "    accuracy = 0\n",
    "\n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        results = vae_new.train_step(batch_data, batch_labels, optimizer)\n",
    "        \n",
    "        train_loss += results[\"loss\"]\n",
    "        rec_loss += results[\"reconstruction_loss\"]\n",
    "        kl_loss += results[\"kl_loss\"]\n",
    "        classification_loss += results[\"classification_loss\"]\n",
    "        accuracy += results[\"accuracy\"]\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    rec_loss /= len(train_loader)\n",
    "    kl_loss /= len(train_loader)\n",
    "    classification_loss /= len(train_loader)\n",
    "    accuracy /= len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Reconstruction Loss: {rec_loss:.4f}, KL Loss: {kl_loss:.4f}, Classification Loss: {classification_loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleDiffusionModel(nn.Module):\n",
    "    def __init__(self, latent_dim, time_steps=1000):\n",
    "        super().__init__()\n",
    "        self.time_steps = time_steps\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Tạo các beta_schedule tuyến tính\n",
    "        beta = torch.linspace(0.0001, 0.02, time_steps)\n",
    "        alpha = 1. - beta\n",
    "        alpha_bar = torch.cumprod(alpha, dim=0)\n",
    "\n",
    "        self.register_buffer('beta', beta)\n",
    "        self.register_buffer('alpha', alpha)\n",
    "        self.register_buffer('alpha_bar', alpha_bar)\n",
    "\n",
    "        # Mạng neural đơn giản để dự đoán nhiễu\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim + 1, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, latent_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, z, t):\n",
    "        noise = torch.randn_like(z)\n",
    "        \n",
    "        # Đảm bảo t là long type và shape phù hợp\n",
    "        if isinstance(t, torch.Tensor):\n",
    "            t = t.to(dtype=torch.long)\n",
    "        else:\n",
    "            t = torch.tensor([t], device=z.device, dtype=torch.long).expand(z.shape[0])\n",
    "\n",
    "        sqrt_alpha_bar = torch.sqrt(self.alpha_bar[t])[:, None]\n",
    "        sqrt_one_minus_alpha_bar = torch.sqrt(1 - self.alpha_bar[t])[:, None]\n",
    "        noisy_z = sqrt_alpha_bar * z + sqrt_one_minus_alpha_bar * noise\n",
    "\n",
    "        predicted_noise = self.model(torch.cat([noisy_z, t.unsqueeze(1)], dim=1))\n",
    "        loss = F.mse_loss(predicted_noise, noise)\n",
    "        return loss\n",
    "\n",
    "    def sample(self, num_samples):\n",
    "        z = torch.randn(num_samples, self.latent_dim).to(next(self.parameters()).device)\n",
    "        for i in reversed(range(self.time_steps)):\n",
    "            t = torch.full((num_samples,), i, device=z.device, dtype=torch.long)\n",
    "            z = self.denoise_step(z, t)\n",
    "        return z\n",
    "    \n",
    "    def denoise_step(self, z, t):\n",
    "        timestep = t.item() if isinstance(t, torch.Tensor) else t\n",
    "        t_batch = torch.full((z.shape[0],), timestep, device=z.device, dtype=torch.long)\n",
    "\n",
    "        predicted_noise = self.model(torch.cat([z, t_batch.unsqueeze(1)], dim=1))\n",
    "\n",
    "        alpha = self.alpha[timestep]\n",
    "        alpha_bar = self.alpha_bar[timestep]\n",
    "        beta = self.beta[timestep]\n",
    "\n",
    "        z = (1 / torch.sqrt(alpha)) * (z - ((1 - alpha) / torch.sqrt(1 - alpha_bar)) * predicted_noise)\n",
    "        if timestep > 0:\n",
    "            noise = torch.randn_like(z)\n",
    "            z += torch.sqrt(beta) * noise\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    vae_new.encoder.eval()\n",
    "    dummy_input = torch.randn(1, input_dim).to(device)  # Thay input_dim theo đúng dữ liệu của bạn\n",
    "    dummy_labels = torch.zeros(1, dtype=torch.long).to(device)\n",
    "    z_mean, z_log_var, _ = vae_new.encoder(dummy_input, dummy_labels)\n",
    "    latent_dim = z_mean.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_dim = vae.encoder[-1].out_features  # Kích thước latent z\n",
    "diffusion_model = SimpleDiffusionModel(latent_dim=latent_dim).to(device)\n",
    "diffusion_optimizer = torch.optim.Adam(diffusion_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_diffusion(vae, diffusion_model, dataloader, optimizer, device, time_steps=1000, epochs=150):\n",
    "    diffusion_model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_data, batch_labels in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                z_mean, z_log_var, z = vae.encoder(batch_data, batch_labels)\n",
    "\n",
    "            t = torch.randint(0, time_steps, (z.shape[0],), device=device).long()\n",
    "            loss = diffusion_model(z, t)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Diffusion Loss: {total_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score\n",
    "def evaluate_diffusion_with_classifier(vae, diffusion_model, classifier, test_loader, device, time_steps=1000):\n",
    "    vae.eval()\n",
    "    diffusion_model.eval()\n",
    "    classifier.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data, batch_labels in test_loader:\n",
    "            batch_data = batch_data.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # Lấy z từ encoder\n",
    "            z_mean, z_log_var, z = vae.encoder(batch_data, batch_labels)\n",
    "\n",
    "            # Forward diffusion\n",
    "            t_forward = time_steps - 1\n",
    "            sqrt_alpha_bar = torch.sqrt(diffusion_model.alpha_bar[t_forward])\n",
    "            sqrt_one_minus_alpha_bar = torch.sqrt(1 - diffusion_model.alpha_bar[t_forward])\n",
    "            noisy_z = sqrt_alpha_bar * z + sqrt_one_minus_alpha_bar * torch.randn_like(z)\n",
    "\n",
    "            # Reverse diffusion (hoàn nhiễu)\n",
    "            z_recovered = noisy_z\n",
    "            for t in reversed(range(time_steps)):\n",
    "                z_recovered = diffusion_model.denoise_step(z_recovered, t)\n",
    "\n",
    "            # Phân loại trên z đã hoàn nhiễu\n",
    "            logits = classifier(z_recovered)\n",
    "\n",
    "            # Kiểm tra shape của logits\n",
    "            print(\"Logits shape:\", logits.shape)  # Debug\n",
    "\n",
    "            if len(logits.shape) == 1:\n",
    "                # Trường hợp: binary classification với output shape [batch_size]\n",
    "                preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            elif len(logits.shape) == 2:\n",
    "                # Trường hợp: multi-class classification\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected logits shape: {logits.shape}\")\n",
    "\n",
    "            # Chuyển về CPU và numpy để dùng với sklearn\n",
    "            preds = preds.cpu().numpy().flatten()\n",
    "            labels = batch_labels.squeeze().cpu().numpy().flatten()\n",
    "\n",
    "            # Lưu lại cho metrics\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    # Tính và in các chỉ số\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "    # Nếu bạn muốn trả về thêm các chỉ số cụ thể:\n",
    "    accuracy = sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "    f1 = f1_score(all_labels, all_preds, average='binary' if len(np.unique(all_labels)) == 2 else 'macro')\n",
    "    precision = precision_score(all_labels, all_preds, average='binary' if len(np.unique(all_labels)) == 2 else 'macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='binary' if len(np.unique(all_labels)) == 2 else 'macro')\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_score\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 608/608 [00:06<00:00, 93.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Diffusion Loss: 3.1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 608/608 [00:08<00:00, 67.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Diffusion Loss: 0.2457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 608/608 [00:08<00:00, 70.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Diffusion Loss: 0.1788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 608/608 [00:08<00:00, 71.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Diffusion Loss: 0.1974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 608/608 [00:08<00:00, 70.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Diffusion Loss: 0.2086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 608/608 [00:08<00:00, 72.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Diffusion Loss: 0.1986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 608/608 [00:07<00:00, 77.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Diffusion Loss: 0.1836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 608/608 [00:07<00:00, 78.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Diffusion Loss: 0.1736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 608/608 [00:09<00:00, 67.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Diffusion Loss: 0.1779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 608/608 [00:09<00:00, 61.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Diffusion Loss: 0.1689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 608/608 [00:09<00:00, 64.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Diffusion Loss: 0.1722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 608/608 [00:09<00:00, 64.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Diffusion Loss: 0.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 608/608 [00:09<00:00, 65.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Diffusion Loss: 0.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 608/608 [00:09<00:00, 66.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Diffusion Loss: 0.1397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 608/608 [00:08<00:00, 67.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Diffusion Loss: 0.1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 608/608 [00:08<00:00, 71.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Diffusion Loss: 0.1305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 608/608 [00:08<00:00, 73.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Diffusion Loss: 0.1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 608/608 [00:07<00:00, 78.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Diffusion Loss: 0.1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 608/608 [00:07<00:00, 78.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Diffusion Loss: 0.1205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 608/608 [00:08<00:00, 70.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Diffusion Loss: 0.1171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 608/608 [00:08<00:00, 68.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Diffusion Loss: 0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 608/608 [00:08<00:00, 71.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Diffusion Loss: 0.1170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 608/608 [00:09<00:00, 64.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Diffusion Loss: 0.1132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 608/608 [00:08<00:00, 68.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Diffusion Loss: 0.1118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 608/608 [00:08<00:00, 75.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Diffusion Loss: 0.1096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 608/608 [00:07<00:00, 76.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Diffusion Loss: 0.1083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 608/608 [00:08<00:00, 72.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Diffusion Loss: 0.1070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 608/608 [00:10<00:00, 60.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Diffusion Loss: 0.1089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 608/608 [00:09<00:00, 63.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Diffusion Loss: 0.1059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 608/608 [00:09<00:00, 65.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Diffusion Loss: 0.1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 608/608 [00:09<00:00, 66.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Diffusion Loss: 0.1022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 608/608 [00:06<00:00, 95.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Diffusion Loss: 0.1023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 608/608 [00:06<00:00, 94.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Diffusion Loss: 0.1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 608/608 [00:06<00:00, 99.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Diffusion Loss: 0.0997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 608/608 [00:06<00:00, 93.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Diffusion Loss: 0.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 608/608 [00:07<00:00, 81.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Diffusion Loss: 0.0997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 608/608 [00:08<00:00, 73.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Diffusion Loss: 0.0987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 608/608 [00:07<00:00, 76.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Diffusion Loss: 0.0972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 608/608 [00:06<00:00, 86.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Diffusion Loss: 0.0974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 608/608 [00:05<00:00, 101.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Diffusion Loss: 0.0965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 608/608 [00:05<00:00, 103.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Diffusion Loss: 0.0962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 608/608 [00:05<00:00, 103.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Diffusion Loss: 0.0955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 608/608 [00:05<00:00, 104.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Diffusion Loss: 0.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 608/608 [00:05<00:00, 102.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Diffusion Loss: 0.0941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 608/608 [00:05<00:00, 102.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Diffusion Loss: 0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 608/608 [00:06<00:00, 90.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Diffusion Loss: 0.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 608/608 [00:05<00:00, 103.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Diffusion Loss: 0.0912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 608/608 [00:05<00:00, 102.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Diffusion Loss: 0.0917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 608/608 [00:05<00:00, 106.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Diffusion Loss: 0.0931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 608/608 [00:05<00:00, 105.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Diffusion Loss: 0.0907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 608/608 [00:06<00:00, 101.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Diffusion Loss: 0.0898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 608/608 [00:05<00:00, 105.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Diffusion Loss: 0.0898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 608/608 [00:05<00:00, 103.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Diffusion Loss: 0.0916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 608/608 [00:05<00:00, 104.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Diffusion Loss: 0.0889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 608/608 [00:06<00:00, 100.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Diffusion Loss: 0.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 608/608 [00:06<00:00, 100.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Diffusion Loss: 0.0892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 608/608 [00:06<00:00, 98.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Diffusion Loss: 0.0882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 608/608 [00:06<00:00, 91.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Diffusion Loss: 0.0866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 608/608 [00:08<00:00, 72.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Diffusion Loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 608/608 [00:06<00:00, 96.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Diffusion Loss: 0.0862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 608/608 [00:06<00:00, 100.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61, Diffusion Loss: 0.0864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 608/608 [00:05<00:00, 101.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62, Diffusion Loss: 0.0847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 608/608 [00:06<00:00, 101.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63, Diffusion Loss: 0.0853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|██████████| 608/608 [00:06<00:00, 101.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64, Diffusion Loss: 0.0840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|██████████| 608/608 [00:05<00:00, 103.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, Diffusion Loss: 0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|██████████| 608/608 [00:05<00:00, 102.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, Diffusion Loss: 0.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|██████████| 608/608 [00:05<00:00, 103.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, Diffusion Loss: 0.0842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|██████████| 608/608 [00:06<00:00, 101.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, Diffusion Loss: 0.0836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|██████████| 608/608 [00:05<00:00, 103.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69, Diffusion Loss: 0.0816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|██████████| 608/608 [00:05<00:00, 103.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Diffusion Loss: 0.0827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 608/608 [00:05<00:00, 104.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71, Diffusion Loss: 0.0820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|██████████| 608/608 [00:05<00:00, 103.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72, Diffusion Loss: 0.0804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|██████████| 608/608 [00:05<00:00, 103.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73, Diffusion Loss: 0.0818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|██████████| 608/608 [00:05<00:00, 103.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74, Diffusion Loss: 0.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|██████████| 608/608 [00:05<00:00, 106.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75, Diffusion Loss: 0.0806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|██████████| 608/608 [00:06<00:00, 101.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76, Diffusion Loss: 0.0791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|██████████| 608/608 [00:05<00:00, 104.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77, Diffusion Loss: 0.0817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|██████████| 608/608 [00:05<00:00, 101.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78, Diffusion Loss: 0.0814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|██████████| 608/608 [00:06<00:00, 100.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79, Diffusion Loss: 0.0796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|██████████| 608/608 [00:05<00:00, 103.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Diffusion Loss: 0.0804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 608/608 [00:05<00:00, 105.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81, Diffusion Loss: 0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|██████████| 608/608 [00:05<00:00, 103.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82, Diffusion Loss: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|██████████| 608/608 [00:05<00:00, 102.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83, Diffusion Loss: 0.0787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|██████████| 608/608 [00:05<00:00, 104.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84, Diffusion Loss: 0.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|██████████| 608/608 [00:05<00:00, 104.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85, Diffusion Loss: 0.0791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|██████████| 608/608 [00:05<00:00, 103.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86, Diffusion Loss: 0.0793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|██████████| 608/608 [00:05<00:00, 102.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, Diffusion Loss: 0.0806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|██████████| 608/608 [00:05<00:00, 102.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88, Diffusion Loss: 0.0783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|██████████| 608/608 [00:05<00:00, 103.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, Diffusion Loss: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|██████████| 608/608 [00:05<00:00, 101.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Diffusion Loss: 0.0773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 608/608 [00:05<00:00, 102.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91, Diffusion Loss: 0.0764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|██████████| 608/608 [00:05<00:00, 104.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92, Diffusion Loss: 0.0778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|██████████| 608/608 [00:05<00:00, 102.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93, Diffusion Loss: 0.0779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|██████████| 608/608 [00:05<00:00, 104.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94, Diffusion Loss: 0.0774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|██████████| 608/608 [00:06<00:00, 101.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95, Diffusion Loss: 0.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|██████████| 608/608 [00:06<00:00, 97.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96, Diffusion Loss: 0.0770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|██████████| 608/608 [00:06<00:00, 95.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97, Diffusion Loss: 0.0749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|██████████| 608/608 [00:06<00:00, 95.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98, Diffusion Loss: 0.0762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|██████████| 608/608 [00:06<00:00, 101.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99, Diffusion Loss: 0.0763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 608/608 [00:06<00:00, 96.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Diffusion Loss: 0.0763\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([32, 1])\n",
      "Logits shape: torch.Size([1, 1])\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      4782\n",
      "           1       0.00      0.00      0.00       307\n",
      "\n",
      "    accuracy                           0.94      5089\n",
      "   macro avg       0.47      0.50      0.48      5089\n",
      "weighted avg       0.88      0.94      0.91      5089\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4782    0]\n",
      " [ 307    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Admin\\miniconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9396738062487718,\n",
       " 'f1_score': 0.0,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# latent_dim = vae.encoder[-1].out_features\n",
    "diffusion_model = SimpleDiffusionModel(latent_dim=latent_dim).to(device)\n",
    "diffusion_optimizer = optim.Adam(diffusion_model.parameters(), lr=1e-3)\n",
    "\n",
    "train_diffusion(vae_new, diffusion_model, train_loader, diffusion_optimizer, device, epochs=100)\n",
    "\n",
    "eval =evaluate_diffusion_with_classifier(vae_new, diffusion_model, vae.classifier, test_loader, device)\n",
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
