{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b1aa9a8-fdc3-47d7-a89a-8f5d01655b00",
   "metadata": {},
   "source": [
    "## General information\n",
    "\n",
    "In this kernel I work with IEEE Fraud Detection competition.\n",
    "\n",
    "EEE-CIS works across a variety of AI and machine learning areas, including deep neural networks, fuzzy systems, evolutionary computation, and swarm intelligence. Today they’re partnering with the world’s leading payment service company, Vesta Corporation, seeking the best solutions for fraud prevention industry, and now you are invited to join the challenge.\n",
    "\n",
    "We have a binary classification problem with a heavy imbalance which is an inherent property of such problems.\n",
    "At first I'll explore the data and try to find valuable insights, maybe I'll do some feature engineering and then it wil be time to build models.\n",
    "\n",
    "![](https://cis.ieee.org/images/files/slideshow/abstract01.jpg)\n",
    "\n",
    "*Work in progress*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b90be3-d0ab-4198-ad56-1acc7b788f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\Data\\ads_fraud_detection\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "__script_path=os.path.abspath(globals().get('__file__','.'))\n",
    "__script_dir = os.path.dirname(__script_path)\n",
    "root_dir = os.path.abspath(f'{__script_dir}/../..')\n",
    "print(root_dir)\n",
    "for lib in [root_dir][::-1]:\n",
    "    if lib in sys.path:\n",
    "        sys.path.remove(lib)\n",
    "    sys.path.insert(0,lib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f331d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/Users/PC/Data/ads_fraud_detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\PC\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\PC\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (c:\\Users\\PC\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\preprocessing\\sequence.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlibs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#init_notebook_mode(connected=True)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;66;03m# requires version >= 1.9.0\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\libs\\common.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model, Sequential\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregularizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m l2\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'pad_sequences' from 'keras.preprocessing.sequence' (c:\\Users\\PC\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\keras\\preprocessing\\sequence.py)"
     ]
    }
   ],
   "source": [
    "from config.config import *\n",
    "from libs.common import *\n",
    "#init_notebook_mode(connected=True)\n",
    "print(tf.__version__) # requires version >= 1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c883be51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBLIB_TEMP_FOLDER=/tmp\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import eli5\n",
    "import shap\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "# import altair as alt\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# alt.renderers.enable('notebook')\n",
    "\n",
    "%env JOBLIB_TEMP_FOLDER=/tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97348d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import gc\n",
    "from numba import jit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "# import altair as alt\n",
    "# from altair.vega import v5\n",
    "from IPython.display import HTML\n",
    "\n",
    "# using ideas from this kernel: https://www.kaggle.com/notslush/altair-visualization-2018-stackoverflow-survey\n",
    "def prepare_altair():\n",
    "    \"\"\"\n",
    "    Helper function to prepare altair for working.\n",
    "    \"\"\"\n",
    "\n",
    "    vega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v5.SCHEMA_VERSION\n",
    "    vega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\n",
    "    vega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\n",
    "    vega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\n",
    "    noext = \"?noext\"\n",
    "    \n",
    "    paths = {\n",
    "        'vega': vega_url + noext,\n",
    "        'vega-lib': vega_lib_url + noext,\n",
    "        'vega-lite': vega_lite_url + noext,\n",
    "        'vega-embed': vega_embed_url + noext\n",
    "    }\n",
    "    \n",
    "    workaround = f\"\"\"    requirejs.config({{\n",
    "        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
    "        paths: {paths}\n",
    "    }});\n",
    "    \"\"\"\n",
    "    \n",
    "    return workaround\n",
    "    \n",
    "\n",
    "def add_autoincrement(render_func):\n",
    "    # Keep track of unique <div/> IDs\n",
    "    cache = {}\n",
    "    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n",
    "        if autoincrement:\n",
    "            if id in cache:\n",
    "                counter = 1 + cache[id]\n",
    "                cache[id] = counter\n",
    "            else:\n",
    "                cache[id] = 0\n",
    "            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n",
    "        else:\n",
    "            if id not in cache:\n",
    "                cache[id] = 0\n",
    "            actual_id = id\n",
    "        return render_func(chart, id=actual_id)\n",
    "    # Cache will stay outside and \n",
    "    return wrapped\n",
    "           \n",
    "\n",
    "@add_autoincrement\n",
    "def render(chart, id=\"vega-chart\"):\n",
    "    \"\"\"\n",
    "    Helper function to plot altair visualizations.\n",
    "    \"\"\"\n",
    "    chart_str = \"\"\"\n",
    "    <div id=\"{id}\"></div><script>\n",
    "    require([\"vega-embed\"], function(vg_embed) {{\n",
    "        const spec = {chart};     \n",
    "        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n",
    "        console.log(\"anything?\");\n",
    "    }});\n",
    "    console.log(\"really...anything?\");\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    return HTML(\n",
    "        chart_str.format(\n",
    "            id=id,\n",
    "            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage(deep=True).sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "    \n",
    "\n",
    "@jit\n",
    "def fast_auc(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    fast roc_auc computation: https://www.kaggle.com/c/microsoft-malware-prediction/discussion/76013\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    nfalse = 0\n",
    "    auc = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n):\n",
    "        y_i = y_true[i]\n",
    "        nfalse += (1 - y_i)\n",
    "        auc += y_i * nfalse\n",
    "    auc /= (nfalse * (n - nfalse))\n",
    "    return auc\n",
    "\n",
    "\n",
    "def eval_auc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast auc eval function for lgb.\n",
    "    \"\"\"\n",
    "    return 'auc', fast_auc(y_true, y_pred), True\n",
    "\n",
    "\n",
    "def group_mean_log_mae(y_true, y_pred, types, floor=1e-9):\n",
    "    \"\"\"\n",
    "    Fast metric computation for this competition: https://www.kaggle.com/c/champs-scalar-coupling\n",
    "    Code is from this kernel: https://www.kaggle.com/uberkinder/efficient-metric\n",
    "    \"\"\"\n",
    "    maes = (y_true-y_pred).abs().groupby(types).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, floor))).mean()\n",
    "    \n",
    "\n",
    "def train_model_regression(X, X_test, y, params, folds=None, model_type='lgb', eval_metric='mae', columns=None, plot_feature_importance=False, model=None,\n",
    "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000, splits=None, n_folds=3):\n",
    "    \"\"\"\n",
    "    A function to train a variety of regression models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns is None else columns\n",
    "    X_test = X_test[columns]\n",
    "    splits = folds.split(X) if splits is None else splits\n",
    "    n_splits = folds.n_splits if splits is None else n_folds\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'sklearn_scoring_function': metrics.mean_absolute_error},\n",
    "                    'group_mae': {'lgb_metric_name': 'mae',\n",
    "                        'catboost_metric_name': 'MAE',\n",
    "                        'scoring_function': group_mean_log_mae},\n",
    "                    'mse': {'lgb_metric_name': 'mse',\n",
    "                        'catboost_metric_name': 'MSE',\n",
    "                        'sklearn_scoring_function': metrics.mean_squared_error}\n",
    "                    }\n",
    "\n",
    "    \n",
    "    result_dict = {}\n",
    "    \n",
    "    # out-of-fold predictions on train data\n",
    "    oof = np.zeros(len(X))\n",
    "    \n",
    "    # averaged predictions on train data\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "        if verbose:\n",
    "            print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMRegressor(**params, n_estimators = n_estimators, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict(X_test).reshape(-1,)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostRegressor(iterations=20000,  eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        if eval_metric != 'group_mae':\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "        else:\n",
    "            scores.append(metrics_dict[eval_metric]['scoring_function'](y_valid, y_pred_valid, X_valid['type']))\n",
    "\n",
    "        prediction += y_pred    \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_splits\n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "        \n",
    "    return result_dict\n",
    "    \n",
    "\n",
    "\n",
    "def train_model_classification(X, X_test, y, params, folds, model_type='lgb', eval_metric='auc', columns=None, plot_feature_importance=False, model=None,\n",
    "                               verbose=10000, early_stopping_rounds=200, n_estimators=50000, splits=None, n_folds=3, averaging='usual', n_jobs=-1):\n",
    "    \"\"\"\n",
    "    A function to train a variety of classification models.\n",
    "    Returns dictionary with oof predictions, test predictions, scores and, if necessary, feature importances.\n",
    "    \n",
    "    :params: X - training data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: X_test - test data, can be pd.DataFrame or np.ndarray (after normalizing)\n",
    "    :params: y - target\n",
    "    :params: folds - folds to split data\n",
    "    :params: model_type - type of model to use\n",
    "    :params: eval_metric - metric to use\n",
    "    :params: columns - columns to use. If None - use all columns\n",
    "    :params: plot_feature_importance - whether to plot feature importance of LGB\n",
    "    :params: model - sklearn model, works only for \"sklearn\" model type\n",
    "    \n",
    "    \"\"\"\n",
    "    columns = X.columns if columns is None else columns\n",
    "    n_splits = folds.n_splits if splits is None else n_folds\n",
    "    X_test = X_test[columns]\n",
    "    \n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {'auc': {'lgb_metric_name': eval_auc,\n",
    "                        'catboost_metric_name': 'AUC',\n",
    "                        'sklearn_scoring_function': metrics.roc_auc_score},\n",
    "                    }\n",
    "    \n",
    "    result_dict = {}\n",
    "    if averaging == 'usual':\n",
    "        # out-of-fold predictions on train data\n",
    "        oof = np.zeros((len(X), 1))\n",
    "\n",
    "        # averaged predictions on train data\n",
    "        prediction = np.zeros((len(X_test), 1))\n",
    "        \n",
    "    elif averaging == 'rank':\n",
    "        # out-of-fold predictions on train data\n",
    "        oof = np.zeros((len(X), 1))\n",
    "\n",
    "        # averaged predictions on train data\n",
    "        prediction = np.zeros((len(X_test), 1))\n",
    "\n",
    "    \n",
    "    # list of scores on folds\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "        print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[columns][train_index], X[columns][valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "            \n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMClassifier(**params, n_estimators=n_estimators, n_jobs = n_jobs)\n",
    "            model.fit(X_train, y_train, \n",
    "                    eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                    verbose=verbose, early_stopping_rounds=early_stopping_rounds)\n",
    "            \n",
    "            y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)[:, 1]\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=n_estimators, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)\n",
    "        \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=n_estimators, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'], **params,\n",
    "                                      loss_function=Logloss)\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        if averaging == 'usual':\n",
    "            \n",
    "            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "            \n",
    "            prediction += y_pred.reshape(-1, 1)\n",
    "\n",
    "        elif averaging == 'rank':\n",
    "                                  \n",
    "            oof[valid_index] = y_pred_valid.reshape(-1, 1)\n",
    "            scores.append(metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid))\n",
    "                                  \n",
    "            prediction += pd.Series(y_pred).rank().values.reshape(-1, 1)        \n",
    "        \n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_splits\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "            \n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "            result_dict['top_columns'] = cols\n",
    "        \n",
    "    return result_dict\n",
    "\n",
    "# setting up altair\n",
    "# workaround = prepare_altair()\n",
    "# HTML(\"\".join((\n",
    "#     \"<script>\",\n",
    "#     workaround,\n",
    "#     \"</script>\",\n",
    "# )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ee48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=f\"{exps_dir}/exp3\"\n",
    "if os.path.exists(save_dir) == False: \n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfad7f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data download location c:\\Users\\PC\\Data\\ads_fraud_detection\\src\\prj3\\1.EDA\\tmp\n"
     ]
    },
    {
     "ename": "ApiException",
     "evalue": "(403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'Content-Type': 'application/json', 'Date': 'Wed, 30 Apr 2025 14:32:09 GMT', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Origin': '*', 'Set-Cookie': 'ka_sessionid=80db718ea611da87f9576bb2c16dcca9; max-age=2626560; path=/, .AspNetCore.Mvc.CookieTempDataProvider=CfDJ8HYJ4SW6YXhJj8CRciRldeTbp88Uv-3oi16H62mMUWCZhfaU3zJrLzUM-QCE5jciFXShSXOb8aQGL22piMurMa3dD4D94r6zE0hLNXv4Afg2UPhCfx7RgEgJsMKTHIFCHtPvwkDZMHYTfFG90VRrguEGer4S0mHanDIA1po-tTSrszqlK12kmy8wM1wxWyHUvsT7OtGLe6cb30baxqSPx4iXzOM6zVQJZ7FIxH6mdYGFH81NFEHY_3pYa2Xp4kjs7tOHhYUOC9VitQ; path=/; samesite=lax; httponly, GCLB=CKzWruCh7MrulgEQAw; path=/; HttpOnly', 'Vary': 'Accept-Encoding', 'X-Kaggle-MillisecondsElapsed': '13', 'X-Kaggle-RequestId': 'ff0d012147eb92fcac625a3f78b0125a', 'X-Kaggle-ApiVersion': '1.7.4.2', 'X-Kaggle-HubVersion': '0.3.12', 'X-Frame-Options': 'SAMEORIGIN', 'Strict-Transport-Security': 'max-age=63072000; includeSubDomains; preload', 'Content-Security-Policy': \"object-src 'none'; script-src 'nonce-12gD2URtfe8yKMFD2p5DWw==' 'report-sample' 'unsafe-inline' 'unsafe-eval' 'strict-dynamic' https: http:; base-uri 'none'; report-uri https://csp.withgoogle.com/csp/kaggle/20201130; frame-src 'self' https://www.kaggleusercontent.com https://www.youtube.com/embed/ https://polygraph-cool.github.io https://www.google.com/recaptcha/ https://www.docdroid.com https://www.docdroid.net https://kaggle-static.storage.googleapis.com https://kkb-production.jupyter-proxy.kaggle.net https://kkb-production.firebaseapp.com https://kaggle-metastore.firebaseapp.com https://apis.google.com https://content-sheets.googleapis.com/ https://accounts.google.com/ https://storage.googleapis.com https://docs.google.com https://drive.google.com https://calendar.google.com/ https://google.qualtrics.com/ ;\", 'X-Content-Type-Options': 'nosniff', 'Referrer-Policy': 'strict-origin-when-cross-origin', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'Transfer-Encoding': 'chunked'})\nHTTP response body: b'{\"code\":403,\"message\":\"You must accept this competition\\\\u0027s rules before you\\\\u0027ll be able to download files.\"}'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mApiException\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# all_keys = ['fakejob', 'vehicleloan', 'malurl', 'ieeecis', 'ccfraud', 'fraudecom', 'twitterbot', 'ipblock'] \u001b[39;00m\n\u001b[0;32m      4\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mieeecis\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43mFraudDatasetBenchmark\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_pre_downloaded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelete_downloaded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_random_values_if_real_na\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEVENT_TIMESTAMP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLABEL_TIMESTAMP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mENTITY_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mENTITY_TYPE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mENTITY_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEVENT_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# default\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(obj\u001b[38;5;241m.\u001b[39mkey)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain set: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\fdb\\datasets.py:20\u001b[0m, in \u001b[0;36mFraudDatasetBenchmark.__init__\u001b[1;34m(self, key, load_pre_downloaded, delete_downloaded, add_random_values_if_real_na)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m      9\u001b[0m     key, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEVENT_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     18\u001b[0m         }):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m key\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_pre_downloaded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelete_downloaded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_random_values_if_real_na\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\fdb\\preprocessing_objects.py:41\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(key, load_pre_downloaded, delete_downloaded, add_random_values_if_real_na)\u001b[0m\n\u001b[0;32m     32\u001b[0m     obj \u001b[38;5;241m=\u001b[39m MalurlPreProcessor(\n\u001b[0;32m     33\u001b[0m         train_percentage \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.9\u001b[39m,\n\u001b[0;32m     34\u001b[0m         timestamp_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcommon_kw\n\u001b[0;32m     38\u001b[0m     )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mieeecis\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 41\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mIEEEPreProcessor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_percentage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimestamp_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtransactiondt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43misfraud\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevent_id_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mentity_id_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# manually created in code\u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcommon_kw\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccfraud\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     51\u001b[0m     obj \u001b[38;5;241m=\u001b[39m CCFraudPreProcessor(\n\u001b[0;32m     52\u001b[0m         train_percentage \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m,\n\u001b[0;32m     53\u001b[0m         timestamp_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcommon_kw\n\u001b[0;32m     57\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\fdb\\preprocessing.py:313\u001b[0m, in \u001b[0;36mIEEEPreProcessor.__init__\u001b[1;34m(self, **kw)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mIEEEPreProcessor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\fdb\\preprocessing.py:87\u001b[0m, in \u001b[0;36mBasePreProcessor.__init__\u001b[1;34m(self, key, train_percentage, timestamp_col, label_col, label_timestamp_col, event_id_col, entity_id_col, features_to_drop, load_pre_downloaded, delete_downloaded, add_random_values_if_real_na)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Simply get all required objects at the time of object creation\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m KAGGLE_CONFIGS\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m load_pre_downloaded:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_kaggle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# download the data when an object is created\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess()\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\fdb\\preprocessing.py:134\u001b[0m, in \u001b[0;36mBasePreProcessor.download_kaggle_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData download location\u001b[39m\u001b[38;5;124m'\u001b[39m, _DOWNLOAD_LOCATION)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m KAGGLE_CONFIGS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey][_TYPE] \u001b[38;5;241m==\u001b[39m _COMPETITIONS:\n\u001b[1;32m--> 134\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_kaggle_data_from_competetions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m KAGGLE_CONFIGS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey][_TYPE] \u001b[38;5;241m==\u001b[39m _DATASETS:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;66;03m# If filename is given, download single file,\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# Else download all files.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m KAGGLE_CONFIGS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey]\u001b[38;5;241m.\u001b[39mget(_FILENAME):\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\fdb\\preprocessing.py:95\u001b[0m, in \u001b[0;36mBasePreProcessor._download_kaggle_data_from_competetions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download_kaggle_data_from_competetions\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     94\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m KAGGLE_CONFIGS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey][_OWNER]\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mkaggle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompetition_download_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompetition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mKAGGLE_CONFIGS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_OWNER\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_DOWNLOAD_LOCATION\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file_name\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py:998\u001b[0m, in \u001b[0;36mKaggleApi.competition_download_files\u001b[1;34m(self, competition, path, force, quiet)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    995\u001b[0m     effective_path \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    997\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response(\n\u001b[1;32m--> 998\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompetitions_data_download_files_with_http_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompetition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1000\u001b[0m url \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mretries\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mredirect_location\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1001\u001b[0m outfile \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(effective_path,\n\u001b[0;32m   1002\u001b[0m                        competition \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m url\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\kaggle\\api\\kaggle_api.py:384\u001b[0m, in \u001b[0;36mKaggleApi.competitions_data_download_files_with_http_info\u001b[1;34m(self, id, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# Authentication setting\u001b[39;00m\n\u001b[0;32m    382\u001b[0m auth_settings \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasicAuth\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m--> 384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/competitions/data/download-all/\u001b[39;49m\u001b[38;5;132;43;01m{id}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mform_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResult\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[0;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43masync_req\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_return_http_data_only\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_preload_content\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_request_timeout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_formats\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\kaggle\\api_client.py:313\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03mTo make an async request, set the async_req parameter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m    then the method will return the response directly.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    320\u001b[0m     thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api, (resource_path,\n\u001b[0;32m    321\u001b[0m                                    method, path_params, query_params,\n\u001b[0;32m    322\u001b[0m                                    header_params, body,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    326\u001b[0m                                    collection_formats,\n\u001b[0;32m    327\u001b[0m                                    _preload_content, _request_timeout))\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\kaggle\\api_client.py:145\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[1;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    142\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfiguration\u001b[38;5;241m.\u001b[39mhost \u001b[38;5;241m+\u001b[39m resource_path\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_data\n\u001b[0;32m    153\u001b[0m return_data \u001b[38;5;241m=\u001b[39m response_data\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\kaggle\\api_client.py:335\u001b[0m, in \u001b[0;36mApiClient.request\u001b[1;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Makes the HTTP request using RESTClient.\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mHEAD(url,\n\u001b[0;32m    342\u001b[0m                                  query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[0;32m    343\u001b[0m                                  _preload_content\u001b[38;5;241m=\u001b[39m_preload_content,\n\u001b[0;32m    344\u001b[0m                                  _request_timeout\u001b[38;5;241m=\u001b[39m_request_timeout,\n\u001b[0;32m    345\u001b[0m                                  headers\u001b[38;5;241m=\u001b[39mheaders)\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\kaggle\\rest.py:231\u001b[0m, in \u001b[0;36mRESTClientObject.GET\u001b[1;34m(self, url, headers, query_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGET\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, query_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    230\u001b[0m         _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Data\\ads_fraud_detection\\.conda\\lib\\site-packages\\kaggle\\rest.py:225\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[1;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[0;32m    222\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse body: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, r\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m299\u001b[39m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[1;31mApiException\u001b[0m: (403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'Content-Type': 'application/json', 'Date': 'Wed, 30 Apr 2025 14:32:09 GMT', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Origin': '*', 'Set-Cookie': 'ka_sessionid=80db718ea611da87f9576bb2c16dcca9; max-age=2626560; path=/, .AspNetCore.Mvc.CookieTempDataProvider=CfDJ8HYJ4SW6YXhJj8CRciRldeTbp88Uv-3oi16H62mMUWCZhfaU3zJrLzUM-QCE5jciFXShSXOb8aQGL22piMurMa3dD4D94r6zE0hLNXv4Afg2UPhCfx7RgEgJsMKTHIFCHtPvwkDZMHYTfFG90VRrguEGer4S0mHanDIA1po-tTSrszqlK12kmy8wM1wxWyHUvsT7OtGLe6cb30baxqSPx4iXzOM6zVQJZ7FIxH6mdYGFH81NFEHY_3pYa2Xp4kjs7tOHhYUOC9VitQ; path=/; samesite=lax; httponly, GCLB=CKzWruCh7MrulgEQAw; path=/; HttpOnly', 'Vary': 'Accept-Encoding', 'X-Kaggle-MillisecondsElapsed': '13', 'X-Kaggle-RequestId': 'ff0d012147eb92fcac625a3f78b0125a', 'X-Kaggle-ApiVersion': '1.7.4.2', 'X-Kaggle-HubVersion': '0.3.12', 'X-Frame-Options': 'SAMEORIGIN', 'Strict-Transport-Security': 'max-age=63072000; includeSubDomains; preload', 'Content-Security-Policy': \"object-src 'none'; script-src 'nonce-12gD2URtfe8yKMFD2p5DWw==' 'report-sample' 'unsafe-inline' 'unsafe-eval' 'strict-dynamic' https: http:; base-uri 'none'; report-uri https://csp.withgoogle.com/csp/kaggle/20201130; frame-src 'self' https://www.kaggleusercontent.com https://www.youtube.com/embed/ https://polygraph-cool.github.io https://www.google.com/recaptcha/ https://www.docdroid.com https://www.docdroid.net https://kaggle-static.storage.googleapis.com https://kkb-production.jupyter-proxy.kaggle.net https://kkb-production.firebaseapp.com https://kaggle-metastore.firebaseapp.com https://apis.google.com https://content-sheets.googleapis.com/ https://accounts.google.com/ https://storage.googleapis.com https://docs.google.com https://drive.google.com https://calendar.google.com/ https://google.qualtrics.com/ ;\", 'X-Content-Type-Options': 'nosniff', 'Referrer-Policy': 'strict-origin-when-cross-origin', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'Transfer-Encoding': 'chunked'})\nHTTP response body: b'{\"code\":403,\"message\":\"You must accept this competition\\\\u0027s rules before you\\\\u0027ll be able to download files.\"}'\n"
     ]
    }
   ],
   "source": [
    "from fdb.datasets import FraudDatasetBenchmark\n",
    "\n",
    "# all_keys = ['fakejob', 'vehicleloan', 'malurl', 'ieeecis', 'ccfraud', 'fraudecom', 'twitterbot', 'ipblock'] \n",
    "key = 'ieeecis'\n",
    "\n",
    "obj = FraudDatasetBenchmark(\n",
    "    key=key,\n",
    "    load_pre_downloaded=False,  # default\n",
    "    delete_downloaded=True,  # default\n",
    "    add_random_values_if_real_na = { \n",
    "        \"EVENT_TIMESTAMP\": True, \n",
    "        \"LABEL_TIMESTAMP\": True,\n",
    "        \"ENTITY_ID\": True,\n",
    "        \"ENTITY_TYPE\": True,\n",
    "        \"ENTITY_ID\": True,\n",
    "        \"EVENT_ID\": True\n",
    "        } # default\n",
    "    )\n",
    "print(obj.key)\n",
    "\n",
    "print('Train set: ')\n",
    "display(obj.train.head())\n",
    "print(len(obj.train.columns))\n",
    "print(obj.train.shape)\n",
    "\n",
    "print('Test set: ')\n",
    "display(obj.test.head())\n",
    "print(obj.test.shape)\n",
    "\n",
    "print('Test scores')\n",
    "display(obj.test_labels.head())\n",
    "print(obj.test_labels['EVENT_LABEL'].value_counts())\n",
    "print(obj.train['EVENT_LABEL'].value_counts(normalize=True))\n",
    "print('=========')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9a9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_identity = pd.read_csv(f'{data_dir}/ieee-fraud-detection/train_identity.csv')\n",
    "# train_transaction = pd.read_csv(f'{data_dir}/ieee-fraud-detection/train_transaction.csv')\n",
    "# test_identity = pd.read_csv(f'{data_dir}/ieee-fraud-detection/test_identity.csv')\n",
    "# test_transaction = pd.read_csv(f'{data_dir}/ieee-fraud-detection/test_transaction.csv')\n",
    "# sub = pd.read_csv(f'{data_dir}/ieee-fraud-detection/sample_submission.csv')\n",
    "# # let's combine the data and work with the whole dataset\n",
    "# train = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
    "# test = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda989da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(561013, 72) (29527, 73)\n"
     ]
    }
   ],
   "source": [
    "test = obj.test\n",
    "test = pd.concat([test, obj.test_labels], axis=1)\n",
    "train = obj.train\n",
    "train.drop(columns=['LABEL_TIMESTAMP'], inplace=True) \n",
    "print(train.shape, test.shape)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dd09be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Không có cột nào bị thiếu trong test.\n",
      "Không có cột nào bị thiếu trong train.\n"
     ]
    }
   ],
   "source": [
    "train_cols = set(train.columns)\n",
    "test_cols = set(test.columns)\n",
    "\n",
    "# Cột có trong train nhưng không có trong test\n",
    "missing_in_test = train_cols - test_cols\n",
    "\n",
    "# Cột có trong test nhưng không có trong train\n",
    "missing_in_train = test_cols - train_cols\n",
    "\n",
    "# In kết quả\n",
    "if missing_in_test:\n",
    "    print(\"Cột có trong train nhưng thiếu trong test:\", missing_in_test)\n",
    "else:\n",
    "    print(\"Không có cột nào bị thiếu trong test.\")\n",
    "\n",
    "if missing_in_train:\n",
    "    print(\"Cột có trong test nhưng thiếu trong train:\", missing_in_train)\n",
    "else:\n",
    "    print(\"Không có cột nào bị thiếu trong train.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021997f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset has 561013 rows and 72 columns.\n",
      "Test dataset has 29527 rows and 73 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'Train dataset has {train.shape[0]} rows and {train.shape[1]} columns.')\n",
    "print(f'Test dataset has {test.shape[0]} rows and {test.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a522dfa-8c71-41bd-bf65-bf5eaab00fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51 columns in train dataset with missing values.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {train.isnull().any().sum()} columns in train dataset with missing values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a396fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.columns = [col.upper() for col in train.columns]\n",
    "# test.columns = [col.upper() for col in test.columns]\n",
    "\n",
    "train.rename(columns={\"EVENT_LABEL\": \"isFraud\"}, inplace=True)\n",
    "test.rename(columns={\"EVENT_LABEL\": \"isFraud\"}, inplace=True)\n",
    "# # train.rename(columns={\"ENTITY_ID\": \"UNIQUEID\"}, inplace=True)\n",
    "# # test.rename(columns={\"ENTITY_ID\": \"UNIQUEID\"}, inplace=True)\n",
    "\n",
    "# print(train.columns)\n",
    "# print(test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f32f41-5c71-48bf-b005-4c8c7a7f1504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Thay NaN bằng chuỗi trống để tránh lỗi khi ép kiểu string\n",
    "# one_value_cols_train = [col for col in train.columns if train[col].fillna(\"\").astype(str).nunique() <= 1]\n",
    "# one_value_cols_test = [col for col in test.columns if test[col].fillna(\"\").astype(str).nunique() <= 1]\n",
    "\n",
    "# # So sánh hai danh sách\n",
    "# print(set(one_value_cols_train) == set(one_value_cols_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1f800-41d4-492c-9d3f-ff0ae5f5fa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'There are {len(one_value_cols)} columns in train dataset with one unique value.')\n",
    "# print(f'There are {len(one_value_cols_test)} columns in test dataset with one unique value.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72030d7b-b1c7-4612-b0e7-b07c3f63e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(train['id_01'], bins=77);\n",
    "# plt.title('Distribution of id_01 variable');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45304438-e232-4ab7-9d72-94e1f24218bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['id_03'].value_counts(dropna=False, normalize=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8192ea1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['isFraud', 'transactionamt', 'productcd', 'card1', 'card2', 'card3', 'card5', 'card6', 'addr1', 'dist1', 'p_emaildomain', 'r_emaildomain', 'c1', 'c2', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10', 'c11', 'c12', 'c13', 'c14', 'v62', 'v70', 'v76', 'v78', 'v82', 'v91', 'v127', 'v130', 'v139', 'v160', 'v165', 'v187', 'v203', 'v207', 'v209', 'v210', 'v221', 'v234', 'v257', 'v258', 'v261', 'v264', 'v266', 'v267', 'v271', 'v274', 'v277', 'v283', 'v285', 'v289', 'v291', 'v294', 'id_01', 'id_02', 'id_05', 'id_06', 'id_09', 'id_13', 'id_17', 'id_19', 'id_20', 'devicetype', 'deviceinfo', 'EVENT_ID', 'ENTITY_ID', 'EVENT_TIMESTAMP', 'ENTITY_TYPE'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477b250-e2f3-4ec0-a403-56ab007bb873",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['transactionamt_to_mean_card1'] = train['transactionamt'] / train.groupby(['card1'])['transactionamt'].transform('mean')\n",
    "train['transactionamt_to_mean_card2'] = train['transactionamt'] / train.groupby(['card2'])['transactionamt'].transform('mean')\n",
    "train['transactionamt_to_std_card1'] = train['transactionamt'] / train.groupby(['card1'])['transactionamt'].transform('std')\n",
    "train['transactionamt_to_mean_card3'] = train['transactionamt'] / train.groupby(['card3'])['transactionamt'].transform('mean')\n",
    "train['transactionamt_to_std_card3'] = train['transactionamt'] / train.groupby(['card3'])['transactionamt'].transform('std')\n",
    "train['transactionamt_to_mean_card5'] = train['transactionamt'] / train.groupby(['card5'])['transactionamt'].transform('mean')\n",
    "train['transactionamt_to_std_card5'] = train['transactionamt'] / train.groupby(['card5'])['transactionamt'].transform('std')\n",
    "train['transactionamt_to_mean_card6'] = train['transactionamt'] / train.groupby(['card6'])['transactionamt'].transform('mean')\n",
    "train['transactionamt_to_std_card6'] = train['transactionamt'] / train.groupby(['card6'])['transactionamt'].transform('std')\n",
    "train['transactionamt_to_std_card2'] = train['transactionamt'] / train.groupby(['card2'])['transactionamt'].transform('std')\n",
    "\n",
    "test['transactionamt_to_mean_card1'] = test['transactionamt'] / test.groupby(['card1'])['transactionamt'].transform('mean')\n",
    "test['transactionamt_to_mean_card2'] = test['transactionamt'] / test.groupby(['card2'])['transactionamt'].transform('mean')\n",
    "test['transactionamt_to_std_card1'] = test['transactionamt'] / test.groupby(['card1'])['transactionamt'].transform('std')\n",
    "test['transactionamt_to_mean_card3'] = test['transactionamt'] / test.groupby(['card3'])['transactionamt'].transform('mean')\n",
    "test['transactionamt_to_std_card3'] = test['transactionamt'] / test.groupby(['card3'])['transactionamt'].transform('std')\n",
    "test['transactionamt_to_mean_card5'] = test['transactionamt'] / test.groupby(['card5'])['transactionamt'].transform('mean')\n",
    "test['transactionamt_to_std_card5'] = test['transactionamt'] / test.groupby(['card5'])['transactionamt'].transform('std')\n",
    "test['transactionamt_to_mean_card6'] = test['transactionamt'] / test.groupby(['card6'])['transactionamt'].transform('mean')\n",
    "test['transactionamt_to_std_card6'] = test['transactionamt'] / test.groupby(['card6'])['transactionamt'].transform('std')\n",
    "test['transactionamt_to_std_card2'] = test['transactionamt'] / test.groupby(['card2'])['transactionamt'].transform('std')\n",
    "\n",
    "\n",
    "train['id_02_to_mean_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('mean')\n",
    "train['id_02_to_std_card1'] = train['id_02'] / train.groupby(['card1'])['id_02'].transform('std')\n",
    "train['id_02_to_mean_card2'] = train['id_02'] / train.groupby(['card2'])['id_02'].transform('mean')\n",
    "train['id_02_to_std_card2'] = train['id_02'] / train.groupby(['card2'])['id_02'].transform('std')\n",
    "train['id_02_to_mean_card3'] = train['id_02'] / train.groupby(['card3'])['id_02'].transform('mean')\n",
    "train['id_02_to_std_card3'] = train['id_02'] / train.groupby(['card3'])['id_02'].transform('std')\n",
    "train['id_02_to_mean_card5'] = train['id_02'] / train.groupby(['card5'])['id_02'].transform('mean')\n",
    "train['id_02_to_std_card5'] = train['id_02'] / train.groupby(['card5'])['id_02'].transform('std')\n",
    "train['id_02_to_mean_card6'] = train['id_02'] / train.groupby(['card6'])['id_02'].transform('mean')\n",
    "train['id_02_to_std_card6'] = train['id_02'] / train.groupby(['card6'])['id_02'].transform('std')\n",
    "\n",
    "\n",
    "test['id_02_to_mean_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('mean')\n",
    "test['id_02_to_std_card1'] = test['id_02'] / test.groupby(['card1'])['id_02'].transform('std')\n",
    "test['id_02_to_mean_card2'] = test['id_02'] / test.groupby(['card2'])['id_02'].transform('mean')\n",
    "test['id_02_to_std_card2'] = test['id_02'] / test.groupby(['card2'])['id_02'].transform('std')\n",
    "test['id_02_to_mean_card3'] = test['id_02'] / test.groupby(['card3'])['id_02'].transform('mean')\n",
    "test['id_02_to_std_card3'] = test['id_02'] / test.groupby(['card3'])['id_02'].transform('std')\n",
    "test['id_02_to_mean_card5'] = test['id_02'] / test.groupby(['card5'])['id_02'].transform('mean')\n",
    "test['id_02_to_std_card5'] = test['id_02'] / test.groupby(['card5'])['id_02'].transform('std')\n",
    "test['id_02_to_mean_card6'] = test['id_02'] / test.groupby(['card6'])['id_02'].transform('mean')\n",
    "test['id_02_to_std_card6'] = test['id_02'] / test.groupby(['card6'])['id_02'].transform('std')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242032f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = train['p_emaildomain'].str.split('.', expand=True)\n",
    "train[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = train['r_emaildomain'].str.split('.', expand=True)\n",
    "test[['P_emaildomain_1', 'P_emaildomain_2', 'P_emaildomain_3']] = test['p_emaildomain'].str.split('.', expand=True)\n",
    "test[['R_emaildomain_1', 'R_emaildomain_2', 'R_emaildomain_3']] = test['r_emaildomain'].str.split('.', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361aced8-0116-465b-a018-ad9b78209c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(f'{save_dir}/train_EDA.csv', index=None)\n",
    "test.to_csv(f'{save_dir}/test_EDA.csv', index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb735e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
